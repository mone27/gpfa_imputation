# AUTOGENERATED! DO NOT EDIT! File to edit: ../lib_nbs/20_Gaussian.ipynb.

# %% auto 0
__all__ = ['ListNormal', 'Normal', 'ListMNormal', 'MNormal', 'to_posdef', 'is_symmetric', 'symmetric_upto', 'is_posdef',
           'is_posdef_eigv', 'PosDef', 'CheckPosDef', 'conditional_guassian', 'cond_gaussian_batched', 'cov2std']

# %% ../lib_nbs/20_Gaussian.ipynb 4
from collections import namedtuple
from fastcore.basics import patch

# %% ../lib_nbs/20_Gaussian.ipynb 7
ListNormal = namedtuple('ListNormal', ['mean', 'std'])

# %% ../lib_nbs/20_Gaussian.ipynb 8
Normal = namedtuple('Normal', ['mean', 'std'])

# %% ../lib_nbs/20_Gaussian.ipynb 9
@patch
def __getitem__(self: ListNormal, n:int
           )->Normal:
    """Get the mean and cov for the nth Normal distribution in the list """
    return Normal(self.mean[n], self.std[n])

# %% ../lib_nbs/20_Gaussian.ipynb 10
@patch
def detach(self: ListNormal)->ListNormal:
    """Detach both mean and cov at once """
    return ListNormal(self.mean.detach(), self.std.detach())

# %% ../lib_nbs/20_Gaussian.ipynb 13
ListMNormal = namedtuple('ListMultiNormal', ['mean', 'cov'])

# %% ../lib_nbs/20_Gaussian.ipynb 14
MNormal = namedtuple('MultiNormal', ['mean', 'cov'])

# %% ../lib_nbs/20_Gaussian.ipynb 15
@patch
def __getitem__(self: ListMNormal, n:int
           )->Normal:
    """Get the mean and cov for the nth Normal distribution in the list """
    return MNormal(self.mean[n], self.cov[n])
@patch
def __setitem__(self: ListMNormal, idx, value)->Normal:
    """set the mean and cov for the nth Normal distribution in the list """
    self.mean[idx], self.cov[idx] = value

# %% ../lib_nbs/20_Gaussian.ipynb 16
@patch
def detach(self: ListMNormal)->ListMNormal:
    """Detach both mean and cov at once """
    return ListMNormal(self.mean.detach(), self.cov.detach())

# %% ../lib_nbs/20_Gaussian.ipynb 20
import pandas as pd
from torch import Tensor

# %% ../lib_nbs/20_Gaussian.ipynb 23
def is_symmetric(value, atol=1e-5):
    return torch.isclose(value, value.mT, atol=atol).all().item()

# %% ../lib_nbs/20_Gaussian.ipynb 25
def symmetric_upto(value, start=-8):
    for exp in torch.arange(start, 3):
        if is_symmetric(value, atol=10**exp):
            return exp.item()
    return exp.item()

# %% ../lib_nbs/20_Gaussian.ipynb 29
def is_posdef(cov):
    return torch.distributions.constraints.positive_definite.check(cov).item()

# %% ../lib_nbs/20_Gaussian.ipynb 33
def is_posdef_eigv(cov):
    eigv = torch.linalg.eigvalsh(cov)
    if (eigv < 0).any():
        return False, eigv
    return True, eigv

# %% ../lib_nbs/20_Gaussian.ipynb 38
class PosDef():
    """ Positive Definite Constraint for PyTorch parameters"""
    def transform(self,
                  raw # square matrix
                 ):
        """transform any matrix into a positive definite one"""
        C = torch.tril(raw)
        return C @ C.mT
    
    def inverse_transform(self,
                          value # a positive definite matrix
                         ):
        """tranform positive definite matrix into a matrix that can be back_transformed using `transform`"""
        return torch.linalg.cholesky(value)

to_posdef = PosDef().transform

# %% ../lib_nbs/20_Gaussian.ipynb 50
from warnings import warn
from fastcore.basics import store_attr

# %% ../lib_nbs/20_Gaussian.ipynb 51
class CheckPosDef():
    def __init__(self,
                do_check:bool = False, # set to True to actually check matrix
                use_log:bool = True, # keep internal log
                warning:bool = True, # show a warning if a matrix is not pos def 
                ):
        store_attr()
        self.log = pd.DataFrame()
        self.extra_args = {}
    def add_args(self, **kwargs):
        """Add an extra argument to the next call of check_posdef """
        self.extra_args = {**kwargs, **self.extra_args}
        return self
    
    def check(self,
              x: Tensor, # (batch of) square matrix
              **extra_args
             ) -> pd.DataFrame:
        
        if not self.do_check: return
        
        self.add_args(**extra_args)
        
        x = x if x.dim() > 2 else [x]
        infos = pd.concat([*map(self._check_matrix, x)])
        
        if self.use_log: self.log = pd.concat([self.log, infos])
        if self.warning and (~infos['is_pd_eigv'].all() or ~infos['is_pd_chol'].all()):
             warn("Matrix is not positive definite")
        
        self.extra_args = {} 
        return infos
    
    def _check_matrix(self,
                     x: Tensor # square matrix
                    ) -> pd.DataFrame:
        
        x = x.detach().cpu().clone() # free GPU memory and ensure that there is a copy
        sym_upto = symmetric_upto(x)

        is_pd_eigv, eigv = is_posdef_eigv(x)
        is_pd_chol = torch.linalg.cholesky_ex(x).info.eq(0).all().item() # skip pytorch too strict symmetry check
        is_sym = is_symmetric(x)

        info = pd.DataFrame({
            'is_pd_eigv': is_pd_eigv,
            'is_pd_chol': is_pd_chol,
            'is_sym': is_sym,
            'sym_upto': sym_upto,
            'eigv': [eigv.detach().numpy()],
            'matrix': [x.detach().numpy()],
            **self.extra_args
        })

        return info

# %% ../lib_nbs/20_Gaussian.ipynb 61
import torch
from torch.distributions import MultivariateNormal
from torch.linalg import cholesky
from torch import cholesky_inverse
from torch import Tensor

from fastcore.test import *
from .utils import *
from typing import List

# %% ../lib_nbs/20_Gaussian.ipynb 62
def conditional_guassian(
                         μ: Tensor, # mean with shape `[n_vars]`
                         Σ: Tensor, # cov with shape `[n_vars, n_vars] `
                         obs: Tensor, # Observations with shape `[n_obs]`, where `n_obs = sum(idx)`
                         mask: Tensor # Boolean tensor specifying for each variable is observed (True) or not (False). Shape `[n_vars]`
                        ) -> ListMNormal: # Distribution conditioned on observations. shape `[n_vars - n_obs]`
    assert μ.shape[0] == mask.shape[0]
    assert obs.shape[0] == sum(mask)
    
    μ_x = μ[~mask]
    μ_o = μ[mask]
    # the double square brackets `:][:` are needed to keep the dimensionality even for empty tensors 
    Σ_xx = Σ[~mask,:][:, ~mask]
    Σ_xo = Σ[~mask,:][:,  mask]
    Σ_ox = Σ[ mask,:][:, ~mask]
    Σ_oo = Σ[ mask,:][:,  mask]
    
    Σ_oo_inv = cholesky_inverse(cholesky(Σ_oo))
    
    
    mean = μ_x + Σ_xo@Σ_oo_inv@(obs - μ_o)
    cov = Σ_xx - Σ_xo@Σ_oo_inv@Σ_ox
    
    return ListMNormal(mean, cov)
    

# %% ../lib_nbs/20_Gaussian.ipynb 66
def cond_gaussian_batched(dist: ListMNormal,
                         obs, # this needs to have the same shape of the mask !!! 
                         mask
                         ) -> List[ListMNormal]: # lists of distributions for element in the batch
    return [conditional_guassian(dist.mean[i], dist.cov[i], obs[i][mask[i]], mask[i]) for i in range(obs.shape[0])]
        

# %% ../lib_nbs/20_Gaussian.ipynb 104
def cov2std(x):
    "convert cov of array of covariances to array of stddev"
    return torch.sqrt(torch.diagonal(x, dim1=-2, dim2=-1))
