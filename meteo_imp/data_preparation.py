# AUTOGENERATED! DO NOT EDIT! File to edit: ../lib_nbs/00_data_preparation.ipynb.

# %% auto 0
__all__ = ['GPFADataGenerator', 'MeteoDataTest', 'Standardizer']

# %% ../lib_nbs/00_data_preparation.ipynb 4
import torch
from torch import Tensor

import pandas as pd
import numpy as np
from fastcore.foundation import patch
from fastcore.test import *
from fastcore.basics import *

import matplotlib.pyplot as plt
import altair as alt
from altair import datum

from functools import lru_cache
from typing import Collection

# %% ../lib_nbs/00_data_preparation.ipynb 7
class GPFADataGenerator:
    def __init__(self,
                    n_features: int,
                    n_obs: int,
                    latent_func = lambda x: torch.sin(3*x), # Functions used to generate the true latent
                    noise_std = .2,
                    Lambda = None
                ):
        
        self.n_features, self.n_obs = n_features, n_obs
        self.time = torch.arange(0, self.n_obs, dtype=torch.float)
        
        self.latent = latent_func(self.time)
        
        self.Lambda = torch.tensor(Lambda).reshape(n_features, 1) if Lambda is not None else torch.rand(n_features, 1)
        
        self.exact_X = (self.Lambda * self.latent).T
        
        self.X =  self.exact_X + torch.normal(0., noise_std, size = (n_obs, n_features)) 
        
        self.data = pd.DataFrame(self.X.numpy(), columns = [f"x{i}" for i in range(self.n_features)]) 
        

# %% ../lib_nbs/00_data_preparation.ipynb 12
class MeteoDataTest:
    "Utility class to keep track of dataset, missing data and export to right format"
    def __init__(self, data: pd.DataFrame):
        " Init with provided dataset"
        self.data = data.copy()
        self.data_complete = self.data.copy()
        self.n_features, self.n_obs = data.shape[1], data.shape[0]
        self.time = torch.arange(0, self.n_obs, dtype=torch.float)
    @classmethod
    def generate_gpfa(cls, *args, **kwargs):
        generator = GPFADataGenerator(*args, **kwargs)
        self = MeteoDataTest(generator.data)
        self.generator = generator
        return self

# %% ../lib_nbs/00_data_preparation.ipynb 15
@patch()
def add_random_missing(self: MeteoDataTest,
                       prob_miss_row: float = .2,  #  Probability an entire row is missing
                       prob_miss_value: float = .1  # Probability a single observation is missing
                       ):
    """Make some row and same values randomly missing """
    # keep the original data
        
    self.is_miss_row = torch.rand(self.n_obs) <= prob_miss_row
    
    self.data[self.is_miss_row.numpy()] = np.nan
    
    self.is_miss_value = (torch.rand(self.n_obs * self.n_features) <= prob_miss_value).reshape(-1, self.n_features)
    
    self.data[self.is_miss_value.numpy()] = np.nan
    
    return self

# %% ../lib_nbs/00_data_preparation.ipynb 20
def _make_random_gap(
    gap_length: int, # The length of the gap
    total_length: int, # The total number of observations
    gap_start: int = None # Optional start of gap
): # (total_length) array of bools to indicicate if the data is missing or not
    "Add a continous gap of ginve length at random position"
    if(gap_length >= total_length):
        return np.repeat(True, total_length)
    gap_start = np.random.randint(total_length - gap_length) if gap_start is None else gap_start
    return np.hstack([
        np.repeat(False, gap_start),
        np.repeat(True, gap_length),
        np.repeat(False, total_length - (gap_length + gap_start))
    ])

# %% ../lib_nbs/00_data_preparation.ipynb 23
@patch
def add_gap(self: MeteoDataTest,
            gap_length:int,  # length of gap
            variables: Collection[str],  # variables that should be affected by the gap
            gap_start: int = None  # Optional start of the gap
            ):
    
    
    self.is_gap = _make_random_gap(gap_length, self.data.shape[0], gap_start)
    self.data.loc[self.is_gap, variables] = np.nan
    return self

# %% ../lib_nbs/00_data_preparation.ipynb 26
@patch
def tidy_df(self: MeteoDataTest,
            complete = False,  # full dataset (False) or the one with missing data (True)
            is_missing = False  # add flag whether value is missing
            ):
    
    df = self.data if not complete else self.data_complete # no need to copy here because next lines does a copy anyway
    df = df.assign(time = self.time.numpy())
        
    df = df.melt("time")
    
    if is_missing: df = df.assign(is_missing = self.data.melt().value.isna()) #missing data is not from complete data
        
    return df

# %% ../lib_nbs/00_data_preparation.ipynb 34
@patch(as_prop=True)
def data_compl_tidy(self: MeteoDataTest):
    return self.tidy_df(complete=True, is_missing=True)

# %% ../lib_nbs/00_data_preparation.ipynb 39
class Standardizer:
    def __init__(self,
                 x: Tensor # up to 2D Tensor
                ):
        """Init normalizer by storing mean and std dev"""
        self.x_mean = x.mean(axis=0)
        self.x_std = x.std(axis=0)
        
    def normalize(self,
        x: Tensor # up to 2D tensor 
                 ) -> Tensor: # x_normalized
        "Normalize (substract mean and divide by standard deviation) input tensor"
        x_mean = x.mean(axis=0)
        x_std = x.std(axis=0)

        return ((x - self.x_mean) / self.x_std)

    def reverse_normalize(self,
        x_norm, # Normalized array
                          ) -> Tensor:       # Array after reversing normalization
        return x_norm * self.x_std + self.x_mean

    def reverse_normalize_std(self,
        x_std_norm, # Normalized array of standard deviations
                          ) -> Tensor:       # Array after reversing normalization
        return x_std_norm * self.x_std

# %% ../lib_nbs/00_data_preparation.ipynb 42
@patch
def log_transform(self: MeteoDataTest,
                  vars: str | Collection[str],  # list of variables names to log-transform
                  )-> MeteoDataTest:
    "Tranform the given var with log(x+1)"
    for var in listify(vars):
        self.data["log_" + var] = np.log(self.data[var] + 1)
        self.data_complete["log_" + var] = np.log(self.data_complete[var] + 1)
    self.data = self.data.drop(columns=vars)
    self.data_complete = self.data_complete.drop(columns=vars)
    return self
