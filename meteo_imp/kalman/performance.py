# AUTOGENERATED! DO NOT EDIT! File to edit: ../../lib_nbs/12_filter_performance_stability.ipynb.

# %% auto 0
__all__ = ['default_kwargs', 'KalmanFilterPerformance', 'product_dict', 'perf_comb_params', 'fuzz_filter_SR',
           'plot_err_sr_filter']

# %% ../../lib_nbs/12_filter_performance_stability.ipynb 3
from fastcore.test import *
from fastcore.basics import *
from ..utils import *
from ..gaussian import *
# from meteo_imp.data_preparation import MeteoDataTest
from .filter import *
from .filter import get_test_data

import pykalman
from typing import *

import numpy as np
import pandas as pd
import torch
from torch import Tensor
from torch.distributions import MultivariateNormal

from timeit import timeit
import polars as pl
import altair as alt

from tqdm.auto import tqdm

import itertools
from fastcore.meta import delegates

# %% ../../lib_nbs/12_filter_performance_stability.ipynb 4
class KalmanFilterPerformance():
    def __init__(self, n_obs=100, n_dim_obs=4, n_dim_state=3, n_dim_contr=3, bs=5, p_missing=.3,
                 init_method = 'random',
                 use_sr_filter=True, device='cpu', use_conditional=True, use_batch=True, **kwargs):
        store_attr()
        filt_cls = KalmanFilterSR if use_sr_filter else KalmanFilter
        if init_method == 'random':
            self.filter = filt_cls.init_random(self.n_dim_obs,self.n_dim_state, self.n_dim_contr)
        elif init_method == 'simple':
            assert n_dim_state == n_dim_contr and n_dim_state == n_dim_obs, "must have same dim for init simple"
            self.filter = filt_cls.init_simple(n_dim_state)
        elif init_method == 'local_slope':
            self.filter = filt_cls.init_local_slope_pca(n_dim_obs = n_dim_obs, n_dim_state=n_dim_state//2, n_dim_contr=n_dim_contr//2)
        else:
            raise ValueError(f"{init_method} is not supported")
        
        self.filter.to(device)
        self.filter.use_conditional = self.use_conditional
        self.data = get_test_data(n_obs, n_dim_obs = n_dim_obs, n_dim_contr=n_dim_contr, p_missing=p_missing, bs=bs, device=device)
        
    def get_method(self, method):
        data, mask, control = self.data
        method = getattr(self.filter, method)
        if self.use_batch:
            return lambda: method(data, mask, control)
        else:
            return lambda: [method(d,m,c) for d,m,c in zip(data, mask, control)]
    def time_method(self, method, rep = 1):
        method = self.get_method(method)
        time = timeit('method()', globals={'method': method}, number=rep)
        return time / rep
        
        
    

# %% ../../lib_nbs/12_filter_performance_stability.ipynb 7
# from https://stackoverflow.com/a/5228294
def product_dict(**kwargs):
    keys = kwargs.keys()
    vals = kwargs.values()
    for instance in itertools.product(*vals):
        yield dict(zip(keys, instance))

# %% ../../lib_nbs/12_filter_performance_stability.ipynb 8
default_kwargs = {'n_obs':100, 'n_dim_obs':4, 'n_dim_state':3, 'n_dim_contr':3, 'bs':5,
                       'use_sr_filter': True, 'device':'cpu', 'use_conditional':True, 'use_batch':True}

# %% ../../lib_nbs/12_filter_performance_stability.ipynb 9
@delegates(KalmanFilterPerformance)
def perf_comb_params(method,  **kwargs):
    kwargs = default_kwargs | kwargs
    kwargs = {key:tuplify(arg) for key, arg in kwargs.items()}
    arg_sets = list(product_dict(**kwargs))
    out = []
    for arg_set in tqdm(arg_sets):
        kf = KalmanFilterPerformance(**arg_set)
        time = kf.time_method(method)
        out.append({'time': time} | arg_set)
    return pl.DataFrame(out)

# %% ../../lib_nbs/12_filter_performance_stability.ipynb 36
import polars as pl
import altair as alt
from altair import datum

# %% ../../lib_nbs/12_filter_performance_stability.ipynb 38
def fuzz_filter_SR(n_iter=10, n_obs=50):
    reset_seed()
    out = []
    for n in tqdm(range(n_iter)):
        k = KalmanFilter.init_random(10,5,8, seed=None)
        kSR = KalmanFilterSR.init_from(k)
        data, mask, control = get_test_data(n_obs,10,8)
        filt = k.filter(data, mask, control)
        filtSR = kSR.filter(data, mask, control)
        for t in range(n_obs):
            P = filt.cov[:,t]
            P_C = filtSR.cov[:,t]
            out.append({'t': t, 'n': n, 'MAE': (P - P_C @ P_C.mT).abs().mean().item()})
    return pl.DataFrame(out)

# %% ../../lib_nbs/12_filter_performance_stability.ipynb 42
def plot_err_sr_filter(err_raw):
    err = err_raw.groupby('t').agg([
        pl.col('MAE').median().alias("median"),
        pl.col('MAE').quantile(.75).alias("Q3"),
        pl.col('MAE').quantile(.25).alias("Q1"),
        pl.col('MAE').max().alias("max")
    ]) 
    
    median = alt.Chart(err.to_pandas()).mark_line(color="black"
           ).encode(
    x = alt.X('t', title="Number of Iterations"),
    y = alt.Y('median', axis=alt.Axis(format=".1e"), scale=alt.Scale(type="log"), title="log MAE"),
    # color=datum("median"),
    strokeDash = datum("median")
    #, scale=alt.Scale(range=['black']))
    )

    Q1 = alt.Chart(err.to_pandas()).mark_line(color='dimgray', strokeDash=[4,6]).encode(x = 't', y = 'Q1', strokeDash=datum("quartile"))
    Q3 = alt.Chart(err.to_pandas()).mark_line(color='dimgray', strokeDash=[4,6]).encode(x = 't', y = 'Q3', strokeDash=datum("quartile"))
    max = alt.Chart(err.to_pandas()).mark_line(color='black', strokeDash=[2,2]).encode(x = 't', y = 'max', strokeDash=datum("max"))
    p = (Q1 + Q3 + max + median).properties()
    return p 
