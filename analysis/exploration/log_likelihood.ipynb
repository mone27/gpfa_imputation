{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec8aae4-5895-4ebb-8d71-274bb1182cd9",
   "metadata": {},
   "source": [
    "# Exploration of Loglikelihood computations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4397cd2f-a963-4eb8-871d-00c97f691a48",
   "metadata": {},
   "source": [
    "This notebook is not running yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f349303-ab26-470b-996a-12d0ca27ced7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f77a25f0-5122-4f6a-afc8-9050f731b484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.7474)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.loglikelihood(X, smooth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a309d98e-e0cc-4df5-8c15-58de6c45510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "405d2e80-e9cc-4d8b-950f-065b8a0d5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_multivariate_normal_density(X, means, covars, min_covar=1.e-7):\n",
    "    \"\"\"Log probability for full covariance matrices. \"\"\"\n",
    "    if hasattr(linalg, 'solve_triangular'):\n",
    "        # only in scipy since 0.9\n",
    "        solve_triangular = linalg.solve_triangular\n",
    "    else:\n",
    "        # slower, but works\n",
    "        solve_triangular = linalg.solve\n",
    "    n_samples, n_dim = X.shape\n",
    "    nmix = len(means)\n",
    "    log_prob = np.empty((n_samples, nmix))\n",
    "    for c, (mu, cv) in enumerate(zip(means, covars)):\n",
    "        try:\n",
    "            cv_chol = linalg.cholesky(cv, lower=True)\n",
    "        except linalg.LinAlgError:\n",
    "            # The model is most probabily stuck in a component with too\n",
    "            # few observations, we need to reinitialize this components\n",
    "            cv_chol = linalg.cholesky(cv + min_covar * np.eye(n_dim),\n",
    "                                      lower=True)\n",
    "        cv_log_det = 2 * np.sum(np.log(np.diagonal(cv_chol)))\n",
    "        cv_sol = solve_triangular(cv_chol, (X - mu).T, lower=True).T\n",
    "        log_prob[:, c] = - .5 * (np.sum(cv_sol ** 2, axis=1) + \\\n",
    "                                     n_dim * np.log(2 * np.pi) + cv_log_det)\n",
    "\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2c65073-eeca-41cc-8cdc-0d67a3b6e996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.41893853]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_multivariate_normal_density(np.ones((1,1)), np.zeros(1), np.eye(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed3fa2e1-7e9a-4d55-8c8d-da90d74d4ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.4189)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultivariateNormal(torch.zeros(1), torch.eye(1)).log_prob(torch.ones((1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dce87d1b-6bd6-4162-839b-9da2f9e5043d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.83787707]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_multivariate_normal_density(np.ones((1, 2)), np.zeros((1,2)), np.expand_dims(np.eye(2), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb8121d3-0233-4611-b01a-b2cc2c58167a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.8379)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultivariateNormal(torch.zeros(2), torch.eye(2)).log_prob(torch.ones((2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6956af7-7f3e-4e6d-b2e9-7f30bcdbb830",
   "metadata": {},
   "source": [
    "pytorch and pykalman have the same results for computing the loglikelihood of a gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4c7cc357-5442-4fec-9ac3-6b2bf555843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _torch_loglikelihoods(observation_matrices, observation_offsets,\n",
    "                    observation_covariance, predicted_state_means,\n",
    "                    predicted_state_covariances, observations):\n",
    "    \n",
    "    n_timesteps = observations.shape[0]\n",
    "    loglikelihoods = np.zeros(n_timesteps)\n",
    "    for t in range(n_timesteps):\n",
    "        observation = observations[t]\n",
    "        observation_matrix = _last_dims(observation_matrices, t)\n",
    "        observation_offset = _last_dims(observation_offsets, t, ndims=1)\n",
    "        predicted_state_mean = _last_dims(\n",
    "            predicted_state_means, t, ndims=1\n",
    "        )\n",
    "        predicted_state_covariance = _last_dims(\n",
    "            predicted_state_covariances, t\n",
    "        )\n",
    "\n",
    "        predicted_observation_mean = (\n",
    "            observation_matrix @ predicted_state_mean\n",
    "            + observation_offset\n",
    "        )\n",
    "        predicted_observation_covariance = (\n",
    "            observation_matrix @ predicted_state_covariance @ observation_matrix.T\n",
    "            + observation_covariance\n",
    "        )\n",
    "\n",
    "        loglikelihoods[t] = MultivariateNormal(\n",
    "            predicted_observation_mean,\n",
    "            predicted_observation_covariance\n",
    "        ).log_prob(observation.unsqueeze(0))\n",
    "    return loglikelihoods.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bad19e57-e0e5-4e16-bd9b-4b6aecaffe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = k.filter(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ebafa7d2-7309-49ef-992a-e7fa209be894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mpyk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mloglikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Calculate the log likelihood of all observations\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : [n_timesteps, n_dim_obs] array\u001b[0m\n",
       "\u001b[0;34m            observations for time steps [0...n_timesteps-1]\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        likelihood : float\u001b[0m\n",
       "\u001b[0;34m            likelihood of all observations\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_observations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# initialize parameters\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m(\u001b[0m\u001b[0mtransition_matrices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition_offsets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m         \u001b[0mtransition_covariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_matrices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m         \u001b[0mobservation_offsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_covariance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m         \u001b[0minitial_state_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state_covariance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# apply the Kalman Filter\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m(\u001b[0m\u001b[0mpredicted_state_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_state_covariances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m         \u001b[0mkalman_gains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_state_means\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m         \u001b[0mfiltered_state_covariances\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0m_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtransition_matrices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_matrices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtransition_covariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_covariance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtransition_offsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_offsets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0minitial_state_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state_covariance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mZ\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# get likelihoods for each time step\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mloglikelihoods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_loglikelihoods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m          \u001b[0mobservation_matrices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_offsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_covariance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m          \u001b[0mpredicted_state_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_state_covariances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloglikelihoods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/data-science/lib/python3.10/site-packages/pykalman/standard.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyk.loglikelihood??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ada2a259-f92c-4b80-b9c1-c32ac0f93a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nX = X.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3533b0aa-d6db-41e9-96bc-1e810f601e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean, pred_cov = pyk.filter(nX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0639d2b7-1a30-4042-b1e7-ba99535c4ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.231597970652478"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyk.loglikelihood(nX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e97fbcaf-f682-44f6-84e7-36e0a1a9bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array(pyk._parse_observations(nX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "35cfff97-ce1a-49c4-8736-52c3a2b4ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(transition_matrices, transition_offsets,\n",
    "         transition_covariance, observation_matrices,\n",
    "         observation_offsets, observation_covariance,\n",
    "         initial_state_mean, initial_state_covariance) = (\n",
    "            pyk._initialize_parameters()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "613ad905-c2e0-4627-91b7-4d084341b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "(predicted_state_means, predicted_state_covariances,\n",
    "         kalman_gains, filtered_state_means,\n",
    "         filtered_state_covariances) = (\n",
    "            pykalman.standard._filter(\n",
    "                transition_matrices, observation_matrices,\n",
    "                transition_covariance, observation_covariance,\n",
    "                transition_offsets, observation_offsets,\n",
    "                initial_state_mean, initial_state_covariance,\n",
    "                Z\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c0d0e4aa-bac0-446e-badb-707f917401b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.7473859589713614"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pykalman.standard._loglikelihoods(\n",
    " observation_matrices, observation_offsets, observation_covariance,\n",
    "          pred_mean, pred_cov, Z\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7e2ba1f0-3583-4fa5-a671-0f8d33746b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.747385859489441"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_torch_loglikelihoods(\n",
    "    k.obs_matrices,\n",
    "    k.obs_offsets,\n",
    "    k.obs_cov,\n",
    "    state.mean,\n",
    "    state.cov,\n",
    "    X\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0de46ebd-4fad-42fb-97eb-b4eaabc256ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.747385949780805"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pykalman.standard._loglikelihoods(\n",
    "    k.obs_matrices.numpy(),\n",
    "    k.obs_offsets.numpy(),\n",
    "    k.obs_cov.numpy(),\n",
    "    state.mean.numpy(),\n",
    "    state.cov.numpy(),\n",
    "    Z\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f0915efe-ccdd-48bd-ad95-c024bbad5fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.231597970652478"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyk.loglikelihood(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "89c11933-de33-4e58-b7d3-df30c5aad096",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(pyk.filter(nX), k.filter(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "47bfedcc-d0f2-4e0a-a039-9b0573dd9428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.231597970652478"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyk.loglikelihood(nX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
