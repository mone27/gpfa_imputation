{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec8aae4-5895-4ebb-8d71-274bb1182cd9",
   "metadata": {},
   "source": [
    "# Exploration of Loglikelihood computations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4397cd2f-a963-4eb8-871d-00c97f691a48",
   "metadata": {},
   "source": [
    "This notebook is not running yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f349303-ab26-470b-996a-12d0ca27ced7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77a25f0-5122-4f6a-afc8-9050f731b484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.7474)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.loglikelihood(X, smooth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a309d98e-e0cc-4df5-8c15-58de6c45510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405d2e80-e9cc-4d8b-950f-065b8a0d5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_multivariate_normal_density(X, means, covars, min_covar=1.e-7):\n",
    "    \"\"\"Log probability for full covariance matrices. \"\"\"\n",
    "    if hasattr(linalg, 'solve_triangular'):\n",
    "        # only in scipy since 0.9\n",
    "        solve_triangular = linalg.solve_triangular\n",
    "    else:\n",
    "        # slower, but works\n",
    "        solve_triangular = linalg.solve\n",
    "    n_samples, n_dim = X.shape\n",
    "    nmix = len(means)\n",
    "    log_prob = np.empty((n_samples, nmix))\n",
    "    for c, (mu, cv) in enumerate(zip(means, covars)):\n",
    "        try:\n",
    "            cv_chol = linalg.cholesky(cv, lower=True)\n",
    "        except linalg.LinAlgError:\n",
    "            # The model is most probabily stuck in a component with too\n",
    "            # few observations, we need to reinitialize this components\n",
    "            cv_chol = linalg.cholesky(cv + min_covar * np.eye(n_dim),\n",
    "                                      lower=True)\n",
    "        cv_log_det = 2 * np.sum(np.log(np.diagonal(cv_chol)))\n",
    "        cv_sol = solve_triangular(cv_chol, (X - mu).T, lower=True).T\n",
    "        log_prob[:, c] = - .5 * (np.sum(cv_sol ** 2, axis=1) + \\\n",
    "                                     n_dim * np.log(2 * np.pi) + cv_log_det)\n",
    "\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c65073-eeca-41cc-8cdc-0d67a3b6e996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.41893853]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_multivariate_normal_density(np.ones((1,1)), np.zeros(1), np.eye(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3fa2e1-7e9a-4d55-8c8d-da90d74d4ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.4189)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultivariateNormal(torch.zeros(1), torch.eye(1)).log_prob(torch.ones((1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce87d1b-6bd6-4162-839b-9da2f9e5043d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.83787707]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_multivariate_normal_density(np.ones((1, 2)), np.zeros((1,2)), np.expand_dims(np.eye(2), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8121d3-0233-4611-b01a-b2cc2c58167a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.8379)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultivariateNormal(torch.zeros(2), torch.eye(2)).log_prob(torch.ones((2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6956af7-7f3e-4e6d-b2e9-7f30bcdbb830",
   "metadata": {},
   "source": [
    "pytorch and pykalman have the same results for computing the loglikelihood of a gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7cc357-5442-4fec-9ac3-6b2bf555843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _torch_loglikelihoods(observation_matrices, observation_offsets,\n",
    "                    observation_covariance, predicted_state_means,\n",
    "                    predicted_state_covariances, observations):\n",
    "    \n",
    "    n_timesteps = observations.shape[0]\n",
    "    loglikelihoods = np.zeros(n_timesteps)\n",
    "    for t in range(n_timesteps):\n",
    "        observation = observations[t]\n",
    "        observation_matrix = _last_dims(observation_matrices, t)\n",
    "        observation_offset = _last_dims(observation_offsets, t, ndims=1)\n",
    "        predicted_state_mean = _last_dims(\n",
    "            predicted_state_means, t, ndims=1\n",
    "        )\n",
    "        predicted_state_covariance = _last_dims(\n",
    "            predicted_state_covariances, t\n",
    "        )\n",
    "\n",
    "        predicted_observation_mean = (\n",
    "            observation_matrix @ predicted_state_mean\n",
    "            + observation_offset\n",
    "        )\n",
    "        predicted_observation_covariance = (\n",
    "            observation_matrix @ predicted_state_covariance @ observation_matrix.T\n",
    "            + observation_covariance\n",
    "        )\n",
    "\n",
    "        loglikelihoods[t] = MultivariateNormal(\n",
    "            predicted_observation_mean,\n",
    "            predicted_observation_covariance\n",
    "        ).log_prob(observation.unsqueeze(0))\n",
    "    return loglikelihoods.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad19e57-e0e5-4e16-bd9b-4b6aecaffe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = k.filter(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebafa7d2-7309-49ef-992a-e7fa209be894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mpyk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mloglikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Calculate the log likelihood of all observations\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : [n_timesteps, n_dim_obs] array\u001b[0m\n",
       "\u001b[0;34m            observations for time steps [0...n_timesteps-1]\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        likelihood : float\u001b[0m\n",
       "\u001b[0;34m            likelihood of all observations\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_observations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# initialize parameters\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m(\u001b[0m\u001b[0mtransition_matrices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition_offsets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m         \u001b[0mtransition_covariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_matrices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m         \u001b[0mobservation_offsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_covariance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m         \u001b[0minitial_state_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state_covariance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# apply the Kalman Filter\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m(\u001b[0m\u001b[0mpredicted_state_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_state_covariances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m         \u001b[0mkalman_gains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_state_means\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m         \u001b[0mfiltered_state_covariances\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0m_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtransition_matrices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_matrices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtransition_covariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_covariance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mtransition_offsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_offsets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0minitial_state_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state_covariance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mZ\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# get likelihoods for each time step\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mloglikelihoods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_loglikelihoods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m          \u001b[0mobservation_matrices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_offsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_covariance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m          \u001b[0mpredicted_state_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_state_covariances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloglikelihoods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/data-science/lib/python3.10/site-packages/pykalman/standard.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyk.loglikelihood??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2a259-f92c-4b80-b9c1-c32ac0f93a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nX = X.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3533b0aa-d6db-41e9-96bc-1e810f601e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean, pred_cov = pyk.filter(nX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639d2b7-1a30-4042-b1e7-ba99535c4ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.231597970652478"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyk.loglikelihood(nX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97fbcaf-f682-44f6-84e7-36e0a1a9bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array(pyk._parse_observations(nX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cfff97-ce1a-49c4-8736-52c3a2b4ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(transition_matrices, transition_offsets,\n",
    "         transition_covariance, observation_matrices,\n",
    "         observation_offsets, observation_covariance,\n",
    "         initial_state_mean, initial_state_covariance) = (\n",
    "            pyk._initialize_parameters()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613ad905-c2e0-4627-91b7-4d084341b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "(predicted_state_means, predicted_state_covariances,\n",
    "         kalman_gains, filtered_state_means,\n",
    "         filtered_state_covariances) = (\n",
    "            pykalman.standard._filter(\n",
    "                transition_matrices, observation_matrices,\n",
    "                transition_covariance, observation_covariance,\n",
    "                transition_offsets, observation_offsets,\n",
    "                initial_state_mean, initial_state_covariance,\n",
    "                Z\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d0e4aa-bac0-446e-badb-707f917401b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.7473859589713614"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pykalman.standard._loglikelihoods(\n",
    " observation_matrices, observation_offsets, observation_covariance,\n",
    "          pred_mean, pred_cov, Z\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ba1f0-3583-4fa5-a671-0f8d33746b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.747385859489441"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_torch_loglikelihoods(\n",
    "    k.obs_matrices,\n",
    "    k.obs_offsets,\n",
    "    k.obs_cov,\n",
    "    state.mean,\n",
    "    state.cov,\n",
    "    X\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de46ebd-4fad-42fb-97eb-b4eaabc256ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.747385949780805"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pykalman.standard._loglikelihoods(\n",
    "    k.obs_matrices.numpy(),\n",
    "    k.obs_offsets.numpy(),\n",
    "    k.obs_cov.numpy(),\n",
    "    state.mean.numpy(),\n",
    "    state.cov.numpy(),\n",
    "    Z\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0915efe-ccdd-48bd-ad95-c024bbad5fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.231597970652478"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyk.loglikelihood(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c11933-de33-4e58-b7d3-df30c5aad096",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(pyk.filter(nX), k.filter(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bfedcc-d0f2-4e0a-a039-9b0573dd9428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.231597970652478"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyk.loglikelihood(nX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa6bb45-ea22-4d69-9edf-c29e38027cb2",
   "metadata": {},
   "source": [
    "## Multivariate likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f5d9d2-7c3c-4187-a0d9-762fac61e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import MultivariateNormal\n",
    "import torch\n",
    "from meteo_imp.gaussian import to_posdef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e1af95-5b2a-4a8e-812c-8ce44e38e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d0f440-d38a-441c-a6b4-abb311ba21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = to_posdef(torch.rand(n,n))\n",
    "mean = torch.rand(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce00f95f-7417-4919-b652-71dfb3a9be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = MultivariateNormal(mean, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fade7e2-88d0-46e6-a920-ffba26ccb69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c09c02-21e0-4d9c-a788-99b00abef7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0237, 0.9482, 0.9448, 1.5264, 1.2376])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d929f8-420d-4e5a-a47f-bc3eecdc29a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.6350)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.log_prob(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0432f9da-99d4-44c7-afde-cefc7211a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist2 = MultivariateNormal(mean, torch.diag(cov.diag()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3315cc35-5704-4150-8f6f-2b0ba12c227a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9555, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.1688, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 1.7292, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 2.1713, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0093]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist2.covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f214e49-5984-4ebf-85f5-108784102701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.6010)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist2.log_prob(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e143e-9e92-40e4-8a61-0edef447e6e5",
   "metadata": {},
   "source": [
    "so we see that if there is a diagonal covariance the likelihood is the same of the sum of the likelihoods of the individual variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ecb4f3-5bc6-45cb-82b8-6aa32f17819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "for i in range(n):\n",
    "    dist_n = MultivariateNormal(mean[i:i+1], cov[i:i+1, i:i+1])\n",
    "    tot += dist_n.log_prob(obs[i:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247d85ff-4939-421b-b020-48a1b6c74cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.6010)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4751a3-ba31-4300-803f-2a73290de5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.3723)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_n.log_prob(obs[i:i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c29d1b-63d1-45f6-b08e-b3d11170e175",
   "metadata": {},
   "source": [
    "performance big ll vs individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801594c2-53b7-4892-ba20-3db56d1e8b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bea0a3-3767-4ef3-9a17-169ae879e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = torch.rand(n)\n",
    "mean = torch.rand(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03635bf3-b4a8-4217-977a-4421f50e6aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = MultivariateNormal(mean, torch.diag(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4338a607-5406-469e-bfb3-b5f7d7355e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b681f911-0074-48fd-9da9-782e9d7e0e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.61 ms ± 134 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit dist.log_prob(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b9bfd-f7da-4202-a9b0-637d251f4fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4552.8486)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.log_prob(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de3f94-c6d4-4a8a-a832-6c23c0097afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ll():\n",
    "    tot = 0\n",
    "    for i in range(n):\n",
    "        dist_n = MultivariateNormal(mean[i:i+1], torch.diag(std[i:i+1]))\n",
    "        tot += dist_n.log_prob(obs[i:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b66ce9-4431-477d-bf20-6fbad47e2539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.6010)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf74bd8-0c2f-4deb-a245-af393ae65f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.49 s ± 164 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit single_ll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be9cf8-b004-4588-859c-004b2f3caca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = MultivariateNormal(mean.cuda(), torch.diag(std).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88683e9a-dc51-47df-b2fd-40a9e76ab0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314bf9c4-b857-4f2a-8d71-8cb65bba6206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630 µs ± 3.43 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit dist.log_prob(obs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
