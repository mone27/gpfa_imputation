{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9e4ef58d",
   "metadata": {},
   "source": [
    "---\n",
    "description: Utilities to train and visualize a GPFA model\n",
    "output-file: learner.html\n",
    "title: GPFA Learner\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25b75aa-51b1-4980-97f5-68df5c3eceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cda543e-9b92-4a60-943a-9e2e3d6a5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| default_exp learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ca6d73-c7bc-49af-a142-dbbaf6402c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe43aefc-a8d5-4a01-8fca-0e5819186d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.distributions import MultivariateNormal \n",
    "\n",
    "import gpytorch\n",
    "from gpfa_imputation.gpfa import *\n",
    "from collections import namedtuple\n",
    "import math\n",
    "\n",
    "from fastcore.foundation import *\n",
    "from fastprogress.fastprogress import progress_bar, master_bar\n",
    "from fastcore.foundation import patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48b6e03-df45-4e08-b68a-3674fbf4a13c",
   "metadata": {},
   "source": [
    "The first thing that we need is a Learner object to keep track of:\n",
    "\n",
    "- input data, output data\n",
    "- model\n",
    "- likelihood\n",
    "\n",
    "and that has methods to help with:\n",
    "\n",
    "- training\n",
    "- prediction \n",
    "- visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f18d28-1fb7-496a-a2c5-c959b20be768",
   "metadata": {},
   "source": [
    "The first thing we need is a training loop, just wrap in a function the example one from GPyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4b790-2027-496d-b159-c2b816dc59ae",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e5bdb-d292-45fe-b059-30f39684b133",
   "metadata": {},
   "source": [
    "The different variables in the can have pretty different values so we normalize so they are more comparable. Have numbers between 0 and 1 should also help with the computation accuracy.\n",
    "\n",
    "One additional complexity is the need to backtransform not only the mean but also the standard deviation.\n",
    "\n",
    "So we need a but of math\n",
    "\n",
    "$$x_{norm} = \\frac{x - \\mu_x}{\\sigma_x}$$\n",
    "then\n",
    "$$x = x_{norm}\\sigma_x + \\mu_x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fc5156-2fa2-4d69-9bb9-5b0a0010cfd7",
   "metadata": {},
   "source": [
    "using properties of Guassian distributions ^[https://cs.nyu.edu/~roweis/notes/gaussid.pdf eq. 4a]\n",
    "\n",
    "$$p(x_{norm}) = \\mathcal{N}(\\mu_{norm}, \\sigma^2_{norm})$$\n",
    "\n",
    "$$p(x) = \\mathcal{N}(\\sigma_x\\mu_{norm} + \\mu_x, \\sigma^2_x \\sigma^2_{norm})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f871a188-4af6-43c6-ac0e-1ca69dfa802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Normalizer:\n",
    "    def __init__(self,\n",
    "                 x: Tensor # up to 2D Tensor\n",
    "                ):\n",
    "        \"\"\"Init normalizer by storing mean and std dev\"\"\"\n",
    "        self.x_mean = x.mean(axis=0)\n",
    "        self.x_std = x.std(axis=0)\n",
    "        \n",
    "    def normalize(self,\n",
    "        x: Tensor # up to 2D tensor \n",
    "                 ) -> Tensor: # x_normalized\n",
    "        \"Normalize (substract mean and divide by standard deviation) input tensor\"\n",
    "        x_mean = x.mean(axis=0)\n",
    "        x_std = x.std(axis=0)\n",
    "\n",
    "        return ((x - self.x_mean) / self.x_std)\n",
    "\n",
    "    def reverse_normalize(self,\n",
    "        x_norm, # Normalized array\n",
    "                          ) -> Tensor:       # Array after reversing normalization\n",
    "        return x_norm * self.x_std + self.x_mean\n",
    "\n",
    "    def reverse_normalize_std(self,\n",
    "        x_std_norm, # Normalized array of standard deviations\n",
    "                          ) -> Tensor:       # Array after reversing normalization\n",
    "        return x_std_norm * self.x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8797019d-24de-40b4-8dda-0addb1e92a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(20).reshape(-1,2)\n",
    "norm = Normalizer(x)\n",
    "test_close(x, norm.reverse_normalize(norm.normalize(x)))\n",
    "test_close(x.std(axis=0), norm.reverse_normalize_std(norm.normalize(x).std(axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ed76b-c01b-475f-9494-10c54d4d0047",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0bef3a-0b73-4352-8a9e-7291aaae760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GPFALearner():\n",
    "    def __init__(self,\n",
    "                 X: Tensor, # (n_features * n_obs) Multivariate time series\n",
    "                 T: Tensor = None # (n_obs) Vector of time of observations.\n",
    "                 # If none each observation is considered to be at the same distance\n",
    "                ):\n",
    "        self.prepare_X(X)\n",
    "        if T is None: self.default_time(X)\n",
    "        else: self.T = T\n",
    "        self.T = self.T.to(X.device) # to support GPUs\n",
    "        \n",
    "        self.likelihood = gpytorch.likelihoods.GaussianLikelihood().to(X.device)\n",
    "        latent_kernel = gpytorch.kernels.RBFKernel().to(X.device)\n",
    "        self.model = GPFA(self.T, self.X, self.likelihood, self.n_features, latent_kernel).to(X.device)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def prepare_X(self, X):\n",
    "        self.norm = Normalizer(X)\n",
    "        X = self.norm.normalize(X)\n",
    "        # flatten Matrix to vector\n",
    "        self.X = X.reshape(-1) \n",
    "        self.n_features = X.shape[1]\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def default_time(self, X):\n",
    "        self.T = torch.arange(X.shape[0])\n",
    "        \n",
    "    \n",
    "    def train(self, n_iter=100, lr=0.1):\n",
    "        # need to enable training mode\n",
    "        self.model.train()\n",
    "        self.likelihood.train()\n",
    "        \n",
    "        # Use the adam optimizer\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr) \n",
    "        \n",
    "        self.losses = torch.zeros(n_iter)\n",
    "        # \"Loss\" for GPs - the marginal log likelihood\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self.model)\n",
    "        self.pb = master_bar([1])\n",
    "        for _ in self.pb:\n",
    "            for i in progress_bar(range(n_iter), parent=self.pb):\n",
    "                # Zero gradients from previous iteration\n",
    "                optimizer.zero_grad()\n",
    "                # Output from model\n",
    "                output = self.model(self.T)\n",
    "                # Calc loss and backprop gradients\n",
    "                loss = -mll(output, self.X)\n",
    "                self.losses[i] = loss.detach()\n",
    "                loss.backward()\n",
    "                self.printer(i)\n",
    "\n",
    "                optimizer.step()\n",
    "        \n",
    "        \n",
    "    def printer(self, i):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9105fe73-aa6d-4232-a1f3-24e8276a008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "T = torch.arange(0,6)\n",
    "\n",
    "X = torch.vstack([(torch.arange(0,3, dtype=torch.float32) + 2 + i) * i for i in T]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae1f7d-510d-4b69-88c5-a797bb5c2fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 8., 10., 12.],\n",
       "        [15., 18., 21.],\n",
       "        [24., 28., 32.],\n",
       "        [35., 40., 45.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63fd700-c0af-4ad4-8e52-4c5d6a339212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l for learner\n",
    "l = GPFALearner(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c9acea-2c30-42c7-9a66-10535dbf21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(T, l.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31067ba-ff73-4e57-be57-f5d34efdef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with explicit time\n",
    "test_eq(T, GPFALearner(X, T).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198aad5-7fc9-4665-8823-a28d42a74ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(l.n_features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04726f27-5861-4f00-881d-f15935e05f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0590, -1.0955, -1.1236, -0.8347, -0.8326, -0.8305, -0.4610, -0.4382,\n",
       "        -0.4201,  0.0623,  0.0876,  0.1075,  0.7350,  0.7449,  0.7523,  1.5573,\n",
       "         1.5337,  1.5145])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a69e95-19a1-405e-9998-d97920b5dc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/anaconda3/envs/data-science/lib/python3.10/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:136: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2183.)\n",
      "  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n",
      "/home/simone/anaconda3/envs/data-science/lib/python3.10/site-packages/torch/autograd/__init__.py:173: UserWarning: operator() profile_node %840 : int[] = prim::profile_ivalue(%838)\n",
      " does not have profile information (Triggered internally at  ../torch/csrc/jit/codegen/cuda/graph_fuser.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "l.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b38db4-2eba-4009-b272-d6054980262b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3442,  1.3034,  1.2644,  1.2289,  1.1978,  1.1685,  1.1362,  1.1000,\n",
       "         1.0615,  1.0225,  0.9837,  0.9453,  0.9072,  0.8689,  0.8301,  0.7906,\n",
       "         0.7506,  0.7100,  0.6689,  0.6275,  0.5859,  0.5442,  0.5025,  0.4608,\n",
       "         0.4190,  0.3772,  0.3353,  0.2932,  0.2510,  0.2086,  0.1662,  0.1237,\n",
       "         0.0813,  0.0389, -0.0033, -0.0455, -0.0876, -0.1296, -0.1714, -0.2132,\n",
       "        -0.2548, -0.2962, -0.3375, -0.3786, -0.4196, -0.4603, -0.5008, -0.5410,\n",
       "        -0.5810, -0.6207, -0.6601, -0.6990, -0.7343, -0.7640, -0.8089, -0.8364,\n",
       "        -0.8857, -0.9075, -0.9574, -0.9789, -1.0242, -1.0492, -1.0886, -1.1164,\n",
       "        -1.1515, -1.1772, -1.2128, -1.2350, -1.2700, -1.2861, -1.3172, -1.3314,\n",
       "        -1.3617, -1.3904, -1.4003, -1.4268, -1.4382, -1.4574, -1.4849, -1.4873,\n",
       "        -1.5002, -1.5141, -1.5112, -1.5356, -1.5542, -1.5486, -1.5625, -1.5695,\n",
       "        -1.5620, -1.5779, -1.5880, -1.5860, -1.6030, -1.6040, -1.5996, -1.6096,\n",
       "        -1.6022, -1.5983, -1.6107, -1.6174])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa919f20-cc8f-47c7-b35e-12e57b7486f4",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "add a function to get predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f4ef6-9f6b-44d9-877b-1095b222bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@torch.no_grad() # don't calc gradients on predictions\n",
    "@patch()\n",
    "def predict_raw(self: GPFALearner, T):\n",
    "    self.model.eval()\n",
    "    self.likelihood.eval()\n",
    "    return self.likelihood(self.model(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed0643-1ce3-40ac-bb5b-59534c2c6c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/anaconda3/envs/data-science/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(loc: torch.Size([18]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_out = l.predict_raw(T)\n",
    "raw_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e256c-f331-4508-9ace-d1b161528fd7",
   "metadata": {},
   "source": [
    "the model prediction is a distribution with `len(T)*n_features` dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a050f2-0aa0-4e0a-8fb7-869397feadc9",
   "metadata": {},
   "source": [
    "which is in the in the wrong shape and need to be rescaled after the normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2540a9d5-7fab-4722-bb71-8356f01d69cd",
   "metadata": {},
   "source": [
    "Also we don't need th full distribution but only the mean and stddev for each variable at every time step\n",
    "\n",
    "And we can \"fix\" the shape by transforming back to a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebaf0b9-1f07-4bc4-8719-a0c7047e203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_stddev = raw_out.stddev.reshape(-1, l.n_features)\n",
    "raw_mean = raw_out.mean.reshape(-1, l.n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07d9468-642a-4c7e-b40f-203680003159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0250, 0.0198, 0.0224],\n",
       "        [0.0242, 0.0187, 0.0214],\n",
       "        [0.0239, 0.0183, 0.0211],\n",
       "        [0.0239, 0.0183, 0.0211],\n",
       "        [0.0242, 0.0187, 0.0214],\n",
       "        [0.0250, 0.0198, 0.0224]], grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b23a4c-2da7-4bda-887c-29ef751600b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "NormParam = namedtuple(\"NormalParameters\", [\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9426d969-63e0-4a38-a020-eb17701b1364",
   "metadata": {},
   "source": [
    "This function transforms the raw output of the Gaussian Process (`p(X)`) into a prediction that can be used.\n",
    "need to do two things:\n",
    "\n",
    "- take mean and stddev (this is the diagonal of the covariance matrix) for each variable\n",
    "- reshape so that each row is a time step and each column a variable\n",
    "- reverse the normalization\n",
    "\n",
    "the mean and the std are passed individually because in the conditional predictions is not possible to have the whole covariance matrix (and thus a MultiNormal) but the mean and stddev are enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c88c0d-5844-485c-8287-7411e351ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@torch.no_grad() # needed because raw output still has gradients attached\n",
    "@patch\n",
    "def prediction_from_raw(self: GPFALearner, raw_mean, raw_std):\n",
    "    \"\"\" Takes a raw prediction and produces and final prediction, by reshaping and reversing normalization\"\"\"\n",
    "    raw_std = raw_std.reshape(-1, self.n_features)\n",
    "    raw_mean = raw_mean.reshape(-1, self.n_features)\n",
    "    \n",
    "    pred_mean = self.norm.reverse_normalize(raw_mean)\n",
    "    pred_std = self.norm.reverse_normalize_std(raw_std)\n",
    "    \n",
    "    #remove pytorch gradients\n",
    "    return NormParam(pred_mean.detach(), pred_std.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3af212-6cd8-4e60-8648-7562469bb7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO document this function better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d04c2f8-7d02-4ada-8b4b-d98cf29d9b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def predict(self: GPFALearner, T):\n",
    "    pred_raw = self.predict_raw(T)\n",
    "    return self.prediction_from_raw(pred_raw.mean, pred_raw.stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eea5e6-89a6-4a71-bf56-e8fce29eab54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormalParameters(mean=tensor([[-4.5984e-01, -1.7553e-02,  4.4573e-01],\n",
       "        [ 3.0967e+00,  4.0383e+00,  4.9975e+00],\n",
       "        [ 8.2710e+00,  9.9444e+00,  1.1622e+01],\n",
       "        [ 1.5309e+01,  1.7973e+01,  2.0630e+01],\n",
       "        [ 2.4203e+01,  2.8114e+01,  3.2012e+01],\n",
       "        [ 3.4577e+01,  3.9946e+01,  4.5289e+01]]), std=tensor([[0.3351, 0.3012, 0.3816],\n",
       "        [0.3239, 0.2848, 0.3657],\n",
       "        [0.3200, 0.2785, 0.3599],\n",
       "        [0.3198, 0.2787, 0.3599],\n",
       "        [0.3239, 0.2848, 0.3659],\n",
       "        [0.3351, 0.3015, 0.3822]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.predict(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0784d70-8220-4372-99e9-485647e68c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = l.predict(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977b09d-703f-4152-ad05-78273a6d750e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01055e42-da8f-481d-9f62-2f8e83987adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0965c418-ca0f-40d9-a53a-fecb5fd3bb68",
   "metadata": {},
   "source": [
    "### Check learning is working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb33da4a-ca64-489d-bddc-eff1bdef3dbc",
   "metadata": {},
   "source": [
    "The idea is to use the current model to generate a dataset, that can be for sure modelled using a GPFA (because is the output of GPFA) and then train another model and see if the parameters converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7530f0b-ba2c-409b-ac15-04dde1ec9213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dummy GPFA with 3 features\n",
    "Lt = GPFALearner(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c72f6-6073-4451-ac94-becc940978e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = {\n",
    "   \"Lambda\": torch.tensor([-1, 0.3, .8]).reshape(Lt.n_features, -1),\n",
    "   \"psi\": torch.tensor([1e-5, 5e-5, 2e-5]),\n",
    "   \"latent_kernel.lengthscale\": torch.tensor(5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75348565-ae93-442e-926e-882619bf3c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPFAKernel(\n",
       "  (latent_kernel): RBFKernel(\n",
       "    (raw_lengthscale_constraint): Positive()\n",
       "  )\n",
       "  (raw_psi_diag_constraint): Positive()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lt.model.covar_module.initialize(**test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa81d68-083b-4904-b54f-2768078945d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_X = Lt.predict(T).mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5665123d-a870-42f2-8f19-a82caae617da",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = GPFALearner(target_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba72dc-5a1a-4955-826c-88d574196996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18af534f-0c2b-4024-bd28-61ca0c3ac004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.0693e-03, -8.3923e-04, -8.5640e-04],\n",
       "        [-2.9421e-03, -3.9482e-04, -1.4305e-04],\n",
       "        [-9.4700e-04, -1.2779e-04, -4.9591e-05],\n",
       "        [ 1.1806e-03,  1.1635e-04, -3.4332e-05],\n",
       "        [ 2.8696e-03,  4.3678e-04,  2.6131e-04],\n",
       "        [ 3.9005e-03,  8.0872e-04,  8.1444e-04]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2.predict(T).mean - target_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e62c4f0-39e9-4f57-bcc8-3bbdda35b175",
   "metadata": {},
   "source": [
    "they seems pretty small numbers, so the model is working! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9aab33-6ea7-4c07-8de1-50c136763970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda:\n",
      " tensor([[-1.6049],\n",
      "        [ 1.6213],\n",
      "        [ 1.6172]])\n",
      "psi:  tensor([1.0492e-04, 3.8727e-05, 3.8805e-05])\n",
      "lengthscale: 5.523871421813965\n"
     ]
    }
   ],
   "source": [
    "print(\"Lambda:\\n\", l2.model.covar_module.Lambda.detach())\n",
    "\n",
    "print(\"psi: \", l2.model.covar_module.psi.detach())\n",
    "\n",
    "print(\"lengthscale:\", l2.model.covar_module.latent_kernel.lengthscale.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a993e091-eb29-42a7-8c8e-3050b6189d92",
   "metadata": {},
   "source": [
    "### Conditional Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4e3b7f-95e1-4624-958b-082abc5f4593",
   "metadata": {},
   "source": [
    "This add the supports for conditional predictions, which means that at the time (t) when we are making the predictions some of the variables have been actually observed. Since the model prediction is a normal distribution we can condition on the observed values and thus improve the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8b5f7f-2541-4750-8740-3bf244d88ced",
   "metadata": {},
   "source": [
    "Therefore we need to compute the conditional distribution of a normal ^[https://cs.nyu.edu/~roweis/notes/gaussid.pdf eq, 5a, 5d]\n",
    "\n",
    "$$ X = \\left[\\begin{array}{c} x \\\\ o \\end{array} \\right] $$\n",
    "\n",
    "$$ p(X) = N\\left(\\left[ \\begin{array}{c} \\mu_x \\\\ \\mu_o \\end{array} \\right], \\left[\\begin{array}{cc} \\Sigma_{xx} & \\Sigma_{xo} \\\\ \\Sigma_{ox} & \\Sigma_{oo} \\end{array} \\right]\\right)$$\n",
    "\n",
    "where $X$ is a vector of variable that need to predicted and $o$ is a vector of the variables that have been observed\n",
    "\n",
    "The mean is in \"flat format\", where all the features from one time step are next to each other followed by the features of the next time step.\n",
    "\n",
    "then \n",
    "\n",
    "$$p(x|o) = N(\\mu_x + \\Sigma_{xo}\\Sigma_{oo}^{-1}(o - \\mu_o), \\Sigma_{xx} - \\Sigma_{xo}\\Sigma_{oo}^{-1}\\Sigma_{ox})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd1908b-6c88-48e0-b555-2d36d4a04fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "def conditional_guassian(gauss: MultivariateNormal,\n",
    "                         obs,\n",
    "                         idx # Boolean tensor specifying for each variable is observed (True) or not (False)\n",
    "                        ):\n",
    "    μ = gauss.mean\n",
    "    Σ = gauss.covariance_matrix\n",
    "    # check idx same size of mu\n",
    "    μ_x = μ[~idx]\n",
    "    μ_o = μ[idx]\n",
    "    \n",
    "    Σ_xx = Σ[~idx,:][:, ~idx]\n",
    "    Σ_xo = Σ[~idx,:][:, idx]\n",
    "    Σ_ox = Σ[idx,:][:, ~idx]\n",
    "    Σ_oo = Σ[idx,:][:, idx]\n",
    "    \n",
    "    Σ_oo_inv = torch.linalg.inv(Σ_oo)\n",
    "    \n",
    "    mean = μ_x + Σ_xo@Σ_oo_inv@(obs - μ_o)\n",
    "    cov = Σ_xx - Σ_xo@Σ_oo_inv@Σ_ox\n",
    "    \n",
    "    return MultivariateNormal(mean, cov)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19daec27-87a1-4ba7-92dc-b9236c08f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example distribution with only 2 variables\n",
    "μ = torch.tensor([.5, 1.])\n",
    "Σ = torch.tensor([[1., .5], [.5 ,1.]])\n",
    "\n",
    "gauss = MultivariateNormal(μ, Σ)\n",
    "\n",
    "idx = torch.tensor([True, False]) # second variable is the observed one\n",
    "\n",
    "obs = torch.tensor(5.) # value of second variable\n",
    "\n",
    "gauss_cond = conditional_guassian(gauss, obs, idx)\n",
    "\n",
    "# hardcoded values to test that the code is working, see also for alternative implementation https://python.quantecon.org/multivariate_normal.html\n",
    "test_close(3.25, gauss_cond.mean.item())\n",
    "test_close(.75, gauss_cond.covariance_matrix.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d34213-7009-4609-b27e-c7afccf62c9a",
   "metadata": {},
   "source": [
    "Test with multiple variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b744875-96dc-44a9-b5fe-11d49711169f",
   "metadata": {},
   "source": [
    "overwrite the predict method to add support for conditional predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2597e5-07a8-48bc-a7db-1db22ad62f65",
   "metadata": {},
   "source": [
    "Need to have the mean and std for both the conditional predictions and the observations, with the same shape and order of the complete prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e861ab7-d218-4981-bbbd-cf89da85b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "def _merge_raw_cond_pred(pred_raw,\n",
    "                         pred_cond,\n",
    "                         obs,\n",
    "                         idx\n",
    "                        ) -> NormParam:\n",
    "    \"\"\"This functions merges a complete predition with a conditional prediction and the observations.\n",
    "    For the observations the std is considered to be 0 \"\"\"\n",
    "    mean = torch.zeros_like(pred_raw.mean) # get shape from complete prediction\n",
    "    mean[~idx] = pred_cond.mean # add predictions\n",
    "    mean[idx] = obs # add observations\n",
    "    \n",
    "    std = torch.zeros_like(pred_raw.stddev)\n",
    "    std[~idx] = pred_cond.stddev\n",
    "    std[idx] = 0 # there is no uncertainty as it's an oberservation\n",
    "    \n",
    "    return NormParam(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96025e7d-884f-487c-af6b-cdb0a407a5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7500]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_cond.covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21aecd-c9f0-4fff-8d63-9b5b4a858b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormalParameters(mean=tensor([5.0000, 3.2500]), std=tensor([0.0000, 0.8660]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_pred = _merge_raw_cond_pred(gauss, gauss_cond, obs, idx)\n",
    "merge_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8eb3f-0753-47fc-88eb-a8771f68a7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually calculated\n",
    "test_close(merge_pred.mean, torch.tensor([5., 3.25]))\n",
    "test_close(merge_pred.std, torch.tensor([0., math.sqrt(.75)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6becae1-e944-4fac-a14c-f158298bce6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1684b1e5-1d80-4657-b95f-cb1a1d020547",
   "metadata": {},
   "source": [
    "The problem is that the mean and the std for normalization are different for each feature, so in order to have the normalization working it is necessary to give the observations as a 2D array and not like a 1D array (like required by the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802e75a-af1e-4331-9d46-9d4da85d57a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def _normalize_obs(self: GPFALearner,\n",
    "                   obs, # (n_obs)\n",
    "                   idx\n",
    "                  ) -> Tensor: # (n_obs)\n",
    "    \"\"\" reshape the observations so they can normalized\"\"\"\n",
    "    obs_compl = torch.zeros(idx.shape)\n",
    "    obs_compl[idx] = obs\n",
    "    obs_compl = obs_compl.reshape(-1, self.n_features)\n",
    "    obs_norm = self.norm.normalize(obs_compl)\n",
    "    return obs_norm.reshape(-1)[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fefac69-603a-4437-9f0d-dbd9cf4eeed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_pred = torch.tensor([6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89656a8-cfa1-47e0-ba69-8a29974f9cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormalParameters(mean=tensor([[45.6545, 52.5808, 59.4680],\n",
       "        [56.3511, 64.7825, 73.1598]]), std=tensor([[0.6913, 0.7524, 0.8631],\n",
       "        [1.7868, 2.0245, 2.2787]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.predict(T_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b248fd-4dad-4418-a229-6e7c04318eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.zeros(T_pred.shape[0] * X.shape[1], dtype=torch.bool)\n",
    "# simulate an observation using sensible numbers from the prediction\n",
    "idx[[0,2]] = torch.tensor([True, True])\n",
    "obs = torch.tensor([42., 61.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03dbc7e-3c5d-4eca-b0b2-5cad6e80677c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0806, 2.4525])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l._normalize_obs(obs, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f682d-b2fb-4a78-8b22-b25847af47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def predict(self: GPFALearner,\n",
    "            T: Tensor, # (n_pred) time where prediction is needed\n",
    "            # (n_obs_pred) Optional - if at the times of the prediction there are some observations\n",
    "            # array with the values of observations to condition distribution\n",
    "            obs: Tensor = None,\n",
    "            # ((n_pred*n_features)) Optional - necessary if obs are present\n",
    "            # Boolean array that is True where an observation is present and False where a prediction is needed\n",
    "            # This is a 1D array with the length equal to n_pred (number time steps to predict) times n_features\n",
    "            idx: Tensor = None\n",
    "           ):\n",
    "    pred_raw = self.predict_raw(T)\n",
    "    \n",
    "    # Conditional observations\n",
    "    if obs is not None and idx is not None:\n",
    "        # observations needs to be normalized before can be used with the raw prediction!\n",
    "        obs_norm = self._normalize_obs(obs, idx)\n",
    "        pred_cond = conditional_guassian(pred_raw, obs_norm, idx)\n",
    "\n",
    "        pred_merge = _merge_raw_cond_pred(pred_raw, pred_cond, obs_norm, idx)\n",
    "    else:\n",
    "        pred_merge = NormParam(pred_raw.mean, pred_raw.stddev)\n",
    "    \n",
    "    return self.prediction_from_raw(pred_merge.mean, pred_merge.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac9235-f902-4a97-bc3d-dd4b271e917f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0806, 2.4525])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l._normalize_obs(obs, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c81fb-daa9-499e-9feb-cc929c7351ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42., 61.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a7c5e-6112-44af-b831-6f936937415b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3537, 2.3606, 2.3626, 3.1533, 3.1626, 3.1653],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.predict_raw(T_pred).mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce783e-bfaa-4eae-8ceb-205f1490f120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormalParameters(mean=tensor([[42.0000, 51.6744, 61.0000],\n",
       "        [54.1866, 62.3160, 70.3888]]), std=tensor([[0.0000, 0.3315, 0.0000],\n",
       "        [0.7656, 0.8412, 0.9601]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.predict(T_pred, obs, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14080b5c-fae8-435c-8a6f-e359511207eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormalParameters(mean=tensor([[45.6545, 52.5808, 59.4680],\n",
       "        [56.3511, 64.7825, 73.1598]]), std=tensor([[0.6913, 0.7524, 0.8631],\n",
       "        [1.7868, 2.0245, 2.2787]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.predict(T_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0787ebc-b4c3-4d8c-8e7b-6266b26ed2a7",
   "metadata": {},
   "source": [
    "There is a small change in the predicted values after conditioning as you would expect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6172add9-1b1a-4f0b-b6b6-9317b65dcf9c",
   "metadata": {},
   "source": [
    "## GPU Support\n",
    "\n",
    "add support for CUDA to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13767083-2ed1-4070-bc76-5592528ddea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l for learner\n",
    "l_cuda = GPFALearner(X.to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd0d3b-bf91-42b2-aa71-54134bcf2c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPFA(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (mean_module): GPFAZeroMean()\n",
       "  (covar_module): GPFAKernel(\n",
       "    (latent_kernel): RBFKernel(\n",
       "      (raw_lengthscale_constraint): Positive()\n",
       "    )\n",
       "    (raw_psi_diag_constraint): Positive()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_cuda.model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d64f5c-3889-4ec3-9faf-cbea9773d3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_cuda.X.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba542b-c4a3-4c63-b807-b2dd46988505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_cuda.T.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e37c5-8f71-45fe-8a59-02d704a789f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_cuda.likelihood = l_cuda.likelihood.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f56dfa-f866-47c2-8035-7e56047121ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_cuda.model =l_cuda.model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ed3e5-159c-46fb-85fa-ab351a153dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/100 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ml_cuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mGPFALearner.train\u001b[0;34m(self, n_iter, lr)\u001b[0m\n\u001b[1;32m     47\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Calc loss and backprop gradients\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mmll\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses[i] \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     51\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/data-science/lib/python3.10/site-packages/gpytorch/module.py:30\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 30\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/anaconda3/envs/data-science/lib/python3.10/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py:62\u001b[0m, in \u001b[0;36mExactMarginalLogLikelihood.forward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Get the log prob of the marginal distribution\u001b[39;00m\n\u001b[1;32m     61\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlikelihood(function_dist, \u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 62\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_other_terms(res, params)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Scale by the amount of data we have\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/data-science/lib/python3.10/site-packages/gpytorch/distributions/multivariate_normal.py:153\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sample(value)\n\u001b[1;32m    152\u001b[0m mean, covar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy_covariance_matrix\n\u001b[0;32m--> 153\u001b[0m diff \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Repeat the covar to match the batch shape of diff\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diff\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m covar\u001b[38;5;241m.\u001b[39mbatch_shape:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "l_cuda.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b97ea7-7a40-4656-8f0d-a645b4b22abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_cuda.predict(T_pred.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c63d38b-aa0e-49c6-b077-ccb92d2a9293",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea3484-f442-43e4-965c-ebb494e3b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.predict(T_pred.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e6d87-368e-4456-86b2-6adf60a8585d",
   "metadata": {},
   "source": [
    "## Printer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe30200-7597-4051-a408-32cc4c40b323",
   "metadata": {},
   "source": [
    "This methods get called at each training iterator to show the progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e4cb0-d021-497b-9dff-a097d5cb1158",
   "metadata": {},
   "source": [
    "we want to extract all the parameters from the model. If there is a contraint tranfrom the parameter to get the correct value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e9bf6-219f-47e0-b284-e85825d17d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def get_parameter_value(name, param, constraint):\n",
    "    if constraint is not None:\n",
    "        value = constraint.transform(param.data.detach())\n",
    "        name = name.replace(\"raw_\", \"\") # parameter is not raw anymore\n",
    "    else:\n",
    "        value = param.data.detach()\n",
    "    return (name, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5e188e-8470-4946-8a38-ad0a0df60c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"covar_module.psi\"\n",
    "test_eq(l.model.covar_module.psi.detach(), get_parameter_value(name, l.model.covar_module.raw_psi_diag, l.model.covar_module.raw_psi_diag_constraint)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92349103-e7cf-4b0f-bbbe-01514d32d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def tensor_to_first_item(tensor):\n",
    "    if tensor.dim() > 0:\n",
    "        return tensor_to_first_item(tensor[0])\n",
    "    return tensor.item()\n",
    "\n",
    "\n",
    "def format_parameter(name, value):\n",
    "    value = tensor_to_first_item(value)\n",
    "    name = name.split(\".\")[-1] # get only last part of name\n",
    "    return f\"{name}: {value:.3f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab63ab0-354a-479a-b27c-e75df7e2cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_formatted_params(self: GPFALearner):\n",
    "    return \", \".join([\n",
    "        format_parameter(*get_parameter_value(name, value, constraint))\n",
    "        for name, value, constraint in\n",
    "        self.model.named_parameters_and_constraints()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f2243e-4934-49ad-aa49-760d8ce02622",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.get_formatted_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a11ce9-80f7-48fa-a6c0-496ab0307ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is not really working at the moment, but it's not important\n",
    "@patch\n",
    "def plot_loss_printer(self: GPFALearner, i_iter):\n",
    "    if i_iter ==0: return\n",
    "    x = torch.arange(0, i_iter)\n",
    "    y = self.losses[:i_iter]\n",
    "    plot_data = [[x, y]]\n",
    "    self.pb.update_graph(plot_data)\n",
    "    \n",
    "    x_bounds = [x.min(), x.max()+1]\n",
    "    y_bounds = [y.min(), y.max()]\n",
    "    self.pb.names = [\"Training loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e81958-97c3-49dd-ba5d-718898e91df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def printer(self: GPFALearner, i_iter):\n",
    "\n",
    "    if i_iter%10 == 0:\n",
    "        update_str = f\"loss: {self.losses[i_iter].item():.3f}, \" + self.get_formatted_params()\n",
    "        #self.plot_loss(i_iter)\n",
    "    \n",
    "    #self.pb.write(update_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ada474-9681-4f2a-9024-a517c285e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.train(lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64935ea1-89df-456a-8c7d-a3037320cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c344f-67f8-49fb-a833-730978420f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58580804-365d-447a-9a5e-3463f4846b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
