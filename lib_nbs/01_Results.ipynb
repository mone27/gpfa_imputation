{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adaed2a0-365d-49de-addd-41da0467bf1c",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "> This handles results of a GPFA/SimpleGP Imputation with plotting and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3332f45-1ef9-47b5-b90e-51a680468540",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0131c374-bcf0-4937-ad82-ad1100cc9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| default_exp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6698446-4653-44e4-b6c2-117fcfbced09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from meteo_imp.gpfa.learner import *\n",
    "from meteo_imp.data_preparation import *\n",
    "from meteo_imp.gpfa.imputation import *\n",
    "from meteo_imp.utils import *\n",
    "\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from fastcore.foundation import patch, patch_to\n",
    "from fastcore.meta import delegates\n",
    "from fastcore.basics import store_attr, listify\n",
    "from fastcore.test import test_close\n",
    "from itertools import zip_longest\n",
    "from fastcore.dispatch import typedispatch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "from altair import datum\n",
    "\n",
    "from typing import Collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b475b2-6129-4de9-84ee-b53abfd6ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ImputationResult:\n",
    "    def __init__(self,\n",
    "                 data_imputed, #imputed data in tidy format\n",
    "                 data_complete, # complete data in tidy format\n",
    "                 model_info, # learner for parameters display\n",
    "                 units = None, # units for plots\n",
    "                 metrics_all_data = True # Compute metrics only for gap or for all data?\n",
    "                ):\n",
    "        store_attr()\n",
    "\n",
    "    def __repr__(self: GPFAImputation):\n",
    "        return f\"\"\"Imputation Result:\n",
    "        N obs: {self.data_imputed.time.unique().shape[0]}\"\"\"\n",
    "\n",
    "    def __str__(self: GPFAImputation):\n",
    "        return self.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49863b-bc7f-4b39-886c-be6dc5e911f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([5, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e2d876-c380-44c3-9d5c-33c15ad8f362",
   "metadata": {},
   "source": [
    "constructor methods from `GPFAImputation` and `GPFAImputationResults`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaaa462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def to_result(self: GPFAImputation, data_complete, units=None):\n",
    "    var_names = self.data.columns\n",
    "    return ImputationResult(self.impute(add_time=True), data_complete, self.learner.model.get_info(var_names), units, metrics_all_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d85ca6e-dcc2-42ce-8c58-0822a7a7bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def to_result(self: GPFAImputationExplorer, data_complete, units=None):\n",
    "    var_names = self.data.columns\n",
    "    return ImputationResult(self.predict(), data_complete, self.learner.model.get_info(var_names), units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da079c4-904d-48b3-81ab-3c5dcc848f84",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreset_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m fd \u001b[38;5;241m=\u001b[39m GPFADataTest\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m10\u001b[39m, Lambda\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2.\u001b[39m])\u001b[38;5;241m.\u001b[39madd_random_missing()\n\u001b[1;32m      4\u001b[0m imp \u001b[38;5;241m=\u001b[39m GPFAImputation(fd\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/Documents/uni/Thesis/GPFA_imputation/meteo_imp/utils.py:50\u001b[0m, in \u001b[0;36mreset_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_seed\u001b[39m(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m27\u001b[39m):\n\u001b[0;32m---> 50\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m     51\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "fd = GPFADataTest.generate(2, 10, Lambda=[1,2.]).add_random_missing()\n",
    "\n",
    "imp = GPFAImputation(fd.data)\n",
    "imp_exp = GPFAImputationExplorer(fd.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c2cd04-7085-410c-bf9e-b9a71749184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82499c-b7dd-4633-a9b7-f3b79f3e3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = imp.to_result(fd.data_compl_tidy, units = {'x0': 'x0 units', 'x1': 'x1 unitssss'})\n",
    "res_exp = imp_exp.to_result(fd.data_compl_tidy, units = {'x0': 'x0 units', 'x1': 'x1 unitssss'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc96d3c6-34b8-4e25-9ef6-2921e573e0dc",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6407fa7e-4509-41b2-aadb-97b97998de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def compute_metric(self: ImputationResult,\n",
    "                   metric,  # function that takes as argument true and pred and returns the metric\n",
    "                   metric_name = 'metric',\n",
    "                   ):\n",
    "    df = pd.merge(self.data_imputed, self.data_complete, on = ['time','variable'])\n",
    "    \n",
    "    vars = []\n",
    "    \n",
    "    for var in df.variable.unique():\n",
    "        mask = (df.variable == var) & (df.is_missing == True) if not self.metrics_all_data else df.variable == var\n",
    "        \n",
    "        df_var = df[mask]\n",
    "        vars.append({'variable': var,\n",
    "                      metric_name: metric(df_var['value'], df_var['mean']) if len(df_var) > 0 else None})\n",
    "    \n",
    "    return pd.DataFrame(vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953623c6-53f6-4048-8161-302b5a65599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def rmse(self: ImputationResult):\n",
    "    rmse = self.compute_metric(lambda x, y: np.sqrt(mean_squared_error(x,y)), \"rmse\")\n",
    "    if self.units: rmse = rmse.assign(units= self.units.values())\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49057b85-67e4-443b-9bdc-03c8de92c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_exp.rmse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f9716-7afe-4bc3-ac4f-da6f49bb4713",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.rmse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff30bbb-bd4c-4b83-a201-540d71eb97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def r2(self: ImputationResult):\n",
    "    return self.compute_metric(r2_score, \"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4322d4ca-70b8-4798-8202-7c75893b74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.r2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acdfe2f-9850-4e71-ad8d-c94f18b24116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def print_metrics(self: ImputationResult):\n",
    "    \n",
    "    old = self.metrics_all_data\n",
    "    \n",
    "    self.metrics_all_data = True\n",
    "    all_met = {\n",
    "    'r2': self.r2(),\n",
    "    'RMSE': self.rmse()\n",
    "    }\n",
    "    \n",
    "    self.metrics_all_data = False\n",
    "    met = {**all_met,\n",
    "    'r2 - Only GAP': self.r2(),\n",
    "    'RMSE - Only GAP': self.rmse()\n",
    "    }\n",
    "    \n",
    "    self.metrics_all_data = old\n",
    "    return met"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad97983-fc93-4015-88f1-2a279c449790",
   "metadata": {},
   "source": [
    "### Prediction plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc8d193-9e21-4f26-9e37-bf4aa7f0bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(pd.DataFrame({'a': [1,2,3]})).mark_tick().encode(x = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf20f0f1-3395-4604-b5eb-2b24a2a35d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _plot_variable(imp, complete, variable, y_label=\"\", sel=None, properties = {}):\n",
    "    \n",
    "    imp = imp[imp.variable == variable]\n",
    "    sel = sel if sel is not None else alt.selection_interval(bind=\"scales\")\n",
    "    \n",
    "    error = alt.Chart(imp).mark_errorband().encode(\n",
    "        x = \"time\",    \n",
    "        y = alt.Y(\"err_low:Q\", title = y_label, scale=alt.Scale(zero=False)),\n",
    "        y2 = \"err_high:Q\",\n",
    "        color=alt.Color(\"variable\",\n",
    "                        legend = alt.Legend(title=[\"Line: pred. mean\", \"area: +/- 2 std\", \"(variable)\"])\n",
    "                       ),\n",
    "        tooltip = alt.Tooltip(['std', 'mean'], format=\".4\")\n",
    "    ).transform_calculate(\n",
    "        err_low = \"datum.mean - 2 * datum.std\",\n",
    "        err_high = \"datum.mean + 2 * datum.std\"\n",
    "    ).properties( **properties)\n",
    "\n",
    "    pred = alt.Chart(imp).mark_line().encode(\n",
    "        x = \"time\",    \n",
    "        y = alt.Y(\"mean:Q\", title = y_label, scale=alt.Scale(zero=False)),\n",
    "        color=\"variable\",\n",
    "    ).add_selection(\n",
    "        sel\n",
    "    ).properties(title = variable)\n",
    "\n",
    "    base_plot = error + pred\n",
    "    \n",
    "    if complete is not None:\n",
    "\n",
    "        complete = complete[complete.variable == variable]\n",
    "        truth_plt = alt.Chart(complete).mark_point(\n",
    "            color='black',\n",
    "            strokeWidth = 1,\n",
    "            fillOpacity = 1\n",
    "        ).encode(\n",
    "            x = alt.X(\"time\", axis=alt.Axis(domain=False, labels = False, ticks=False, title=None)),\n",
    "            y = alt.Y(\"value\", title = y_label, scale=alt.Scale(zero=False)),\n",
    "            fill= alt.Fill(\"is_missing\", scale = alt.Scale(range=[\"#ffffff00\", \"black\"]),\n",
    "                           legend = alt.Legend(title =[\"Observed data\",\"(is missing)\"])),\n",
    "            shape = \"is_missing\",\n",
    "        )\n",
    "       \n",
    "        p = {'width': properties['width']} if properties else {}\n",
    "        missing = alt.Chart(complete).mark_tick(\n",
    "            color='black',\n",
    "        ).encode(\n",
    "            x = \"time\",\n",
    "            color = alt.condition(datum.is_missing, alt.value('black'), alt.value('white'))\n",
    "        ).add_selection(\n",
    "            sel\n",
    "        ).properties(**p)\n",
    "\n",
    "        base_plot = alt.VConcatChart(vconcat=[(truth_plt + base_plot), missing], spacing=-10)\n",
    "        \n",
    "    return base_plot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4c22c-a984-4ba8-a65f-c08c13887082",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_d = imp.impute(tidy=True, add_time=True)\n",
    "\n",
    "_plot_variable(imp_d, None, \"x1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d2c42e-445b-45b6-a66a-846223155c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch()\n",
    "def plot_pred(\n",
    "    self: ImputationResult,\n",
    "    n_cols: int = 2,\n",
    "    bind_interaction: bool =True, # Whether the sub-plots for each variable should be connected for zooming/panning\n",
    "    properties:dict = {} # additional properties (eg. size) for altair plot\n",
    "):\n",
    "    \"Plot the prediction for each variable\"\n",
    "   \n",
    "    plot_list = [alt.hconcat() for _ in range(0, self.data_imputed.shape[0], n_cols)]\n",
    "    selection_scale = alt.selection_interval(bind=\"scales\", encodings=['x']) if bind_interaction else None\n",
    "    for idx, variable in enumerate(pd.unique(self.data_imputed.variable)):\n",
    "        plot_list[idx // n_cols] |= _plot_variable(self.data_imputed,\n",
    "                                                   self.data_complete,\n",
    "                                                   variable,\n",
    "                                                   y_label = f\"{variable} [{self.units[variable]}]\" if self.units is not None else variable,\n",
    "                                                   sel = selection_scale, properties=properties)\n",
    "    \n",
    "    plot = alt.vconcat(*plot_list)\n",
    "    \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b44233-d20e-4c22-ab17-1fe293eeeae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.plot_pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6efc3d-936c-4eff-80da-42e63602831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.plot_pred(bind_interaction=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b93bb0-d7ed-406c-9a2d-5ec869949239",
   "metadata": {},
   "source": [
    "    The code is running correctly and as expected around the missing data point the error is band is wider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bee157-cac9-4535-a6b4-5b0301e470f0",
   "metadata": {},
   "source": [
    "### Display results\n",
    "\n",
    "show the prediction plot, metrics and model parameters in one convinient view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ec40b7-5a54-4735-abd0-80ddcc3f4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from IPython.display import HTML\n",
    "\n",
    "from ipywidgets import HBox, VBox, interact, widgets\n",
    "from ipywidgets.widgets import Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e87e6b1-e578-4bcf-ad8f-dcf0fdcd6f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _style_df(df):\n",
    "    \"\"\"style dataframe for better printing \"\"\"\n",
    "    return df.style.hide(axis=\"index\").format(precision = 4)\n",
    "\n",
    "def _display_as_row(dfs: dict[str, pd.DataFrame], title=\"\", styler=_style_df):\n",
    "    \"\"\"display multiple dataframes in the same row\"\"\"\n",
    "    out = []\n",
    "    for df_title, df in dfs.items():\n",
    "        df_html = _style_df(df).to_html()\n",
    "        out.append(f\"<div> <p style='font-size: 1.3rem;'>{df_title}</p> {df_html} </div>\")\n",
    "    out = f\"<div style=\\\"display: flex; column-gap: 20px; flex-wrap: wrap;\\\" class='table table-striped table-sm'> {''.join(out)}</div>\"\n",
    "    display(HTML(f\"<p style='font-size: 1.5rem; font-decoration: bold'>{title}<p>\" + \"\".join(out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e86659-4191-4957-8750-9a6b54000b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = HTML(pd.DataFrame([1,2]).to_html(notebook=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a00c89-d6d5-408a-8db4-bd6926c01df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_as_row({\"test\": pd.DataFrame([1,2])}, \"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac98e21-d4eb-4f43-a9a0-98b8e4ff35e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_as_row({f\"test{i}\": pd.DataFrame([1,2]) for i in range(10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7922863-e41b-436e-a284-2803d9cfd96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch \n",
    "def display_results(self: ImputationResult, plot_args={}):\n",
    "    \n",
    "    plot_args = {'properties': {'height': 200 , 'width': 350}, **plot_args} # set default plot size\n",
    "    plot = self.plot_pred(**plot_args)\n",
    "    \n",
    "    display(plot)    \n",
    "    _display_as_row(self.print_metrics(), \"Metrics\")\n",
    "    _display_as_row(self.model_info, \"Model Info\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd4bdb2-8237-49aa-accb-ba24492a24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d965f2-f295-4b43-8013-5adb773f4aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9c4aa-4926-45e4-bbc0-4ba2a042af8c",
   "metadata": {},
   "source": [
    "## Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47bac6-1bac-4b5d-a880-7ddfe17cca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
