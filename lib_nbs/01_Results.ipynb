{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adaed2a0-365d-49de-addd-41da0467bf1c",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "> This handles results of a GPFA/SimpleGP Imputation with plotting and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3332f45-1ef9-47b5-b90e-51a680468540",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0131c374-bcf0-4937-ad82-ad1100cc9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| default_exp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6698446-4653-44e4-b6c2-117fcfbced09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from meteo_imp.gpfa.learner import *\n",
    "from meteo_imp.data_preparation import *\n",
    "from meteo_imp.gpfa.imputation import *\n",
    "from meteo_imp.utils import *\n",
    "\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from fastcore.foundation import patch, patch_to\n",
    "from fastcore.meta import delegates\n",
    "from fastcore.basics import store_attr, listify\n",
    "from fastcore.test import test_close\n",
    "from itertools import zip_longest\n",
    "from fastcore.dispatch import typedispatch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "from altair import datum\n",
    "\n",
    "from typing import Collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b475b2-6129-4de9-84ee-b53abfd6ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ImputationResult:\n",
    "    def __init__(self,\n",
    "                 data_imputed, #imputed data in tidy format\n",
    "                 data_complete, # complete data in tidy format\n",
    "                 model_info, # learner for parameters display\n",
    "                 units = None, # units for plots\n",
    "                 metrics_all_data = True # Compute metrics only for gap or for all data?\n",
    "                ):\n",
    "        store_attr()\n",
    "\n",
    "    def __repr__(self: GPFAImputation):\n",
    "        return f\"\"\"Imputation Result:\n",
    "        N obs: {self.data_imputed.time.unique().shape[0]}\"\"\"\n",
    "\n",
    "    def __str__(self: GPFAImputation):\n",
    "        return self.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49863b-bc7f-4b39-886c-be6dc5e911f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([5, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e2d876-c380-44c3-9d5c-33c15ad8f362",
   "metadata": {},
   "source": [
    "constructor methods from `GPFAImputation` and `GPFAImputationResults`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaaa462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def to_result(self: GPFAImputation, data_complete, units=None):\n",
    "    var_names = self.data.columns\n",
    "    return ImputationResult(self.impute(add_time=True), data_complete, self.learner.model.get_info(var_names), units, metrics_all_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d85ca6e-dcc2-42ce-8c58-0822a7a7bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def to_result(self: GPFAImputationExplorer, data_complete, units=None):\n",
    "    var_names = self.data.columns\n",
    "    return ImputationResult(self.predict(), data_complete, self.learner.model.get_info(var_names), units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da079c4-904d-48b3-81ab-3c5dcc848f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "fd = MeteoDataTest.generate_gpfa(2, 10, Lambda=[1,2.]).add_random_missing()\n",
    "\n",
    "imp = GPFAImputation(fd.data)\n",
    "imp_exp = GPFAImputationExplorer(fd.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c2cd04-7085-410c-bf9e-b9a71749184e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352996</td>\n",
       "      <td>0.013275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.248802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.264305</td>\n",
       "      <td>-0.657965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.248825</td>\n",
       "      <td>0.822856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.896081</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.773089</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.841634</td>\n",
       "      <td>-1.945134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.269603</td>\n",
       "      <td>2.074223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1\n",
       "0  0.352996  0.013275\n",
       "1       NaN  0.248802\n",
       "2 -0.264305 -0.657965\n",
       "3  0.248825  0.822856\n",
       "4 -0.896081       NaN\n",
       "5  0.773089       NaN\n",
       "6       NaN       NaN\n",
       "7       NaN       NaN\n",
       "8 -0.841634 -1.945134\n",
       "9  1.269603  2.074223"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82499c-b7dd-4633-a9b7-f3b79f3e3fc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StandardScaler' object has no attribute 'reverse_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mimp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_compl_tidy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx0 units\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx1 unitssss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m res_exp \u001b[38;5;241m=\u001b[39m imp_exp\u001b[38;5;241m.\u001b[39mto_result(fd\u001b[38;5;241m.\u001b[39mdata_compl_tidy, units \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx0\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx0 units\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx1 unitssss\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mto_result\u001b[0;34m(self, data_complete, units)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;129m@patch\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_result\u001b[39m(\u001b[38;5;28mself\u001b[39m: GPFAImputation, data_complete, units\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m     var_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ImputationResult(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpute\u001b[49m\u001b[43m(\u001b[49m\u001b[43madd_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m, data_complete, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearner\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_info(var_names), units, metrics_all_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/uni/Thesis/GPFA_imputation/meteo_imp/gpfa/imputation.py:70\u001b[0m, in \u001b[0;36mGPFAImputation.impute\u001b[0;34m(self, add_time, tidy)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimpute\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     66\u001b[0m            add_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# add column with time?\u001b[39;00m\n\u001b[1;32m     67\u001b[0m            tidy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# tidy data?\u001b[39;00m\n\u001b[1;32m     68\u001b[0m            ):\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred_T\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[0;32m~/Documents/uni/Thesis/GPFA_imputation/meteo_imp/gpfa/learner.py:198\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(self, T, obs, idx)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     pred_merge \u001b[38;5;241m=\u001b[39m NormParam(pred_raw\u001b[38;5;241m.\u001b[39mmean, pred_raw\u001b[38;5;241m.\u001b[39mstddev)\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_from_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_merge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_merge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/uni/Thesis/GPFA_imputation/meteo_imp/gpfa/learner.py:113\u001b[0m, in \u001b[0;36mprediction_from_raw\u001b[0;34m(self, raw_mean, raw_std)\u001b[0m\n\u001b[1;32m    110\u001b[0m raw_std \u001b[38;5;241m=\u001b[39m raw_std\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features)\n\u001b[1;32m    111\u001b[0m raw_mean \u001b[38;5;241m=\u001b[39m raw_mean\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features)\n\u001b[0;32m--> 113\u001b[0m pred_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreverse_transform\u001b[49m(raw_mean)\n\u001b[1;32m    114\u001b[0m pred_std \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39mreverse_transform_std(raw_std)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m#remove pytorch gradients\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StandardScaler' object has no attribute 'reverse_transform'"
     ]
    }
   ],
   "source": [
    "res = imp.to_result(fd.data_compl_tidy, units = {'x0': 'x0 units', 'x1': 'x1 unitssss'})\n",
    "res_exp = imp_exp.to_result(fd.data_compl_tidy, units = {'x0': 'x0 units', 'x1': 'x1 unitssss'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc96d3c6-34b8-4e25-9ef6-2921e573e0dc",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6407fa7e-4509-41b2-aadb-97b97998de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def compute_metric(self: ImputationResult,\n",
    "                   metric,  # function that takes as argument true and pred and returns the metric\n",
    "                   metric_name = 'metric',\n",
    "                   ):\n",
    "    df = pd.merge(self.data_imputed, self.data_complete, on = ['time','variable'])\n",
    "    \n",
    "    vars = []\n",
    "    \n",
    "    for var in df.variable.unique():\n",
    "        mask = (df.variable == var) & (df.is_missing == True) if not self.metrics_all_data else df.variable == var\n",
    "        \n",
    "        df_var = df[mask]\n",
    "        vars.append({'variable': var,\n",
    "                      metric_name: metric(df_var['value'], df_var['mean']) if len(df_var) > 0 else None})\n",
    "    \n",
    "    return pd.DataFrame(vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953623c6-53f6-4048-8161-302b5a65599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def rmse(self: ImputationResult):\n",
    "    rmse = self.compute_metric(lambda x, y: np.sqrt(mean_squared_error(x,y)), \"rmse\")\n",
    "    if self.units: rmse = rmse.assign(units= self.units.values())\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49057b85-67e4-443b-9bdc-03c8de92c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_exp.rmse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f9716-7afe-4bc3-ac4f-da6f49bb4713",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.rmse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff30bbb-bd4c-4b83-a201-540d71eb97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def r2(self: ImputationResult):\n",
    "    return self.compute_metric(r2_score, \"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4322d4ca-70b8-4798-8202-7c75893b74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.r2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acdfe2f-9850-4e71-ad8d-c94f18b24116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def print_metrics(self: ImputationResult):\n",
    "    \n",
    "    old = self.metrics_all_data\n",
    "    \n",
    "    self.metrics_all_data = True\n",
    "    all_met = {\n",
    "    'r2': self.r2(),\n",
    "    'RMSE': self.rmse()\n",
    "    }\n",
    "    \n",
    "    self.metrics_all_data = False\n",
    "    met = {**all_met,\n",
    "    'r2 - Only GAP': self.r2(),\n",
    "    'RMSE - Only GAP': self.rmse()\n",
    "    }\n",
    "    \n",
    "    self.metrics_all_data = old\n",
    "    return met"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad97983-fc93-4015-88f1-2a279c449790",
   "metadata": {},
   "source": [
    "### Prediction plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc8d193-9e21-4f26-9e37-bf4aa7f0bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(pd.DataFrame({'a': [1,2,3]})).mark_tick().encode(x = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6426babd-b5ab-42e6-b78b-8b40d363cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _plot_error_bar(data, variable, y_label, properties, sel):\n",
    "    \n",
    "    error = alt.Chart(data).mark_errorband().encode(\n",
    "        x = \"time\",    \n",
    "        y = alt.Y(\"err_low:Q\", title = y_label, scale=alt.Scale(zero=False)),\n",
    "        y2 = \"err_high:Q\",\n",
    "        color=alt.Color(\"variable\",\n",
    "                        legend = alt.Legend(title=[\"Line: pred. mean\", \"area: +/- 2 std\", \"(variable)\"])\n",
    "                       ),\n",
    "        tooltip = alt.Tooltip(['std', 'mean'], format=\".4\")\n",
    "    ).transform_calculate(\n",
    "        err_low = \"datum.mean - 2 * datum.std\",\n",
    "        err_high = \"datum.mean + 2 * datum.std\"\n",
    "    ).properties( **properties)\n",
    "\n",
    "    mean = alt.Chart(data).mark_line().encode(\n",
    "        x = \"time\",    \n",
    "        y = alt.Y(\"mean:Q\", title = y_label, scale=alt.Scale(zero=False)),\n",
    "        color=\"variable\",\n",
    "    ).add_selection(\n",
    "        sel\n",
    "    ).properties(title = variable)\n",
    "\n",
    "    return error + mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf20f0f1-3395-4604-b5eb-2b24a2a35d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _plot_variable(imp, complete, variable, y_label=\"\", sel=None, properties = {}):\n",
    "    \n",
    "    imp = imp[imp.variable == variable]\n",
    "    sel = sel if sel is not None else alt.selection_interval(bind=\"scales\")\n",
    "    \n",
    "    base_plot = _plot_error_bar(imp, variable, y_label, properties, sel)\n",
    "        \n",
    "    if complete is not None:\n",
    "\n",
    "        complete = complete[complete.variable == variable]\n",
    "        truth_plt = alt.Chart(complete).mark_point(\n",
    "            color='black',\n",
    "            strokeWidth = 1,\n",
    "            fillOpacity = 1\n",
    "        ).encode(\n",
    "            x = alt.X(\"time\", axis=alt.Axis(domain=False, labels = False, ticks=False, title=None)),\n",
    "            y = alt.Y(\"value\", title = y_label, scale=alt.Scale(zero=False)),\n",
    "            fill= alt.Fill(\"is_missing\", scale = alt.Scale(range=[\"#ffffff00\", \"black\"]),\n",
    "                           legend = alt.Legend(title =[\"Observed data\",\"(is missing)\"])),\n",
    "            shape = \"is_missing\",\n",
    "        )\n",
    "       \n",
    "        p = {'width': properties['width']} if properties else {}\n",
    "        missing = alt.Chart(complete).mark_tick(\n",
    "            color='black',\n",
    "        ).encode(\n",
    "            x = \"time\",\n",
    "            color = alt.condition(datum.is_missing, alt.value('black'), alt.value('white'))\n",
    "        ).add_selection(\n",
    "            sel\n",
    "        ).properties(**p)\n",
    "\n",
    "        base_plot = alt.VConcatChart(vconcat=[(truth_plt + base_plot), missing], spacing=-10)\n",
    "        \n",
    "    return base_plot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4c22c-a984-4ba8-a65f-c08c13887082",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_d = imp.impute(tidy=True, add_time=True)\n",
    "\n",
    "_plot_variable(imp_d, None, \"x1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d2c42e-445b-45b6-a66a-846223155c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch()\n",
    "def plot_pred(\n",
    "    self: ImputationResult,\n",
    "    n_cols: int = 2,\n",
    "    bind_interaction: bool =True, # Whether the sub-plots for each variable should be connected for zooming/panning\n",
    "    properties:dict = {} # additional properties (eg. size) for altair plot\n",
    "):\n",
    "    \"Plot the prediction for each variable\"\n",
    "   \n",
    "    plot_list = [alt.hconcat() for _ in range(0, self.data_imputed.shape[0], n_cols)]\n",
    "    selection_scale = alt.selection_interval(bind=\"scales\", encodings=['x']) if bind_interaction else None\n",
    "    for idx, variable in enumerate(pd.unique(self.data_imputed.variable)):\n",
    "        plot_list[idx // n_cols] |= _plot_variable(self.data_imputed,\n",
    "                                                   self.data_complete,\n",
    "                                                   variable,\n",
    "                                                   y_label = f\"{variable} [{self.units[variable]}]\" if self.units is not None else variable,\n",
    "                                                   sel = selection_scale, properties=properties)\n",
    "    \n",
    "    plot = alt.vconcat(*plot_list)\n",
    "    \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b44233-d20e-4c22-ab17-1fe293eeeae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.plot_pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6efc3d-936c-4eff-80da-42e63602831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.plot_pred(bind_interaction=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b93bb0-d7ed-406c-9a2d-5ec869949239",
   "metadata": {},
   "source": [
    "The code is running correctly and as expected around the missing data point the error is band is wider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bee157-cac9-4535-a6b4-5b0301e470f0",
   "metadata": {},
   "source": [
    "### Display results\n",
    "\n",
    "show the prediction plot, metrics and model parameters in one convinient view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7922863-e41b-436e-a284-2803d9cfd96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch \n",
    "def display_results(self: ImputationResult, plot_args={}):\n",
    "    \n",
    "    plot_args = {'properties': {'height': 200 , 'width': 350}, **plot_args} # set default plot size\n",
    "    plot = self.plot_pred(**plot_args)\n",
    "    \n",
    "    display(plot)    \n",
    "    display_as_row(self.print_metrics(), \"Metrics\")\n",
    "    display_as_row(self.model_info, \"Model Info\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd4bdb2-8237-49aa-accb-ba24492a24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d965f2-f295-4b43-8013-5adb773f4aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9c4aa-4926-45e4-bbc0-4ba2a042af8c",
   "metadata": {},
   "source": [
    "## Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47bac6-1bac-4b5d-a880-7ddfe17cca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
