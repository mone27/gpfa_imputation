{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910de00b-dedd-4710-b53d-b891eeab7c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| default_exp simple_gp_imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6fca7-ccd7-4af6-b817-e4e2c77515d6",
   "metadata": {},
   "source": [
    "# Simple GP Imputation\n",
    "\n",
    "> Imputation using simple Gaussian Processes (1 per variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3116f056-2ce3-44c4-b665-a7620eca76eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpfa_imputation.data_preparation import Normalizer\n",
    "from gpfa_imputation.learner import NormParam\n",
    "import gpytorch\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f34fb-9f5e-43f4-8094-a2ecf15840b5",
   "metadata": {},
   "source": [
    "## GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc14e6-c6d8-4fbc-9672-51fb06f7bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SimpleGP(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x, **params):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x, **params)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87517080-2248-4f2c-9b57-5a12c67659df",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa11e43-c06c-4823-a2cc-48e8935c693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SimpleGPLearner():\n",
    "    def __init__(self,\n",
    "                 X: Tensor, # (n_features * n_obs) Multivariate time series\n",
    "                 T: Tensor = None, # (n_obs) Vector of time of observations.\n",
    "                 # If none each observation are considered to be at the same distance\n",
    "                 latent_dims: int = 1 # Number of latent variables in GPFA\n",
    "                ):\n",
    "        self.prepare_X(X)\n",
    "        if T is None: self.default_time(X)\n",
    "        else: self.T = T\n",
    "        self.T = self.T.to(X.device) # to support GPUs\n",
    "        \n",
    "        self.likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        self.model = SimpleGP(self.T, self.X, self.likelihood)\n",
    "                \n",
    "    @torch.no_grad()\n",
    "    def prepare_X(self, X):\n",
    "        self.norm = Normalizer(X)\n",
    "        self.X = self.norm.normalize(X)\n",
    "        \n",
    "    def default_time(self, X):\n",
    "        self.T = torch.arange(X.shape[0])\n",
    "        \n",
    "    \n",
    "    def train(self, n_iter=100, lr=0.1):\n",
    "        # need to enable training mode\n",
    "        self.model.train()\n",
    "        self.likelihood.train()\n",
    "        \n",
    "        # Use the adam optimizer\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr) \n",
    "        \n",
    "        self.losses = torch.zeros(n_iter)\n",
    "        # \"Loss\" for GPs - the marginal log likelihood\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self.model)\n",
    "        for i in tqdm(range(n_iter)):\n",
    "            # Zero gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "            # Output from model\n",
    "            output = self.model(self.T)\n",
    "            # Calc loss and backprop gradients\n",
    "            loss = -mll(output, self.X)\n",
    "            self.losses[i] = loss.detach()\n",
    "            loss.backward()\n",
    "            self.printer(i)\n",
    "\n",
    "            optimizer.step()\n",
    "        \n",
    "        \n",
    "    def printer(self, i):\n",
    "        pass\n",
    "    \n",
    "    @torch.no_grad() # don't calc gradients on predictions\n",
    "    def predict_raw(self, T):\n",
    "        self.model.eval()\n",
    "        self.likelihood.eval()\n",
    "        return self.likelihood(self.model(T))\n",
    "\n",
    "    @torch.no_grad() # needed because raw output still has gradients attached\n",
    "    def prediction_from_raw(self, raw_mean, raw_std):\n",
    "        \"\"\" Takes a raw prediction and produces and final prediction, by reshaping and reversing normalization\"\"\"\n",
    "        pred_mean = self.norm.reverse_normalize(raw_mean)\n",
    "        pred_std = self.norm.reverse_normalize_std(raw_std)\n",
    "\n",
    "        #remove pytorch gradients\n",
    "        return NormParam(pred_mean.detach(), pred_std.detach())\n",
    "\n",
    "    def predict(self, T):\n",
    "        pred_raw = self.predict_raw(T)\n",
    "        return self.prediction_from_raw(pred_raw.mean, pred_raw.stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec8725-5ff2-4f75-b300-bb17a71c176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([1.,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f77c94-4fa9-4094-99b3-720656972212",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = SimpleGPLearner(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7dfc04-5902-4e8e-ba2c-21d283e650b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258780dedfc34c1b9f114dc59fbc992f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/anaconda3/envs/data-science/lib/python3.10/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:136: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2183.)\n",
      "  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n"
     ]
    }
   ],
   "source": [
    "l.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aa6252-cd22-497a-8e79-c3cb04d38e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormalParameters(mean=tensor([5.5955]), std=tensor([0.1980]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.predict(torch.tensor([5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83303db-b94c-4438-801d-7d5cb9688ae7",
   "metadata": {},
   "source": [
    "Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddb4544-86b9-495f-b262-f6c390c53106",
   "metadata": {},
   "source": [
    "        self.models = []\n",
    "        self.likelihoods = []\n",
    "        \n",
    "        for i in range(X.shape[1]):\n",
    "            self.make_var_model(i)\n",
    "        \n",
    "    def make_var_model(self, i):\n",
    "        x = self.X[i]\n",
    "        lihelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        model = SimpleGP(self.T, x, likelihood)\n",
    "        self.models.append(model)\n",
    "        self.likelihoods.append(likelihood)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
