[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GPFA Imputation Analysis",
    "section": "",
    "text": "GPFA Imputation\nThis is the homepage of the website that contains all the analysis. Use the sidebar for nagivation"
  },
  {
    "objectID": "extract_gap_all_fluxnet.html",
    "href": "extract_gap_all_fluxnet.html",
    "title": "GPFA Imputation Analysis",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\n\n\nfrom gpfa_imputation.gap_finder import *\n\nlinks are obtained from this https://fluxnet.org/data-and-manifest/ page(requires login) by running in the browser console this code\nvar x = document.querySelectorAll(\"a\");\nvar myarray = []\nfor (var i=0; i<x.length; i++){\nvar nametext = x[i].textContent;\nvar cleantext = nametext.replace(/\\s+/g, ' ').trim();\nvar cleanlink = x[i].href;\nmyarray.push([cleantext,cleanlink]);\n};\nfunction make_table() {\n    var table = '<table><thead><th>Links</th></thead><tbody>';\n   for (var i=0; i<myarray.length; i++) {\n            table += '<tr><td>'+myarray[i][1]+'</td></tr>';\n    };\n \n    var w = window.open(\"\");\nw.document.write(table); \n}\nmake_table()\ncode inspired from https://towardsdatascience.com/quickly-extract-all-links-from-a-web-page-using-javascript-and-the-browser-console-49bb6f48127b\nand then doing some smart copy pasting\nacually download in parallel all files with, so is faster than download with python\nparallel -a fluxnet_parallel_wget.txt --jobs 10 wget\n\nfrom fluxnet_links import all_fluxnet_link\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\n\n\ntest_file = Path(\"../../fluxnet/FLX_DE-Hai_FLUXNET2015_FULLSET_2000-2012_1-4.zip\")\ntmp_dir = Path(\"/tmp\")\nout_dir = Path(\"../../fluxnet/gap_stat\")\ndownload_dir = Path(\"/run/media/simone/Simone DATI/fluxnet_all\")\n\n\nsite_info = download_and_find_gaps(all_fluxnet_link, download_dir, out_dir, tmp_dir)\n\n\n\n\nFLX_AR-SLu_FLUXNET2015_FULLSET_HH_2009-2011_1-4\nFLX_AR-Vir_FLUXNET2015_FULLSET_HH_2009-2012_1-4\nFLX_AT-Neu_FLUXNET2015_FULLSET_HH_2002-2012_1-4\nFLX_AU-Ade_FLUXNET2015_FULLSET_HH_2007-2009_1-4\nFLX_AU-ASM_FLUXNET2015_FULLSET_HH_2010-2014_2-4\nFLX_AU-Cpr_FLUXNET2015_FULLSET_HH_2010-2014_2-4\nFLX_AU-Cum_FLUXNET2015_FULLSET_HH_2012-2014_2-4\nFLX_AU-DaP_FLUXNET2015_FULLSET_HH_2007-2013_2-4\nFLX_AU-DaS_FLUXNET2015_FULLSET_HH_2008-2014_2-4\nFLX_AU-Dry_FLUXNET2015_FULLSET_HH_2008-2014_2-4\nFLX_AU-Emr_FLUXNET2015_FULLSET_HH_2011-2013_1-4\nFLX_AU-Fog_FLUXNET2015_FULLSET_HH_2006-2008_1-4\nFLX_AU-Gin_FLUXNET2015_FULLSET_HH_2011-2014_1-4\nFLX_AU-GWW_FLUXNET2015_FULLSET_HH_2013-2014_1-4\nFLX_AU-How_FLUXNET2015_FULLSET_HH_2001-2014_1-4\nFLX_AU-Lox_FLUXNET2015_FULLSET_HH_2008-2009_1-4\nFLX_AU-RDF_FLUXNET2015_FULLSET_HH_2011-2013_1-4\nFLX_AU-Rig_FLUXNET2015_FULLSET_HH_2011-2014_2-4\nFLX_AU-Rob_FLUXNET2015_FULLSET_HH_2014-2014_1-4\nFLX_AU-Stp_FLUXNET2015_FULLSET_HH_2008-2014_1-4\nFLX_AU-TTE_FLUXNET2015_FULLSET_HH_2012-2014_1-4\nFLX_AU-Tum_FLUXNET2015_FULLSET_HR_2001-2014_2-4\nFLX_AU-Wac_FLUXNET2015_FULLSET_HH_2005-2008_1-4\nFLX_AU-Whr_FLUXNET2015_FULLSET_HH_2011-2014_2-4\nFLX_AU-Wom_FLUXNET2015_FULLSET_HH_2010-2014_1-4\nFLX_AU-Ync_FLUXNET2015_FULLSET_HH_2012-2014_1-4\nFLX_BE-Bra_FLUXNET2015_FULLSET_HH_1996-2014_2-4\nFLX_BE-Lon_FLUXNET2015_FULLSET_HH_2004-2014_1-4\nFLX_BE-Vie_FLUXNET2015_FULLSET_HH_1996-2014_1-4\nFLX_BR-Sa1_FLUXNET2015_FULLSET_HR_2002-2011_1-4\nFLX_BR-Sa3_FLUXNET2015_FULLSET_HH_2000-2004_1-4\nFLX_CA-Gro_FLUXNET2015_FULLSET_HH_2003-2014_1-4\nFLX_CA-Man_FLUXNET2015_FULLSET_HH_1994-2008_1-4\nFLX_CA-NS1_FLUXNET2015_FULLSET_HH_2001-2005_2-4\nFLX_CA-NS2_FLUXNET2015_FULLSET_HH_2001-2005_1-4\nFLX_CA-NS3_FLUXNET2015_FULLSET_HH_2001-2005_1-4\nFLX_CA-NS4_FLUXNET2015_FULLSET_HH_2002-2005_1-4\nFLX_CA-NS5_FLUXNET2015_FULLSET_HH_2001-2005_1-4\nFLX_CA-NS6_FLUXNET2015_FULLSET_HH_2001-2005_1-4\nFLX_CA-NS7_FLUXNET2015_FULLSET_HH_2002-2005_1-4\nFLX_CA-Oas_FLUXNET2015_FULLSET_HH_1996-2010_1-4\nFLX_CA-Obs_FLUXNET2015_FULLSET_HH_1997-2010_1-4\nFLX_CA-Qfo_FLUXNET2015_FULLSET_HH_2003-2010_1-4\nFLX_CA-SF1_FLUXNET2015_FULLSET_HH_2003-2006_1-4\nFLX_CA-SF2_FLUXNET2015_FULLSET_HH_2001-2005_1-4\nFLX_CA-SF3_FLUXNET2015_FULLSET_HH_2001-2006_1-4\nFLX_CA-TP1_FLUXNET2015_FULLSET_HH_2002-2014_2-4\nFLX_CA-TP2_FLUXNET2015_FULLSET_HH_2002-2007_1-4\nFLX_CA-TP3_FLUXNET2015_FULLSET_HH_2002-2014_1-4\nFLX_CA-TP4_FLUXNET2015_FULLSET_HH_2002-2014_1-4\nFLX_CA-TPD_FLUXNET2015_FULLSET_HH_2012-2014_1-4\nFLX_CG-Tch_FLUXNET2015_FULLSET_HH_2006-2009_1-4\nFLX_CH-Cha_FLUXNET2015_FULLSET_HH_2005-2014_2-4\nFLX_CH-Dav_FLUXNET2015_FULLSET_HH_1997-2014_1-4\nFLX_CH-Fru_FLUXNET2015_FULLSET_HH_2005-2014_2-4\nFLX_CH-Lae_FLUXNET2015_FULLSET_HH_2004-2014_1-4\nFLX_CH-Oe1_FLUXNET2015_FULLSET_HH_2002-2008_2-4\nFLX_CH-Oe2_FLUXNET2015_FULLSET_HH_2004-2014_1-4\nFLX_CN-Cha_FLUXNET2015_FULLSET_HH_2003-2005_1-4\nFLX_CN-Cng_FLUXNET2015_FULLSET_HH_2007-2010_1-4\nFLX_CN-Dan_FLUXNET2015_FULLSET_HH_2004-2005_1-4\nFLX_CN-Din_FLUXNET2015_FULLSET_HH_2003-2005_1-4\nFLX_CN-Du2_FLUXNET2015_FULLSET_HH_2006-2008_1-4\nFLX_CN-Du3_FLUXNET2015_FULLSET_HH_2009-2010_1-4\nFLX_CN-Ha2_FLUXNET2015_FULLSET_HH_2003-2005_1-4\nFLX_CN-HaM_FLUXNET2015_FULLSET_HH_2002-2004_1-4\nFLX_CN-Qia_FLUXNET2015_FULLSET_HH_2003-2005_1-4\nFLX_CN-Sw2_FLUXNET2015_FULLSET_HH_2010-2012_1-4\nFLX_CZ-BK1_FLUXNET2015_FULLSET_HH_2004-2014_2-4\nFLX_CZ-BK2_FLUXNET2015_FULLSET_HH_2004-2012_2-4\nFLX_CZ-wet_FLUXNET2015_FULLSET_HH_2006-2014_1-4\nFLX_DE-Akm_FLUXNET2015_FULLSET_HH_2009-2014_1-4\nFLX_DE-Geb_FLUXNET2015_FULLSET_HH_2001-2014_1-4\nFLX_DE-Gri_FLUXNET2015_FULLSET_HH_2004-2014_1-4\nFLX_DE-Hai_FLUXNET2015_FULLSET_HH_2000-2012_1-4\nFLX_DE-Kli_FLUXNET2015_FULLSET_HH_2004-2014_1-4\nFLX_DE-Lkb_FLUXNET2015_FULLSET_HH_2009-2013_1-4\nFLX_DE-Lnf_FLUXNET2015_FULLSET_HH_2002-2012_1-4\nFLX_DE-Obe_FLUXNET2015_FULLSET_HH_2008-2014_1-4\nFLX_DE-RuR_FLUXNET2015_FULLSET_HH_2011-2014_1-4\nFLX_DE-RuS_FLUXNET2015_FULLSET_HH_2011-2014_1-4\nFLX_DE-Seh_FLUXNET2015_FULLSET_HH_2007-2010_1-4\nFLX_DE-SfN_FLUXNET2015_FULLSET_HH_2012-2014_1-4\nFLX_DE-Spw_FLUXNET2015_FULLSET_HH_2010-2014_1-4\nFLX_DE-Tha_FLUXNET2015_FULLSET_HH_1996-2014_1-4\nFLX_DE-Zrk_FLUXNET2015_FULLSET_HH_2013-2014_2-4\nFLX_DK-Eng_FLUXNET2015_FULLSET_HH_2005-2008_1-4\nFLX_DK-Fou_FLUXNET2015_FULLSET_HH_2005-2005_1-4\nFLX_DK-Sor_FLUXNET2015_FULLSET_HH_1996-2014_2-4\nFLX_ES-Amo_FLUXNET2015_FULLSET_HH_2007-2012_1-4\nFLX_ES-LgS_FLUXNET2015_FULLSET_HH_2007-2009_1-4\nFLX_ES-LJu_FLUXNET2015_FULLSET_HH_2004-2013_1-4\nFLX_ES-Ln2_FLUXNET2015_FULLSET_HH_2009-2009_1-4\nFLX_FI-Hyy_FLUXNET2015_FULLSET_HH_1996-2014_1-4\nFLX_FI-Jok_FLUXNET2015_FULLSET_HH_2000-2003_1-4\nFLX_FI-Let_FLUXNET2015_FULLSET_HH_2009-2012_1-4\nFLX_FI-Lom_FLUXNET2015_FULLSET_HH_2007-2009_1-4\nFLX_FI-Sod_FLUXNET2015_FULLSET_HH_2001-2014_1-4\nFLX_FR-Fon_FLUXNET2015_FULLSET_HH_2005-2014_1-4\nFLX_FR-Gri_FLUXNET2015_FULLSET_HH_2004-2014_1-4\nFLX_FR-LBr_FLUXNET2015_FULLSET_HH_1996-2008_1-4\nFLX_FR-Pue_FLUXNET2015_FULLSET_HH_2000-2014_2-4\nFLX_GF-Guy_FLUXNET2015_FULLSET_HH_2004-2014_2-4\nFLX_GH-Ank_FLUXNET2015_FULLSET_HH_2011-2014_1-4\nFLX_GL-NuF_FLUXNET2015_FULLSET_HH_2008-2014_1-4\nFLX_GL-ZaF_FLUXNET2015_FULLSET_HH_2008-2011_2-4\nFLX_GL-ZaH_FLUXNET2015_FULLSET_HH_2000-2014_2-4\nFLX_IT-BCi_FLUXNET2015_FULLSET_HH_2004-2014_2-4\nFLX_IT-CA1_FLUXNET2015_FULLSET_HH_2011-2014_2-4\nFLX_IT-CA2_FLUXNET2015_FULLSET_HH_2011-2014_2-4\nFLX_IT-CA3_FLUXNET2015_FULLSET_HH_2011-2014_2-4\nFLX_IT-Col_FLUXNET2015_FULLSET_HH_1996-2014_1-4\nFLX_IT-Cp2_FLUXNET2015_FULLSET_HH_2012-2014_2-4\nFLX_IT-Cpz_FLUXNET2015_FULLSET_HH_1997-2009_1-4\nFLX_IT-Isp_FLUXNET2015_FULLSET_HH_2013-2014_1-4\nFLX_IT-La2_FLUXNET2015_FULLSET_HH_2000-2002_1-4\nFLX_IT-Lav_FLUXNET2015_FULLSET_HH_2003-2014_2-4\nFLX_IT-MBo_FLUXNET2015_FULLSET_HH_2003-2013_1-4\nFLX_IT-Noe_FLUXNET2015_FULLSET_HH_2004-2014_2-4\nFLX_IT-PT1_FLUXNET2015_FULLSET_HH_2002-2004_1-4\nFLX_IT-Ren_FLUXNET2015_FULLSET_HH_1998-2013_1-4\nFLX_IT-Ro1_FLUXNET2015_FULLSET_HH_2000-2008_1-4\nFLX_IT-Ro2_FLUXNET2015_FULLSET_HH_2002-2012_1-4\nFLX_IT-SR2_FLUXNET2015_FULLSET_HH_2013-2014_1-4\nFLX_IT-SRo_FLUXNET2015_FULLSET_HH_1999-2012_1-4\nFLX_IT-Tor_FLUXNET2015_FULLSET_HH_2008-2014_2-4\nFLX_JP-MBF_FLUXNET2015_FULLSET_HH_2003-2005_1-4\nFLX_JP-SMF_FLUXNET2015_FULLSET_HH_2002-2006_1-4\nFLX_MY-PSO_FLUXNET2015_FULLSET_HH_2003-2009_1-4\nFLX_NL-Hor_FLUXNET2015_FULLSET_HH_2004-2011_1-4\nFLX_NL-Loo_FLUXNET2015_FULLSET_HH_1996-2014_1-4\nFLX_PA-SPn_FLUXNET2015_FULLSET_HH_2007-2009_1-4\nFLX_PA-SPs_FLUXNET2015_FULLSET_HH_2007-2009_1-4\nFLX_RU-Che_FLUXNET2015_FULLSET_HH_2002-2005_1-4\nFLX_RU-Cok_FLUXNET2015_FULLSET_HH_2003-2014_2-4\nFLX_RU-Fyo_FLUXNET2015_FULLSET_HH_1998-2014_2-4\nFLX_RU-Ha1_FLUXNET2015_FULLSET_HH_2002-2004_1-4\nFLX_SD-Dem_FLUXNET2015_FULLSET_HH_2005-2009_2-4\nFLX_SJ-Adv_FLUXNET2015_FULLSET_HH_2011-2014_1-4\nFLX_SJ-Blv_FLUXNET2015_FULLSET_HR_2008-2009_1-4\nFLX_SN-Dhr_FLUXNET2015_FULLSET_HH_2010-2013_1-4\nFLX_US-AR1_FLUXNET2015_FULLSET_HH_2009-2012_1-4\nFLX_US-AR2_FLUXNET2015_FULLSET_HH_2009-2012_1-4\nFLX_US-ARb_FLUXNET2015_FULLSET_HH_2005-2006_1-4\nFLX_US-ARc_FLUXNET2015_FULLSET_HH_2005-2006_1-4\nFLX_US-ARM_FLUXNET2015_FULLSET_HH_2003-2012_1-4\nFLX_US-Atq_FLUXNET2015_FULLSET_HH_2003-2008_1-4\nFLX_US-Blo_FLUXNET2015_FULLSET_HH_1997-2007_1-4\nFLX_US-Cop_FLUXNET2015_FULLSET_HR_2001-2007_1-4\nFLX_US-CRT_FLUXNET2015_FULLSET_HH_2011-2013_1-4\nFLX_US-GBT_FLUXNET2015_FULLSET_HH_1999-2006_1-4\nFLX_US-GLE_FLUXNET2015_FULLSET_HH_2004-2014_1-4\nFLX_US-Goo_FLUXNET2015_FULLSET_HH_2002-2006_1-4\nFLX_US-Ha1_FLUXNET2015_FULLSET_HR_1991-2012_1-4\nFLX_US-IB2_FLUXNET2015_FULLSET_HH_2004-2011_1-4\nFLX_US-Ivo_FLUXNET2015_FULLSET_HH_2004-2007_1-4\nFLX_US-KS1_FLUXNET2015_FULLSET_HH_2002-2002_1-4\nFLX_US-KS2_FLUXNET2015_FULLSET_HH_2003-2006_1-4\nFLX_US-Lin_FLUXNET2015_FULLSET_HH_2009-2010_1-4\nFLX_US-Los_FLUXNET2015_FULLSET_HH_2000-2014_2-4\nFLX_US-LWW_FLUXNET2015_FULLSET_HH_1997-1998_1-4\nFLX_US-Me1_FLUXNET2015_FULLSET_HH_2004-2005_1-4\nFLX_US-Me2_FLUXNET2015_FULLSET_HH_2002-2014_1-4\nFLX_US-Me3_FLUXNET2015_FULLSET_HH_2004-2009_1-4\nFLX_US-Me4_FLUXNET2015_FULLSET_HH_1996-2000_1-4\nFLX_US-Me5_FLUXNET2015_FULLSET_HH_2000-2002_1-4\nFLX_US-Me6_FLUXNET2015_FULLSET_HH_2010-2014_2-4\nFLX_US-MMS_FLUXNET2015_FULLSET_HR_1999-2014_1-4\nFLX_US-Myb_FLUXNET2015_FULLSET_HH_2010-2014_2-4\nFLX_US-Ne1_FLUXNET2015_FULLSET_HR_2001-2013_1-4\nFLX_US-Ne2_FLUXNET2015_FULLSET_HR_2001-2013_1-4\nFLX_US-Ne3_FLUXNET2015_FULLSET_HR_2001-2013_1-4\nFLX_US-NR1_FLUXNET2015_FULLSET_HH_1998-2014_1-4\nFLX_US-Oho_FLUXNET2015_FULLSET_HH_2004-2013_1-4\nFLX_US-ORv_FLUXNET2015_FULLSET_HH_2011-2011_1-4\nFLX_US-PFa_FLUXNET2015_FULLSET_HR_1995-2014_1-4\nFLX_US-Prr_FLUXNET2015_FULLSET_HH_2010-2014_1-4\nFLX_US-SRC_FLUXNET2015_FULLSET_HH_2008-2014_1-4\nFLX_US-SRG_FLUXNET2015_FULLSET_HH_2008-2014_1-4\nFLX_US-SRM_FLUXNET2015_FULLSET_HH_2004-2014_1-4\nFLX_US-Sta_FLUXNET2015_FULLSET_HH_2005-2009_1-4\nFLX_US-Syv_FLUXNET2015_FULLSET_HH_2001-2014_1-4\nFLX_US-Ton_FLUXNET2015_FULLSET_HH_2001-2014_1-4\nFLX_US-Tw1_FLUXNET2015_FULLSET_HH_2012-2014_1-4\nFLX_US-Tw2_FLUXNET2015_FULLSET_HH_2012-2013_1-4\nFLX_US-Tw3_FLUXNET2015_FULLSET_HH_2013-2014_2-4\nFLX_US-Tw4_FLUXNET2015_FULLSET_HH_2013-2014_1-4\nFLX_US-Twt_FLUXNET2015_FULLSET_HH_2009-2014_1-4\nFLX_US-UMB_FLUXNET2015_FULLSET_HR_2000-2014_1-4\nFLX_US-UMd_FLUXNET2015_FULLSET_HH_2007-2014_1-4\nFLX_US-Var_FLUXNET2015_FULLSET_HH_2000-2014_1-4\nFLX_US-WCr_FLUXNET2015_FULLSET_HH_1999-2014_1-4\nFLX_US-Whs_FLUXNET2015_FULLSET_HH_2007-2014_1-4\nFLX_US-Wi0_FLUXNET2015_FULLSET_HH_2002-2002_1-4\nFLX_US-Wi1_FLUXNET2015_FULLSET_HH_2003-2003_1-4\nFLX_US-Wi2_FLUXNET2015_FULLSET_HH_2003-2003_1-4\nFLX_US-Wi3_FLUXNET2015_FULLSET_HH_2002-2004_1-4\nFLX_US-Wi4_FLUXNET2015_FULLSET_HH_2002-2005_1-4\nFLX_US-Wi5_FLUXNET2015_FULLSET_HH_2004-2004_1-4\nFLX_US-Wi6_FLUXNET2015_FULLSET_HH_2002-2003_1-4\nFLX_US-Wi7_FLUXNET2015_FULLSET_HH_2005-2005_1-4\nFLX_US-Wi8_FLUXNET2015_FULLSET_HH_2002-2002_1-4\nFLX_US-Wi9_FLUXNET2015_FULLSET_HH_2004-2005_1-4\nFLX_US-Wkg_FLUXNET2015_FULLSET_HH_2004-2014_1-4\nFLX_US-WPT_FLUXNET2015_FULLSET_HH_2011-2013_1-4\nFLX_ZM-Mon_FLUXNET2015_FULLSET_HH_2000-2009_2-4\n\n\n\nsite_info\n\n\n\n\nshape: (206, 3)\n\n\n\n\nstart\n\n\nend\n\n\nsite\n\n\n\n\ni64\n\n\ni64\n\n\nstr\n\n\n\n\n\n\n200901010030\n\n\n201201010000\n\n\n\"AR-SLu\"\n\n\n\n\n200901010030\n\n\n201301010000\n\n\n\"AR-Vir\"\n\n\n\n\n200201010030\n\n\n201301010000\n\n\n\"AT-Neu\"\n\n\n\n\n200701010030\n\n\n201001010000\n\n\n\"AU-Ade\"\n\n\n\n\n201001010030\n\n\n201501010000\n\n\n\"AU-ASM\"\n\n\n\n\n201001010030\n\n\n201501010000\n\n\n\"AU-Cpr\"\n\n\n\n\n201201010030\n\n\n201501010000\n\n\n\"AU-Cum\"\n\n\n\n\n200701010030\n\n\n201401010000\n\n\n\"AU-DaP\"\n\n\n\n\n200801010030\n\n\n201501010000\n\n\n\"AU-DaS\"\n\n\n\n\n200801010030\n\n\n201501010000\n\n\n\"AU-Dry\"\n\n\n\n\n201101010030\n\n\n201401010000\n\n\n\"AU-Emr\"\n\n\n\n\n200601010030\n\n\n200901010000\n\n\n\"AU-Fog\"\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n200301010030\n\n\n200401010000\n\n\n\"US-Wi1\"\n\n\n\n\n200301010030\n\n\n200401010000\n\n\n\"US-Wi2\"\n\n\n\n\n200201010030\n\n\n200501010000\n\n\n\"US-Wi3\"\n\n\n\n\n200201010030\n\n\n200601010000\n\n\n\"US-Wi4\"\n\n\n\n\n200401010030\n\n\n200501010000\n\n\n\"US-Wi5\"\n\n\n\n\n200201010030\n\n\n200401010000\n\n\n\"US-Wi6\"\n\n\n\n\n200501010030\n\n\n200601010000\n\n\n\"US-Wi7\"\n\n\n\n\n200201010030\n\n\n200301010000\n\n\n\"US-Wi8\"\n\n\n\n\n200401010030\n\n\n200601010000\n\n\n\"US-Wi9\"\n\n\n\n\n200401010030\n\n\n201501010000\n\n\n\"US-Wkg\"\n\n\n\n\n201101010030\n\n\n201401010000\n\n\n\"US-WPT\"\n\n\n\n\n200001010030\n\n\n201001010000\n\n\n\"ZM-Mon\"\n\n\n\n\n\n\n\n\nsite_info.write_parquet(out_dir / \"../site_info.parquet\")"
  },
  {
    "objectID": "change parameters init.html",
    "href": "change parameters init.html",
    "title": "GPFA Imputation Analysis",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\n\n\nfrom gpfa_imputation.imputation import *\nfrom gpfa_imputation.data_preparation import *\nfrom gpfa_imputation.results import *\n\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom pyprojroot import here\nimport matplotlib.pyplot as plt\n\nfrom gpfa_imputation.utils import cache_disk\n\n\ndef reset_seed():\n    torch.manual_seed(27);\n    np.random.seed(27);\n\n\ntorch.manual_seed(27);\nnp.random.seed(27);\ncache = True\ncache_path = here() / \".cache\"\n\n\n\ntake the first 200 rows from the Hainich dataset\n\nhai_path = Path(\"FLX_DE-Hai_FLUXNET2015_FULLSET_HH_2000-2012_1-4.csv\")\nhai_raw = pd.read_csv(here(\"data\") / hai_path, na_values=[\"-9999\", \"-9999.99\"], parse_dates=[0, 1], nrows=200)\n\n\nmeteo_vars = {\n    \"TA_F\": \"TA\",\n    \"SW_IN_F\": \"SW_IN\",\n    \"LW_IN_F\": \"LW_IN\",\n    \"VPD_F\": \"VPD\",\n    #\"PA\": \"PA\"\n}\n\nunits = {\n    'TA': '°C',\n    'SW_IN': 'W m-2',\n    'LW_IN': 'W m-2',\n    'VPD': 'hPa'\n}\n\nhai = (hai_raw\n       .rename(columns=meteo_vars)\n       .set_index(\"TIMESTAMP_END\")\n       .loc[:, meteo_vars.values()])\nhai\n\n\n\n\n\n  \n    \n      \n      TA\n      SW_IN\n      LW_IN\n      VPD\n    \n    \n      TIMESTAMP_END\n      \n      \n      \n      \n    \n  \n  \n    \n      2000-01-01 00:30:00\n      -0.60\n      0.0\n      302.475\n      0.222\n    \n    \n      2000-01-01 01:00:00\n      -0.65\n      0.0\n      302.475\n      0.122\n    \n    \n      2000-01-01 01:30:00\n      -0.58\n      0.0\n      301.677\n      0.090\n    \n    \n      2000-01-01 02:00:00\n      -0.51\n      0.0\n      301.677\n      0.110\n    \n    \n      2000-01-01 02:30:00\n      -0.49\n      0.0\n      301.677\n      0.102\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2000-01-05 02:00:00\n      4.74\n      0.0\n      330.202\n      1.191\n    \n    \n      2000-01-05 02:30:00\n      4.75\n      0.0\n      330.202\n      1.057\n    \n    \n      2000-01-05 03:00:00\n      4.76\n      0.0\n      330.202\n      0.935\n    \n    \n      2000-01-05 03:30:00\n      4.62\n      0.0\n      330.202\n      1.162\n    \n    \n      2000-01-05 04:00:00\n      4.51\n      0.0\n      330.202\n      1.636\n    \n  \n\n200 rows × 4 columns\n\n\n\n\nreset_seed()\ndata = GPFADataTest(hai[:150]).add_random_missing()\n\n\nimp = GPFAImputationExplorer(hai[:20], latent_dims=2)\n\n\nimp\n\nGPFA Imputation Explorer:\n    N obs: 20\n    N features 4 (TA, SW_IN, LW_IN, VPD)\n    N missing observations 0\n    N latent: 2\n\n\n\nimp.learner.model.covar_module.Lambda = torch.nn.Parameter(torch.ones(4,2))\n\nimp.fit_predict()\n\n\n\n\n/home/simone/anaconda3/envs/data-science/lib/python3.10/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:136: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\ntorch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\nX = torch.triangular_solve(B, A).solution\nshould be replaced with\nX = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2183.)\n  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n/home/simone/anaconda3/envs/data-science/lib/python3.10/site-packages/torch/autograd/__init__.py:173: UserWarning: operator() profile_node %840 : int[] = prim::profile_ivalue(%838)\n does not have profile information (Triggered internally at  ../torch/csrc/jit/codegen/cuda/graph_fuser.cpp:104.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n/home/simone/anaconda3/envs/data-science/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n  warnings.warn(\n\n\n\n\n\n\n  \n    \n      \n      time\n      variable\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.0\n      TA\n      -0.611029\n      0.040206\n    \n    \n      1\n      1.0\n      TA\n      -0.593040\n      0.036399\n    \n    \n      2\n      2.0\n      TA\n      -0.563206\n      0.035685\n    \n    \n      3\n      3.0\n      TA\n      -0.523531\n      0.035679\n    \n    \n      4\n      4.0\n      TA\n      -0.477152\n      0.035575\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      75\n      15.0\n      VPD\n      0.061757\n      0.035498\n    \n    \n      76\n      16.0\n      VPD\n      0.052250\n      0.035504\n    \n    \n      77\n      17.0\n      VPD\n      0.039970\n      0.035504\n    \n    \n      78\n      18.0\n      VPD\n      0.025721\n      0.035542\n    \n    \n      79\n      19.0\n      VPD\n      0.010783\n      0.035759\n    \n  \n\n80 rows × 4 columns\n\n\n\n\n\n\nfrom sklearn.decomposition import PCA\n\n\npca = PCA(2).fit(data.data_complete)\n\n\nPCA(2).fit(data.data_complete).components_\n\narray([[ 2.64510596e-03,  9.72190612e-01, -2.34163954e-01,\n         2.37925628e-03],\n       [-8.47181130e-03, -2.34134422e-01, -9.72167258e-01,\n        -3.50525961e-04]])\n\n\n\nimp.learner.model.covar_module.Lambda = torch.nn.Parameter(torch.tensor(PCA(2).fit(data.data_complete).components_, dtype=torch.float).T)\n\n\nimp.fit_predict()\n\n\n\n\n/home/simone/anaconda3/envs/data-science/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n  warnings.warn(\n\n\n\n\n\n\n  \n    \n      \n      time\n      variable\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.0\n      TA\n      -0.620425\n      0.039439\n    \n    \n      1\n      1.0\n      TA\n      -0.605260\n      0.035272\n    \n    \n      2\n      2.0\n      TA\n      -0.574535\n      0.034735\n    \n    \n      3\n      3.0\n      TA\n      -0.531093\n      0.034725\n    \n    \n      4\n      4.0\n      TA\n      -0.479548\n      0.034542\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      75\n      15.0\n      VPD\n      0.036359\n      0.029622\n    \n    \n      76\n      16.0\n      VPD\n      0.026041\n      0.029652\n    \n    \n      77\n      17.0\n      VPD\n      0.018374\n      0.029759\n    \n    \n      78\n      18.0\n      VPD\n      0.013253\n      0.030017\n    \n    \n      79\n      19.0\n      VPD\n      0.010129\n      0.030518\n    \n  \n\n80 rows × 4 columns\n\n\n\n\n\n\n\ncache = here() / \".cache\" / \"hai_test_init_values.pickle\"\n# cache.unlink()\n\n\n@cache_disk(cache)\ndef compute():\n    out = {}\n    \n    imp = GPFAImputationExplorer(data.data, latent_dims=2)\n    out[\"normal\"] = imp.fit().to_result(data.data_compl_tidy, units=units)\n    \n    imp = GPFAImputationExplorer(data.data, latent_dims=2)\n    imp.learner.model.covar_module.Lambda = torch.nn.Parameter(torch.ones(4,2))\n    out[\"ones\"] = imp.fit().to_result(data.data_compl_tidy, units=units)\n    \n    imp = GPFAImputationExplorer(data.data, latent_dims=2)\n    imp.learner.model.covar_module.Lambda = torch.nn.Parameter(torch.zeros(4,2))\n    out[\"zeros\"] = imp.fit().to_result(data.data_compl_tidy, units=units)\n    \n    imp = GPFAImputationExplorer(data.data, latent_dims=2)\n    imp.learner.model.covar_module.Lambda = torch.nn.Parameter(torch.rand(4,2))\n    out[\"rand1\"] = imp.fit().to_result(data.data_compl_tidy, units=units)\n    \n    imp = GPFAImputationExplorer(data.data, latent_dims=2)\n    imp.learner.model.covar_module.Lambda = torch.nn.Parameter(torch.rand(4,2))\n    out[\"rand2\"] = imp.fit().to_result(data.data_compl_tidy, units=units)\n    \n    imp = GPFAImputationExplorer(data.data, latent_dims=2)\n    imp.learner.model.covar_module.Lambda = torch.nn.Parameter(torch.rand(4,2))\n    out[\"rand3\"] = imp.fit().to_result(data.data_compl_tidy, units=units)\n    \n    imp = GPFAImputationExplorer(data.data, latent_dims=2)\n    imp.learner.model.covar_module.Lambda = torch.nn.Parameter(torch.tensor(PCA(2).fit(data.data_complete).components_, dtype=torch.float).T)\n    out[\"pca\"] = imp.fit().to_result(data.data_compl_tidy, units=units)\n    \n    return out\n\n\nresults = compute()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nresults[\"normal\"].plot_pred()\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\nresults[\"normal\"].display_results()\n\n\n\n\n\n\n\nMetrics  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.9914\n    \n    \n      SW_IN\n      0.1882\n    \n    \n      LW_IN\n      0.9670\n    \n    \n      VPD\n      0.5806\n    \n  \n\n  RMSE \n\n  \n    \n      variable\n      rmse\n      units\n    \n  \n  \n    \n      TA\n      0.0855\n      °C\n    \n    \n      SW_IN\n      33.4691\n      W m-2\n    \n    \n      LW_IN\n      3.4204\n      W m-2\n    \n    \n      VPD\n      0.1655\n      hPa\n    \n  \n\n \n\n\n\nModel Info  Lambda \n\n  \n    \n      0\n      z0\n      z1\n    \n  \n  \n    \n      TA\n      -0.0205\n      0.9658\n    \n    \n      SW_IN\n      0.2969\n      0.1791\n    \n    \n      LW_IN\n      -0.7879\n      0.0215\n    \n    \n      VPD\n      0.1521\n      0.7044\n    \n  \n\n  lengthscale \n\n  \n    \n      latent\n      lengthscale\n    \n  \n  \n    \n      z0\n      7.8076\n    \n    \n      z1\n      6.8943\n    \n  \n\n  psi \n\n  \n    \n      variable\n      psi\n    \n  \n  \n    \n      TA\n      0.0009\n    \n    \n      SW_IN\n      0.8002\n    \n    \n      LW_IN\n      0.0192\n    \n    \n      VPD\n      0.4391\n    \n  \n\n  likelihood \n\n  \n    \n      noise\n    \n  \n  \n    \n      0.0050\n    \n  \n\n \n\n\n\nresults[\"ones\"].display_results()\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\nMetrics  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.6251\n    \n    \n      SW_IN\n      0.1243\n    \n    \n      LW_IN\n      0.0075\n    \n    \n      VPD\n      0.9595\n    \n  \n\n  RMSE \n\n  \n    \n      variable\n      rmse\n      units\n    \n  \n  \n    \n      TA\n      0.5654\n      °C\n    \n    \n      SW_IN\n      34.7601\n      W m-2\n    \n    \n      LW_IN\n      18.7643\n      W m-2\n    \n    \n      VPD\n      0.0514\n      hPa\n    \n  \n\n \n\n\n\nModel Info  Lambda \n\n  \n    \n      0\n      z0\n      z1\n    \n  \n  \n    \n      TA\n      0.5621\n      0.5621\n    \n    \n      SW_IN\n      0.2967\n      0.2967\n    \n    \n      LW_IN\n      -0.1298\n      -0.1298\n    \n    \n      VPD\n      0.7420\n      0.7420\n    \n  \n\n  lengthscale \n\n  \n    \n      latent\n      lengthscale\n    \n  \n  \n    \n      z0\n      5.5764\n    \n    \n      z1\n      5.5764\n    \n  \n\n  psi \n\n  \n    \n      variable\n      psi\n    \n  \n  \n    \n      TA\n      0.4161\n    \n    \n      SW_IN\n      0.8069\n    \n    \n      LW_IN\n      0.9339\n    \n    \n      VPD\n      0.0106\n    \n  \n\n  likelihood \n\n  \n    \n      noise\n    \n  \n  \n    \n      0.0226\n    \n  \n\n \n\n\n\nresults[\"zeros\"].display_results()\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\nMetrics  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      -0.0176\n    \n    \n      SW_IN\n      -0.0140\n    \n    \n      LW_IN\n      -0.0032\n    \n    \n      VPD\n      -0.0225\n    \n  \n\n  RMSE \n\n  \n    \n      variable\n      rmse\n      units\n    \n  \n  \n    \n      TA\n      0.9315\n      °C\n    \n    \n      SW_IN\n      37.4040\n      W m-2\n    \n    \n      LW_IN\n      18.8651\n      W m-2\n    \n    \n      VPD\n      0.2585\n      hPa\n    \n  \n\n \n\n\n\nModel Info  Lambda \n\n  \n    \n      0\n      z0\n      z1\n    \n  \n  \n    \n      TA\n      0.0000\n      0.0000\n    \n    \n      SW_IN\n      0.0000\n      0.0000\n    \n    \n      LW_IN\n      0.0000\n      0.0000\n    \n    \n      VPD\n      0.0000\n      0.0000\n    \n  \n\n  lengthscale \n\n  \n    \n      latent\n      lengthscale\n    \n  \n  \n    \n      z0\n      0.6931\n    \n    \n      z1\n      0.6931\n    \n  \n\n  psi \n\n  \n    \n      variable\n      psi\n    \n  \n  \n    \n      TA\n      0.4942\n    \n    \n      SW_IN\n      0.4942\n    \n    \n      LW_IN\n      0.4942\n    \n    \n      VPD\n      0.4942\n    \n  \n\n  likelihood \n\n  \n    \n      noise\n    \n  \n  \n    \n      0.4943\n    \n  \n\n \n\n\n\nresults[\"rand1\"].display_results()\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\nMetrics  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.9914\n    \n    \n      SW_IN\n      0.1889\n    \n    \n      LW_IN\n      0.9669\n    \n    \n      VPD\n      0.5808\n    \n  \n\n  RMSE \n\n  \n    \n      variable\n      rmse\n      units\n    \n  \n  \n    \n      TA\n      0.0858\n      °C\n    \n    \n      SW_IN\n      33.4532\n      W m-2\n    \n    \n      LW_IN\n      3.4256\n      W m-2\n    \n    \n      VPD\n      0.1655\n      hPa\n    \n  \n\n \n\n\n\nModel Info  Lambda \n\n  \n    \n      0\n      z0\n      z1\n    \n  \n  \n    \n      TA\n      0.2557\n      0.9759\n    \n    \n      SW_IN\n      0.3381\n      0.1117\n    \n    \n      LW_IN\n      -0.7526\n      0.2073\n    \n    \n      VPD\n      0.3483\n      0.6710\n    \n  \n\n  lengthscale \n\n  \n    \n      latent\n      lengthscale\n    \n  \n  \n    \n      z0\n      7.6743\n    \n    \n      z1\n      6.9948\n    \n  \n\n  psi \n\n  \n    \n      variable\n      psi\n    \n  \n  \n    \n      TA\n      0.0010\n    \n    \n      SW_IN\n      0.8042\n    \n    \n      LW_IN\n      0.0189\n    \n    \n      VPD\n      0.4368\n    \n  \n\n  likelihood \n\n  \n    \n      noise\n    \n  \n  \n    \n      0.0049\n    \n  \n\n \n\n\n\nresults[\"rand2\"].display_results()\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\nMetrics  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.9913\n    \n    \n      SW_IN\n      0.1886\n    \n    \n      LW_IN\n      0.9673\n    \n    \n      VPD\n      0.5809\n    \n  \n\n  RMSE \n\n  \n    \n      variable\n      rmse\n      units\n    \n  \n  \n    \n      TA\n      0.0863\n      °C\n    \n    \n      SW_IN\n      33.4597\n      W m-2\n    \n    \n      LW_IN\n      3.4038\n      W m-2\n    \n    \n      VPD\n      0.1655\n      hPa\n    \n  \n\n \n\n\n\nModel Info  Lambda \n\n  \n    \n      0\n      z0\n      z1\n    \n  \n  \n    \n      TA\n      0.7993\n      0.6500\n    \n    \n      SW_IN\n      0.3210\n      -0.1140\n    \n    \n      LW_IN\n      -0.4229\n      0.6344\n    \n    \n      VPD\n      0.6748\n      0.3442\n    \n  \n\n  lengthscale \n\n  \n    \n      latent\n      lengthscale\n    \n  \n  \n    \n      z0\n      7.0488\n    \n    \n      z1\n      7.4115\n    \n  \n\n  psi \n\n  \n    \n      variable\n      psi\n    \n  \n  \n    \n      TA\n      0.0009\n    \n    \n      SW_IN\n      0.7963\n    \n    \n      LW_IN\n      0.0190\n    \n    \n      VPD\n      0.4403\n    \n  \n\n  likelihood \n\n  \n    \n      noise\n    \n  \n  \n    \n      0.0052\n    \n  \n\n \n\n\n\nresults[\"rand3\"].display_results()\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\nMetrics  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.9914\n    \n    \n      SW_IN\n      0.1885\n    \n    \n      LW_IN\n      0.9673\n    \n    \n      VPD\n      0.5808\n    \n  \n\n  RMSE \n\n  \n    \n      variable\n      rmse\n      units\n    \n  \n  \n    \n      TA\n      0.0858\n      °C\n    \n    \n      SW_IN\n      33.4615\n      W m-2\n    \n    \n      LW_IN\n      3.4069\n      W m-2\n    \n    \n      VPD\n      0.1655\n      hPa\n    \n  \n\n \n\n\n\nModel Info  Lambda \n\n  \n    \n      0\n      z0\n      z1\n    \n  \n  \n    \n      TA\n      0.9089\n      0.4586\n    \n    \n      SW_IN\n      0.2809\n      -0.1911\n    \n    \n      LW_IN\n      -0.2635\n      0.7331\n    \n    \n      VPD\n      0.7226\n      0.1826\n    \n  \n\n  lengthscale \n\n  \n    \n      latent\n      lengthscale\n    \n  \n  \n    \n      z0\n      6.9495\n    \n    \n      z1\n      7.5873\n    \n  \n\n  psi \n\n  \n    \n      variable\n      psi\n    \n  \n  \n    \n      TA\n      0.0009\n    \n    \n      SW_IN\n      0.7981\n    \n    \n      LW_IN\n      0.0192\n    \n    \n      VPD\n      0.4393\n    \n  \n\n  likelihood \n\n  \n    \n      noise\n    \n  \n  \n    \n      0.0052\n    \n  \n\n \n\n\n\nresults[\"pca\"].display_results()\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\nMetrics  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.9915\n    \n    \n      SW_IN\n      0.1882\n    \n    \n      LW_IN\n      0.9670\n    \n    \n      VPD\n      0.5804\n    \n  \n\n  RMSE \n\n  \n    \n      variable\n      rmse\n      units\n    \n  \n  \n    \n      TA\n      0.0853\n      °C\n    \n    \n      SW_IN\n      33.4672\n      W m-2\n    \n    \n      LW_IN\n      3.4193\n      W m-2\n    \n    \n      VPD\n      0.1656\n      hPa\n    \n  \n\n \n\n\n\nModel Info  Lambda \n\n  \n    \n      0\n      z0\n      z1\n    \n  \n  \n    \n      TA\n      0.9431\n      -0.1357\n    \n    \n      SW_IN\n      0.2026\n      0.2780\n    \n    \n      LW_IN\n      -0.0436\n      -0.7956\n    \n    \n      VPD\n      0.7012\n      0.0679\n    \n  \n\n  lengthscale \n\n  \n    \n      latent\n      lengthscale\n    \n  \n  \n    \n      z0\n      6.8095\n    \n    \n      z1\n      7.8881\n    \n  \n\n  psi \n\n  \n    \n      variable\n      psi\n    \n  \n  \n    \n      TA\n      0.0008\n    \n    \n      SW_IN\n      0.7966\n    \n    \n      LW_IN\n      0.0195\n    \n    \n      VPD\n      0.4391\n    \n  \n\n  likelihood \n\n  \n    \n      noise\n    \n  \n  \n    \n      0.0052"
  },
  {
    "objectID": "Multi latent - Imputation GPFA - Hainich.html",
    "href": "Multi latent - Imputation GPFA - Hainich.html",
    "title": "GPFA Imputation Analysis",
    "section": "",
    "text": "Trying to use more than 1 latent variable\n\n%load_ext autoreload\n%autoreload 2\n\n%matplotlib inline\n\n\nfrom gpfa_imputation.imputation import *\nfrom gpfa_imputation.data_preparation import *\nfrom gpfa_imputation.results import *\n\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom pyprojroot import here\nimport matplotlib.pyplot as plt\n\nfrom gpfa_imputation.utils import cache_disk\n\n\ndef reset_seed():\n    torch.manual_seed(27);\n    np.random.seed(27);\n\n\ntorch.manual_seed(27);\nnp.random.seed(27);\ncache_path = here() / \".cache\"\n\n\n\ntake the first 200 rows from the Hainich dataset\n\nhai_path = Path(\"FLX_DE-Hai_FLUXNET2015_FULLSET_HH_2000-2012_1-4.csv\")\nhai_raw = pd.read_csv(here(\"data\") / hai_path, na_values=[\"-9999\", \"-9999.99\"], parse_dates=[0, 1], nrows=200)\n\n\nmeteo_vars = {\n    \"TA_F\": \"TA\",\n    \"SW_IN_F\": \"SW_IN\",\n    \"LW_IN_F\": \"LW_IN\",\n    \"VPD_F\": \"VPD\",\n    #\"PA\": \"PA\"\n}\n\nunits = {\n    'TA': '°C',\n    'SW_IN': 'W m-2',\n    'LW_IN': 'W m-2',\n    'VPD': 'hPa'\n}\n\nhai = (hai_raw\n       .rename(columns=meteo_vars)\n       .set_index(\"TIMESTAMP_END\")\n       .loc[:, meteo_vars.values()])\nhai\n\n\n\n\n\n  \n    \n      \n      TA\n      SW_IN\n      LW_IN\n      VPD\n    \n    \n      TIMESTAMP_END\n      \n      \n      \n      \n    \n  \n  \n    \n      2000-01-01 00:30:00\n      -0.60\n      0.0\n      302.475\n      0.222\n    \n    \n      2000-01-01 01:00:00\n      -0.65\n      0.0\n      302.475\n      0.122\n    \n    \n      2000-01-01 01:30:00\n      -0.58\n      0.0\n      301.677\n      0.090\n    \n    \n      2000-01-01 02:00:00\n      -0.51\n      0.0\n      301.677\n      0.110\n    \n    \n      2000-01-01 02:30:00\n      -0.49\n      0.0\n      301.677\n      0.102\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2000-01-05 02:00:00\n      4.74\n      0.0\n      330.202\n      1.191\n    \n    \n      2000-01-05 02:30:00\n      4.75\n      0.0\n      330.202\n      1.057\n    \n    \n      2000-01-05 03:00:00\n      4.76\n      0.0\n      330.202\n      0.935\n    \n    \n      2000-01-05 03:30:00\n      4.62\n      0.0\n      330.202\n      1.162\n    \n    \n      2000-01-05 04:00:00\n      4.51\n      0.0\n      330.202\n      1.636\n    \n  \n\n200 rows × 4 columns\n\n\n\n\n\nmakes here all the slow computations and cache them on disk\n\nreset_seed()\ndata_r_gaps = GPFADataTest(hai[:150]).add_random_missing()\ndata_c_gaps = GPFADataTest(hai[:150]).add_gap(15, meteo_vars.values())\n\n\ncache_file_gaps = cache_path / \"hai_diff_latents.pickle\"\n# cache_file_gaps.unlink() # uncomment this line to reset the cache\n\n\n@cache_disk(cache_file_gaps)\ndef compute_multiple_latent():\n    hai_r_gaps = [GPFAImputation(\n        data_r_gaps.data, latent_dims=i)\n                  .fit()\n                  .to_result(data_r_gaps.data_compl_tidy, units=units)\n                  for i in range(1,4)]\n    hai_c_gaps = [GPFAImputationExplorer(\n        data_c_gaps.data, latent_dims=i)\n                  .fit()\n                  .to_result(data_c_gaps.data_compl_tidy, units=units)\n                  for i in range(1,4)]\n    return hai_r_gaps, hai_c_gaps\n\n\nhai_r_gaps, hai_c_gaps = compute_multiple_latent()\n\n\n\n\n\n\nhai_r_gaps\n\n[<gpfa_imputation.results.GPFAResult>,\n <gpfa_imputation.results.GPFAResult>,\n <gpfa_imputation.results.GPFAResult>]\n\n\n\nhai_r_gaps[0].display_results()\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\nMetrics  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.6601\n    \n    \n      SW_IN\n      0.0865\n    \n    \n      LW_IN\n      -0.0341\n    \n    \n      VPD\n      0.9569\n    \n  \n\n  RMSE \n\n  \n    \n      variable\n      rmse\n      units\n    \n  \n  \n    \n      TA\n      0.5224\n      °C\n    \n    \n      SW_IN\n      46.1695\n      W m-2\n    \n    \n      LW_IN\n      21.2045\n      W m-2\n    \n    \n      VPD\n      0.0578\n      hPa\n    \n  \n\n \n\n\n\nModel Info  Lambda \n\n  \n    \n      0\n      z0\n    \n  \n  \n    \n      TA\n      0.8015\n    \n    \n      SW_IN\n      0.4251\n    \n    \n      LW_IN\n      -0.1879\n    \n    \n      VPD\n      1.0596\n    \n  \n\n  lengthscale \n\n  \n    \n      latent\n      lengthscale\n    \n  \n  \n    \n      z0\n      5.6057\n    \n  \n\n  psi \n\n  \n    \n      variable\n      psi\n    \n  \n  \n    \n      TA\n      0.4174\n    \n    \n      SW_IN\n      0.8049\n    \n    \n      LW_IN\n      0.9361\n    \n    \n      VPD\n      0.0103\n    \n  \n\n  likelihood \n\n  \n    \n      noise\n    \n  \n  \n    \n      0.0224\n    \n  \n\n \n\n\n\nai_r_gaps[0].plot_pred()\n\n\nhai_r_gaps[1].display_results()\n\n\nhai_r_gaps[2].display_results()\n\n\n\n\n\nhai_c_gaps[0].display_results()\n\n\nhai_c_gaps[1].display_results()\n\n\nhai_c_gaps[2].display_results()"
  },
  {
    "objectID": "GPFA Hainich.html",
    "href": "GPFA Hainich.html",
    "title": "GPFA Imputation Analysis",
    "section": "",
    "text": "First analysis of the Hainich data using GPFA for filling the gaps\n\n%load_ext autoreload\n%autoreload 2\n\n\nfrom gpfa_imputation.imputation import *\nfrom gpfa_imputation.data_preparation import *\n\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom pyprojroot import here\nimport matplotlib.pyplot as plt\n\n\ntorch.manual_seed(27);\nnp.random.seed(27);\n\n\n\ntake the first 200 rows from the Hainich dataset\n\nhai_path = Path(\"FLX_DE-Hai_FLUXNET2015_FULLSET_HH_2000-2012_1-4.csv\")\nhai_raw = pd.read_csv(here(\"data\") / hai_path, na_values=[\"-9999\", \"-9999.99\"], parse_dates=[0, 1], nrows=200)\n\n\nmeteo_vars = {\n    \"TA_F\": \"TA\",\n    \"SW_IN_F\": \"SW_IN\",\n    \"LW_IN_F\": \"LW_IN\",\n    \"VPD_F\": \"VPD\",\n    #\"PA\": \"PA\"\n}\n\nunits = {\n    'TA': '°C',\n    'SW_IN': 'W m-2',\n    'LW_IN': 'W m-2',\n    'VPD': 'hPa'\n}\n\nhai = (hai_raw\n       .rename(columns=meteo_vars)\n       .set_index(\"TIMESTAMP_END\")\n       .loc[:, meteo_vars.values()])\nhai\n\n\n\n\n\n  \n    \n      \n      TA\n      SW_IN\n      LW_IN\n      VPD\n    \n    \n      TIMESTAMP_END\n      \n      \n      \n      \n    \n  \n  \n    \n      2000-01-01 00:30:00\n      -0.60\n      0.0\n      302.475\n      0.222\n    \n    \n      2000-01-01 01:00:00\n      -0.65\n      0.0\n      302.475\n      0.122\n    \n    \n      2000-01-01 01:30:00\n      -0.58\n      0.0\n      301.677\n      0.090\n    \n    \n      2000-01-01 02:00:00\n      -0.51\n      0.0\n      301.677\n      0.110\n    \n    \n      2000-01-01 02:30:00\n      -0.49\n      0.0\n      301.677\n      0.102\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2000-01-05 02:00:00\n      4.74\n      0.0\n      330.202\n      1.191\n    \n    \n      2000-01-05 02:30:00\n      4.75\n      0.0\n      330.202\n      1.057\n    \n    \n      2000-01-05 03:00:00\n      4.76\n      0.0\n      330.202\n      0.935\n    \n    \n      2000-01-05 03:30:00\n      4.62\n      0.0\n      330.202\n      1.162\n    \n    \n      2000-01-05 04:00:00\n      4.51\n      0.0\n      330.202\n      1.636\n    \n  \n\n200 rows × 4 columns\n\n\n\n\n\n\n\ngpfa_data = GPFADataTest(hai).add_random_missing()\n\n\ngpfa_hai = GPFAImputation(gpfa_data.data, gpfa_data.tidy_df(complete=True, is_missing=True))\n\nTypeError: rand(): argument 'size' must be tuple of ints, but found element of type DataFrame at pos 2\n\n\n\ngpfa_hai\n\n\n%time imputed = gpfa_hai.impute()\n\n\n\n\n/home/simone/anaconda3/envs/data-science/lib/python3.10/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:136: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\ntorch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\nX = torch.triangular_solve(B, A).solution\nshould be replaced with\nX = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2183.)\n  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n/home/simone/anaconda3/envs/data-science/lib/python3.10/site-packages/torch/autograd/__init__.py:173: UserWarning: operator() profile_node %840 : int[] = prim::profile_ivalue(%838)\n does not have profile information (Triggered internally at  ../torch/csrc/jit/codegen/cuda/graph_fuser.cpp:104.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\n\nCPU times: user 5min 57s, sys: 485 ms, total: 5min 57s\nWall time: 5min 59s\n\n\n\nimputed\n\n\n\n\n\n  \n    \n      \n      time\n      variable\n      mean\n      std\n    \n  \n  \n    \n      0\n      0.0\n      TA\n      -0.600000\n      NaN\n    \n    \n      1\n      2.0\n      TA\n      -0.580000\n      NaN\n    \n    \n      2\n      3.0\n      TA\n      -0.510000\n      NaN\n    \n    \n      3\n      4.0\n      TA\n      -0.490000\n      NaN\n    \n    \n      4\n      11.0\n      TA\n      -0.230000\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      403\n      189.0\n      VPD\n      0.826632\n      0.252326\n    \n    \n      404\n      190.0\n      VPD\n      0.827371\n      0.252322\n    \n    \n      405\n      192.0\n      VPD\n      1.213000\n      0.000000\n    \n    \n      406\n      193.0\n      VPD\n      0.826446\n      0.252319\n    \n    \n      407\n      197.0\n      VPD\n      0.820434\n      0.252332\n    \n  \n\n800 rows × 4 columns\n\n\n\n\nhai_plot = gpfa_hai.plot_pred(units=units, properties =  {'height': 190 , 'width': 380})\n\nhai_plot.save(\"plots/plot_hai_winter_4_var_200_obs_random_gaps_row_20_value_10.vl.json\")\nhai_plot\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\n#gpfa_hai.plot_pred(complete= gpfa_data.tidy_df(complete=True, is_missing=True) )\n\n\ngpfa_hai.rmse()\n\nAttributeError: module 'sklearn' has no attribute 'metrics'\n\n\n\ngpfa_hai.r2()\n\n\nlosses = pd.DataFrame(gpfa_hai.learner.losses.cpu().numpy(), columns=['loss'])\n\np = losses.plot()\nplt.savefig(here('analysis/plots/loss_plot_hai_winter_4_var_200_obs_random_gaps_row_20_value_10.png'))\np\n\nLambda parameter, the latent variable is very similar to the\n\ngpfa_hai.data.corr()\n\nNameError: name 'gpfa_hai' is not defined\n\n\n\ngpfa_hai.learner.model.covar_module.Lambda.detach()\n\nthis is the value of the length scale of the RBF latent kernel\n\ngpfa_hai.learner.model.covar_module.latent_kernel.lengthscale.detach()\n\n\ngpfa_hai.learner.model.covar_module.psi.detach()\n\n\n\nThe low correlation between SW_IN and TA is likely due to cloud cover, which is hard to predict with a dialy cycle. Hence we are looking at summer days and there is a much better correlation\n\nhai_raw2 = pd.read_csv(here(\"data\") / hai_path, na_values=[\"-9999\", \"-9999.99\"], parse_dates=[0, 1], nrows= 7 * 30 * 24 * 2)\n\nNameError: name 'pd' is not defined\n\n\n\nmeteo_vars = {\n    \"TA_F\": \"TA\",\n    \"SW_IN_F\": \"SW_IN\",\n    \"LW_IN_F\": \"LW_IN\",\n    \"VPD_F\": \"VPD\",\n    #\"PA\": \"PA\"\n}\n\nunits = {\n    'TA': '°C',\n    'SW_IN': 'W m-2',\n    'LW_IN': 'W m-2',\n    'VPD': 'hPa'\n}\n\nhai2 = (hai_raw2\n       .rename(columns=meteo_vars)\n       .set_index(\"TIMESTAMP_END\")\n       .loc[:, meteo_vars.values()])\nhai2\n\n\nhai2[-800:-500].SW_IN.plot()\n\n\nhai2[-800:-500].corr()\n\n\ngpdata2 = GPFADataTest(hai2[-800:-500].copy()).add_random_missing()\n\n\ngp_imp2 = GPFAImputation(gpdata2.data, gpdata2.tidy_df(complete=True, is_missing=True))\n\n\n%time data_imp2 = gp_imp2.impute()\n\n\ngp_imp2.plot_pred(units=units)\n\n\ndata_imp2\n\n\ngp_imp2.rmse()\n\n\ngpdata2.data.corr()\n\n\ngp_imp2.learner.model.covar_module.Lambda.detach()\n\n\ngp_imp2.learner.model.covar_module.psi.detach()\n\nthis is the value of the length scale of the RBF latent kernel\n\ngp_imp2.learner.model.covar_module.latent_kernel.lengthscale.detach()\n\n\n\n\ngpdata3 = GPFADataTest(hai2[-800:-500].loc[:, [\"TA\", \"SW_IN\"]].copy()).add_random_missing()\n\n\ngp_imp3 = GPFAImputation(gpdata3.data, gpdata3.tidy_df(complete=True, is_missing=True))\n\n\n%time data_imp3 = gp_imp3.impute()\n\n\ngp_imp3.plot_pred(units=units, bind_interaction=False)\n\n\ndata_imp3\n\n\ngpdata3.data.corr()\n\n\ngp_imp3.learner.model.covar_module.Lambda.detach()\n\nthis is the value of the length scale of the RBF latent kernel\n\ngp_imp3.learner.model.covar_module.latent_kernel.lengthscale.detach()\n\n\ngp_imp3.learner.model.covar_module.latent_kernel.lengthscale.detach()\n\n\n\n\n\n\nTrying to see how the model works with a continous gap of 10% the length of the dataset for all variables\n\ngpd_gap = GPFADataTest(hai).add_gap(20, variables = ['TA', 'SW_IN', 'LW_IN', 'VPD'])\n\n\ngp_gap = GPFAImputation(gpd_gap.data, gpd_gap.tidy_df(complete=True, is_missing=True))\n\n\ngp_gap\n\n\n%time gp_gap.impute()\n\n\ngap_plot= gp_gap.plot_pred(units=units, properties =  {'height': 190 , 'width': 380})\n\ngap_plot.save(here(\"analysis/plots\") /\" plot_hai_winter_4_var_200_obs_gap_20.vl.json\")\ngap_plot\n\n\nprint(gp_gap.rmse().to_markdown(index=False))\n\n\nprint(pd.DataFrame(gp_gap.learner.model.covar_module.Lambda.detach().numpy()).to_markdown(index=False))\n\n\npsi = pd.DataFrame(gp_gap.learner.model.covar_module.psi.detach().numpy())\npsi.insert(0, \"variable\", meteo_vars.values())\nprint(psi.to_markdown(index=False))\n\n\ngp_gap.learner.model.covar_module.latent_kernel.lengthscale.detach()\n\n\nlosses = pd.DataFrame(gp_gap.learner.losses.cpu().numpy(), columns=['loss'])\n\np = losses.plot()\nplt.savefig(here('analysis/plots/') /'loss_plot_hai_winter_4_var_200_obs_gap_20.png')\np"
  },
  {
    "objectID": "var_distribution.html",
    "href": "var_distribution.html",
    "title": "GPFA Imputation Analysis",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\n\n\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom pyprojroot import here\nimport matplotlib.pyplot as plt\nimport altair as alt\nimport polars as pl\n\nfrom gpfa_imputation.gap_finder import scan_fluxnet_csv\n\nfrom gpfa_imputation.utils import cache_disk\n\n\n\nload Hainich dataset\n\nhai_path = here(\"data\") / \"FLX_DE-Hai_FLUXNET2015_FULLSET_HH_2000-2012_1-4.csv\"\n# hai_raw = pd.read_csv(here(\"data\") / hai_path, na_values=[\"-9999\", \"-9999.99\"], parse_dates=[0, 1], nrows=20_000)\n\n\nmeteo_vars = {\n    \"TA_F\": \"TA\",\n    \"SW_IN_F\": \"SW_IN\",\n    \"LW_IN_F\": \"LW_IN\",\n    \"VPD_F\": \"VPD\",\n    #\"PA\": \"PA\"\n}\n\nunits = {\n    'TA': '°C',\n    'SW_IN': 'W m-2',\n    'LW_IN': 'W m-2',\n    'VPD': 'hPa'\n}\n\nhai = scan_fluxnet_csv(hai_path, convert_dates=True).rename(meteo_vars).select([pl.col(\"end\").alias(\"time\"), *meteo_vars.values()])\n\nhai.fetch(10)\n\n\n\n\nshape: (10, 5)\n\n\n\n\ntime\n\n\nTA\n\n\nSW_IN\n\n\nLW_IN\n\n\nVPD\n\n\n\n\ndatetime[μs]\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\n\n\n\n\n2000-01-01 00:30:00\n\n\n-0.6\n\n\n0.0\n\n\n302.475\n\n\n0.222\n\n\n\n\n2000-01-01 01:00:00\n\n\n-0.65\n\n\n0.0\n\n\n302.475\n\n\n0.122\n\n\n\n\n2000-01-01 01:30:00\n\n\n-0.58\n\n\n0.0\n\n\n301.677\n\n\n0.09\n\n\n\n\n2000-01-01 02:00:00\n\n\n-0.51\n\n\n0.0\n\n\n301.677\n\n\n0.11\n\n\n\n\n2000-01-01 02:30:00\n\n\n-0.49\n\n\n0.0\n\n\n301.677\n\n\n0.102\n\n\n\n\n2000-01-01 03:00:00\n\n\n-0.4\n\n\n0.0\n\n\n301.677\n\n\n0.111\n\n\n\n\n2000-01-01 03:30:00\n\n\n-0.36\n\n\n0.0\n\n\n301.677\n\n\n0.109\n\n\n\n\n2000-01-01 04:00:00\n\n\n-0.35\n\n\n0.0\n\n\n301.677\n\n\n0.107\n\n\n\n\n2000-01-01 04:30:00\n\n\n-0.28\n\n\n0.0\n\n\n308.046\n\n\n0.122\n\n\n\n\n2000-01-01 05:00:00\n\n\n-0.27\n\n\n0.0\n\n\n308.046\n\n\n0.138\n\n\n\n\n\n\n\n\nhai_td = hai.melt('time')\n\n\nhai_td.fetch(3)\n\n\n\n\nshape: (12, 3)\n\n\n\n\ntime\n\n\nvariable\n\n\nvalue\n\n\n\n\ndatetime[μs]\n\n\nstr\n\n\nf64\n\n\n\n\n\n\n2000-01-01 00:30:00\n\n\n\"TA\"\n\n\n-0.6\n\n\n\n\n2000-01-01 01:00:00\n\n\n\"TA\"\n\n\n-0.65\n\n\n\n\n2000-01-01 01:30:00\n\n\n\"TA\"\n\n\n-0.58\n\n\n\n\n2000-01-01 00:30:00\n\n\n\"SW_IN\"\n\n\n0.0\n\n\n\n\n2000-01-01 01:00:00\n\n\n\"SW_IN\"\n\n\n0.0\n\n\n\n\n2000-01-01 01:30:00\n\n\n\"SW_IN\"\n\n\n0.0\n\n\n\n\n2000-01-01 00:30:00\n\n\n\"LW_IN\"\n\n\n302.475\n\n\n\n\n2000-01-01 01:00:00\n\n\n\"LW_IN\"\n\n\n302.475\n\n\n\n\n2000-01-01 01:30:00\n\n\n\"LW_IN\"\n\n\n301.677\n\n\n\n\n2000-01-01 00:30:00\n\n\n\"VPD\"\n\n\n0.222\n\n\n\n\n2000-01-01 01:00:00\n\n\n\"VPD\"\n\n\n0.122\n\n\n\n\n2000-01-01 01:30:00\n\n\n\"VPD\"\n\n\n0.09\n\n\n\n\n\n\n\n\n\n\n\nhai.drop('time').collect().to_pandas().hist(figsize=(15,10));\n\n\n\n\n\n# should to the binning before the plot\n# alt.Chart(hai_td.collect().to_pandas()).mark_line().encode(\n#     x = 'value',\n#     y = 'density()',\n#     facet = alt.Facet('variable', columns=2)\n# )\n\n\n\n\nCode inspired from source: https://towardsdatascience.com/altair-plot-deconstruction-visualizing-the-correlation-structure-of-weather-data-38fb5668c5b1\n\nhai_p = hai.collect().to_pandas().set_index('time')\n\n\nhai_p.corr()\n\n\n\n\n\n  \n    \n      \n      TA\n      SW_IN\n      LW_IN\n      VPD\n    \n  \n  \n    \n      TA\n      1.000000\n      0.432321\n      0.639556\n      0.735412\n    \n    \n      SW_IN\n      0.432321\n      1.000000\n      0.126278\n      0.533506\n    \n    \n      LW_IN\n      0.639556\n      0.126278\n      1.000000\n      0.270424\n    \n    \n      VPD\n      0.735412\n      0.533506\n      0.270424\n      1.000000\n    \n  \n\n\n\n\n\ndef corr_mask(size):\n    corr_mask = np.zeros((size,size), dtype=bool)\n    for i in range(size):\n        for j in range(size):\n            corr_mask[i,j] = True if i >= j else False\n    return corr_mask\n\n\ncorr_mask(len(hai_p.columns))\n\narray([[ True, False, False, False],\n       [ True,  True, False, False],\n       [ True,  True,  True, False],\n       [ True,  True,  True,  True]])\n\n\n\nhai_p = hai_p[sorted(hai_p.columns)] # need to properly plot half a corr matrix\n\n\ncor_hai = (hai_p\n              .corr().mask(~corr_mask(len(hai_p.columns))).stack()\n              .reset_index()     # The stacking results in an index on the correlation values, we need the index as normal columns for Altair\n              .rename(columns={0: 'correlation', 'level_0': 'variable', 'level_1': 'variable2'}))\ncor_hai['correlation_label'] = cor_hai['correlation'].map('{:.2f}'.format)  # Round to 2 decimal\ncor_hai\n\n\n\n\n\n  \n    \n      \n      variable\n      variable2\n      correlation\n      correlation_label\n    \n  \n  \n    \n      0\n      LW_IN\n      LW_IN\n      1.000000\n      1.00\n    \n    \n      1\n      SW_IN\n      LW_IN\n      0.126278\n      0.13\n    \n    \n      2\n      SW_IN\n      SW_IN\n      1.000000\n      1.00\n    \n    \n      3\n      TA\n      LW_IN\n      0.639556\n      0.64\n    \n    \n      4\n      TA\n      SW_IN\n      0.432321\n      0.43\n    \n    \n      5\n      TA\n      TA\n      1.000000\n      1.00\n    \n    \n      6\n      VPD\n      LW_IN\n      0.270424\n      0.27\n    \n    \n      7\n      VPD\n      SW_IN\n      0.533506\n      0.53\n    \n    \n      8\n      VPD\n      TA\n      0.735412\n      0.74\n    \n    \n      9\n      VPD\n      VPD\n      1.000000\n      1.00\n    \n  \n\n\n\n\n\nimport numpy as np\n\ndef compute_2d_histogram(var1, var2, df, density=True, bins=20):\n    H, xedges, yedges = np.histogram2d(df[var1], df[var2], bins=bins, density=density)\n    H[H == 0] = np.nan\n\n    # Create a nice variable that shows the bin boundaries\n    \n    x_width = xedges[1] - xedges[0] # all bins have same width\n    xedges = pd.Series(xedges[:-1] + x_width /2)\n    \n    y_width = yedges[1] - yedges[0] # all bins have same width\n    yedges = pd.Series(yedges[:-1] + y_width /2)\n    \n    # Cast to long format using melt\n    res = pd.DataFrame(H, \n                       index=yedges, \n                       columns=xedges).reset_index().melt(\n                            id_vars='index'\n                       ).rename(columns={'index': 'value2', \n                                         'value': 'count',\n                                         'variable': 'value'})\n    \n\n    res['variable'] = var1\n    res['variable2'] = var2 \n    return res.dropna() # Drop all combinations for which no values where found\n\n\nh, xe, ye = np.histogram2d(hai_p['VPD'], hai_p['TA'])\n\n\nx_width = xe[1] - xe[0] # all bins have same width\nxe = pd.Series(xe + x_width /2)\n\n\nh.shape\n\n(10, 10)\n\n\n\nxe\n\n0      2.38335\n1      7.15005\n2     11.91675\n3     16.68345\n4     21.45015\n5     26.21685\n6     30.98355\n7     35.75025\n8     40.51695\n9     45.28365\n10    50.05035\ndtype: float64\n\n\n\nhai_binned = pd.concat([compute_2d_histogram(var1, var2, hai_p) for var1 in meteo_vars.values() for var2 in meteo_vars.values()])\nhai_binned.head()\n\n\n\n\n\n  \n    \n      \n      value2\n      value\n      count\n      variable\n      variable2\n    \n  \n  \n    \n      0\n      -17.19025\n      -17.19025\n      0.000083\n      TA\n      TA\n    \n    \n      21\n      -14.47075\n      -14.47075\n      0.000224\n      TA\n      TA\n    \n    \n      42\n      -11.75125\n      -11.75125\n      0.000574\n      TA\n      TA\n    \n    \n      63\n      -9.03175\n      -9.03175\n      0.001188\n      TA\n      TA\n    \n    \n      84\n      -6.31225\n      -6.31225\n      0.003781\n      TA\n      TA\n    \n  \n\n\n\n\n\n# Define selector\nvar_sel_cor = alt.selection_single(fields=['variable', 'variable2'], clear=False, \n                                  init={'variable': 'TA', 'variable2': 'SW_IN'})\n\n# Define correlation heatmap\nbase = alt.Chart(cor_hai).encode(\n    x='variable2:O',\n    y='variable:O'    \n)\n\ntext = base.mark_text().encode(\n    text='correlation_label',\n    color=alt.condition(\n        alt.datum.correlation > 0.5, \n        alt.value('white'),\n        alt.value('black')\n    )\n)\n\ncor_plot = base.mark_rect().encode(\n    color=alt.condition(var_sel_cor, alt.value('pink'), 'correlation:Q')\n).add_selection(var_sel_cor)\n\n# Define 2d binned histogram plot\nscat_plot = alt.Chart(hai_binned).transform_filter(\n    var_sel_cor\n).mark_rect().encode(\n    alt.X('value:N', axis=alt.Axis(format=\".4\")), \n    alt.Y('value2:N', axis=alt.Axis(format=\".4\"), sort='descending'),\n    alt.Color('count:Q', scale=alt.Scale(scheme='blues'))\n)\n\n# Combine all plots. hconcat plots both side-by-side \nalt.hconcat((cor_plot + text).properties(width=350, height=350), scat_plot.properties(width=350, height=350)).resolve_scale(color='independent')\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\nhai_p = hai.collect().to_pandas().set_index('time')\n\n\nhai_td_p = hai_td.collect().to_pandas().set_index('time')"
  },
  {
    "objectID": "analyze_gaps_fluxnet.html",
    "href": "analyze_gaps_fluxnet.html",
    "title": "GPFA Imputation Analysis",
    "section": "",
    "text": "from IPython.display import display\nfrom ipywidgets import widgets, interact\n\n\nfrom pathlib import Path\nimport polars as pl\nfrom datetime import datetime\nfrom fastcore.utils import * # support of ls for paths\nimport matplotlib.pyplot as plt\nimport altair as alt\n\n\nout_dir = Path(\"../../fluxnet/gap_stat\")\ndownload_dir = Path(\"/run/media/simone/Simone DATI/fluxnet_all\")\n\n\nsite_info = pl.read_parquet(out_dir / \"../site_info.parquet\").select([\n    pl.col(\"start\").cast(pl.Utf8).str.strptime(pl.Datetime, \"%Y%m%d%H%M\"),\n    pl.col(\"end\").cast(pl.Utf8).str.strptime(pl.Datetime, \"%Y%m%d%H%M\"),\n    pl.col(\"site\").cast(pl.Categorical).sort()\n])\n\n\nsite_info.head()\n\n\n\n\nshape: (5, 3)\n\n\n\n\nstart\n\n\nend\n\n\nsite\n\n\n\n\ndatetime[μs]\n\n\ndatetime[μs]\n\n\ncat\n\n\n\n\n\n\n2009-01-01 00:30:00\n\n\n2012-01-01 00:00:00\n\n\n\"AR-SLu\"\n\n\n\n\n2009-01-01 00:30:00\n\n\n2013-01-01 00:00:00\n\n\n\"AR-Vir\"\n\n\n\n\n2002-01-01 00:30:00\n\n\n2013-01-01 00:00:00\n\n\n\"AT-Neu\"\n\n\n\n\n2007-01-01 00:30:00\n\n\n2010-01-01 00:00:00\n\n\n\"AU-Ade\"\n\n\n\n\n2010-01-01 00:30:00\n\n\n2015-01-01 00:00:00\n\n\n\"AU-ASM\"\n\n\n\n\n\n\n\n\ndef duration_n_obs(duration):\n    \"converts a duration into a n of fluxnet observations\"\n    return abs(int(duration.total_seconds() / (30 * 60)))\n\n\nduration_n_obs(site_info[1, \"start\"] - site_info[1, \"end\"])\n\n70127\n\n\n\n# maybe this code should actually go in 20_gap_finding\nfiles = out_dir.ls()\nfiles.sort() # need to sort to match the site_info\nsites = []\nfor i, path in enumerate(files):\n    sites.append(pl.scan_parquet(path).with_columns([\n        pl.lit(site_info[i, \"site\"]).alias(\"site\"),\n        pl.lit(duration_n_obs(site_info[i, \"start\"] -  site_info[i, \"end\"])).alias(\"total_obs\"),\n        pl.col(\"TIMESTAMP_END\").cast(pl.Utf8).str.strptime(pl.Datetime, \"%Y%m%d%H%M\").alias(\"end\"),\n    ]).drop(\"TIMESTAMP_END\"))\n\n\ngap_stat = pl.concat(sites)\n\n\ngap_stat.head().fetch(5)\n\n\n\n\nshape: (5, 5)\n\n\n\n\ngap_len\n\n\nvariable\n\n\nsite\n\n\ntotal_obs\n\n\nend\n\n\n\n\nu32\n\n\nstr\n\n\nstr\n\n\ni32\n\n\ndatetime[μs]\n\n\n\n\n\n\n16992\n\n\n\"TA_F_MDS_QC\"\n\n\n\"AR-SLu\"\n\n\n52559\n\n\n2009-01-01 00:30:00\n\n\n\n\n5\n\n\n\"TA_F_MDS_QC\"\n\n\n\"AR-SLu\"\n\n\n52559\n\n\n2009-12-21 11:00:00\n\n\n\n\n1\n\n\n\"TA_F_MDS_QC\"\n\n\n\"AR-SLu\"\n\n\n52559\n\n\n2009-12-21 17:00:00\n\n\n\n\n1\n\n\n\"TA_F_MDS_QC\"\n\n\n\"AR-SLu\"\n\n\n52559\n\n\n2010-01-06 13:00:00\n\n\n\n\n3\n\n\n\"TA_F_MDS_QC\"\n\n\n\"AR-SLu\"\n\n\n52559\n\n\n2010-01-07 13:00:00\n\n\n\n\n\n\n\n\ndef filter_variables(variables = [\"TA_F_QC\", \"SW_IN_QC\", \"LW_IN_QC\", \"VPD_F_QC\"]):\n    expr = False\n    for var in variables:\n        expr |= pl.col(\"variable\") == var\n    return expr\n\n\ndef pl_in(col, values):\n    expr = False\n    for val in values:\n        expr |= pl.col(col) == val\n    return expr\n\nsome sites have a lot of data missing, with the avg gap length of several years, so is seems that the year can have an impact\nImportant! here the 3 possibles gap value of a QC variable are considered as one (null, 1, 2) we should co\n\ngap_stat.filter(\n    pl.col(\"variable\") == \"TA_F_QC\" \n).groupby(\"site\").agg([\n    pl.col(\"gap_len\").mean().alias(\"mean\"),\n    (pl.col(\"gap_len\").sum() / pl.col(\"total_obs\").first()).alias(\"frac_gap\")\n]).collect()\n\n\n\n\nshape: (205, 3)\n\n\n\n\nsite\n\n\nmean\n\n\nfrac_gap\n\n\n\n\nstr\n\n\nf64\n\n\nf64\n\n\n\n\n\n\n\"US-Blo\"\n\n\n188.373874\n\n\n0.216887\n\n\n\n\n\"SN-Dhr\"\n\n\n1113.466667\n\n\n0.238168\n\n\n\n\n\"US-Wi0\"\n\n\n175.793103\n\n\n0.581997\n\n\n\n\n\"FI-Jok\"\n\n\n88.463235\n\n\n0.17156\n\n\n\n\n\"US-Me1\"\n\n\n29.280702\n\n\n0.142702\n\n\n\n\n\"AR-SLu\"\n\n\n962.96875\n\n\n0.586293\n\n\n\n\n\"AU-Cpr\"\n\n\n1174.846154\n\n\n0.174256\n\n\n\n\n\"AU-RDF\"\n\n\n242.125\n\n\n0.441842\n\n\n\n\n\"IT-Isp\"\n\n\n2.0\n\n\n0.000114\n\n\n\n\n\"US-ARM\"\n\n\n2042.666667\n\n\n0.034949\n\n\n\n\n\"CN-Cng\"\n\n\n2228.0\n\n\n0.158855\n\n\n\n\n\"CA-SF3\"\n\n\n345.108108\n\n\n0.242833\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"AU-Wom\"\n\n\n19.779264\n\n\n0.067475\n\n\n\n\n\"FI-Hyy\"\n\n\n16.82732\n\n\n0.039199\n\n\n\n\n\"US-SRG\"\n\n\n152.857143\n\n\n0.034872\n\n\n\n\n\"US-Myb\"\n\n\n13728.0\n\n\n0.156628\n\n\n\n\n\"FR-LBr\"\n\n\n490.478261\n\n\n0.049489\n\n\n\n\n\"US-Tw3\"\n\n\n6864.0\n\n\n0.195896\n\n\n\n\n\"DE-Tha\"\n\n\n34.736842\n\n\n0.009906\n\n\n\n\n\"US-Tw1\"\n\n\n9312.0\n\n\n0.177011\n\n\n\n\n\"AU-Stp\"\n\n\n63.535897\n\n\n0.20189\n\n\n\n\n\"CA-TP2\"\n\n\n109.571429\n\n\n0.029173\n\n\n\n\n\"BE-Lon\"\n\n\n14.16\n\n\n0.067913\n\n\n\n\n\"US-Wi5\"\n\n\n45.790249\n\n\n2.299027\n\n\n\n\n\n\n\n\ngaps_year_site_ta = gap_stat.filter(\n    pl.col(\"variable\") == \"TA_F_QC\" \n).with_column(\n  pl.col(\"end\").dt.year().alias(\"year\")  \n).groupby([\"site\", \"year\"]).agg([\n    pl.col(\"gap_len\").mean().alias(\"mean\"),\n    (pl.col(\"gap_len\").sum() / (48 * 365)).alias(\"frac_gap\")\n]).sort([\"site\", \"year\"]).collect()\n\n\ngaps_year_site_ta.describe()\n\n\n\n\nshape: (7, 5)\n\n\n\n\ndescribe\n\n\nsite\n\n\nyear\n\n\nmean\n\n\nfrac_gap\n\n\n\n\nstr\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\n\n\n\n\n\"count\"\n\n\n\"1232\"\n\n\n1232.0\n\n\n1232.0\n\n\n1232.0\n\n\n\n\n\"null_count\"\n\n\n\"0\"\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\n\n\"mean\"\n\n\nnull\n\n\n2007.18263\n\n\n826.696712\n\n\n0.156607\n\n\n\n\n\"std\"\n\n\nnull\n\n\n4.633427\n\n\n3339.649175\n\n\n0.350794\n\n\n\n\n\"min\"\n\n\n\"AR-SLu\"\n\n\n1991.0\n\n\n1.0\n\n\n0.000057\n\n\n\n\n\"max\"\n\n\n\"ZM-Mon\"\n\n\n2015.0\n\n\n52608.0\n\n\n7.686073\n\n\n\n\n\"median\"\n\n\nnull\n\n\n2008.0\n\n\n42.166667\n\n\n0.030822\n\n\n\n\n\n\n\n\ngaps_year_site_ta.filter(pl.col(\"frac_gap\") >=1)\n\n\n\n\nshape: (15, 4)\n\n\n\n\nsite\n\n\nyear\n\n\nmean\n\n\nfrac_gap\n\n\n\n\nstr\n\n\ni32\n\n\nf64\n\n\nf64\n\n\n\n\n\n\n\"BE-Bra\"\n\n\n2003\n\n\n17738.0\n\n\n1.012443\n\n\n\n\n\"BR-Sa1\"\n\n\n2006\n\n\n4167.4\n\n\n1.189326\n\n\n\n\n\"CA-NS1\"\n\n\n2001\n\n\n1219.941176\n\n\n1.183733\n\n\n\n\n\"CA-NS3\"\n\n\n2002\n\n\n4580.8\n\n\n1.307306\n\n\n\n\n\"DE-Lnf\"\n\n\n2007\n\n\n52608.0\n\n\n3.00274\n\n\n\n\n\"IT-Cpz\"\n\n\n1998\n\n\n228.990566\n\n\n1.385445\n\n\n\n\n\"IT-Ro2\"\n\n\n2008\n\n\n1464.5\n\n\n1.504623\n\n\n\n\n\"RU-Cok\"\n\n\n2003\n\n\n411.729167\n\n\n1.128025\n\n\n\n\n\"SJ-Adv\"\n\n\n2011\n\n\n7235.0\n\n\n1.23887\n\n\n\n\n\"US-Blo\"\n\n\n1997\n\n\n292.784615\n\n\n1.086244\n\n\n\n\n\"US-CRT\"\n\n\n2004\n\n\n17545.0\n\n\n1.001427\n\n\n\n\n\"US-LWW\"\n\n\n2011\n\n\n52608.0\n\n\n3.00274\n\n\n\n\n\"US-Syv\"\n\n\n2009\n\n\n52560.0\n\n\n3.0\n\n\n\n\n\"US-WCr\"\n\n\n2007\n\n\n17520.0\n\n\n1.0\n\n\n\n\n\"ZM-Mon\"\n\n\n2000\n\n\n22443.333333\n\n\n7.686073\n\n\n\n\n\n\n\n\ngap_stat.filter(\n    pl.col(\"variable\") == \"TA_F_QC\" \n).filter(pl_in(\"site\", [\"ZM-Mon\"])).collect()\n\n\n\n\nshape: (8, 5)\n\n\n\n\ngap_len\n\n\nvariable\n\n\nsite\n\n\ntotal_obs\n\n\nend\n\n\n\n\nu32\n\n\nstr\n\n\nstr\n\n\ni32\n\n\ndatetime[μs]\n\n\n\n\n\n\n2913\n\n\n\"TA_F_QC\"\n\n\n\"ZM-Mon\"\n\n\n175343\n\n\n2000-01-01 00:30:00\n\n\n\n\n1\n\n\n\"TA_F_QC\"\n\n\n\"ZM-Mon\"\n\n\n175343\n\n\n2000-03-02 17:30:00\n\n\n\n\n1\n\n\n\"TA_F_QC\"\n\n\n\"ZM-Mon\"\n\n\n175343\n\n\n2000-03-04 04:30:00\n\n\n\n\n1\n\n\n\"TA_F_QC\"\n\n\n\"ZM-Mon\"\n\n\n175343\n\n\n2000-03-04 09:00:00\n\n\n\n\n1\n\n\n\"TA_F_QC\"\n\n\n\"ZM-Mon\"\n\n\n175343\n\n\n2000-03-10 11:30:00\n\n\n\n\n131743\n\n\n\"TA_F_QC\"\n\n\n\"ZM-Mon\"\n\n\n175343\n\n\n2000-03-11 02:00:00\n\n\n\n\n1\n\n\n\"TA_F_QC\"\n\n\n\"ZM-Mon\"\n\n\n175343\n\n\n2008-01-30 12:00:00\n\n\n\n\n7753\n\n\n\"TA_F_QC\"\n\n\n\"ZM-Mon\"\n\n\n175343\n\n\n2009-07-23 12:00:00\n\n\n\n\n\n\n\n\ngap_stat.filter(\n    pl.col(\"variable\") == \"TA_F_QC\" \n).filter(pl_in(\"site\", [\"DE-Lnf\"])).collect()\n\n\n\n\nshape: (6, 5)\n\n\n\n\ngap_len\n\n\nvariable\n\n\nsite\n\n\ntotal_obs\n\n\nend\n\n\n\n\nu32\n\n\nstr\n\n\nstr\n\n\ni32\n\n\ndatetime[μs]\n\n\n\n\n\n\n5116\n\n\n\"TA_F_QC\"\n\n\n\"DE-Lnf\"\n\n\n192863\n\n\n2002-01-01 00:30:00\n\n\n\n\n52608\n\n\n\"TA_F_QC\"\n\n\n\"DE-Lnf\"\n\n\n192863\n\n\n2007-01-01 00:30:00\n\n\n\n\n1\n\n\n\"TA_F_QC\"\n\n\n\"DE-Lnf\"\n\n\n192863\n\n\n2010-04-15 10:00:00\n\n\n\n\n20\n\n\n\"TA_F_QC\"\n\n\n\"DE-Lnf\"\n\n\n192863\n\n\n2012-08-14 13:00:00\n\n\n\n\n45\n\n\n\"TA_F_QC\"\n\n\n\"DE-Lnf\"\n\n\n192863\n\n\n2012-10-09 14:00:00\n\n\n\n\n2\n\n\n\"TA_F_QC\"\n\n\n\"DE-Lnf\"\n\n\n192863\n\n\n2012-10-16 13:30:00\n\n\n\n\n\n\n\n\ndef visualize_by_site(df):\n    sites = df[\"site\"].unique()\n    for site in sites:\n        yield df.filter(pl.col(\"site\") == site)\n\n\nby_site = list(visualize_by_site(gaps_year_site_ta))\n\n\nbutton_next = widgets.Button(description=\"Next\", icon=\"arrow-right\")\nbutton_prev = widgets.Button(description=\"Previous\", icon=\"arrow-left\")\noutput = widgets.Output()\n\ndisplay(button_next, button_prev, output)\n\ni = 0\n\ndef update_view():\n    with output:\n        print(f\"{i} of {len(by_site)}\")\n        display(by_site[i])\n    output.clear_output(wait=True)\n\ndef on_next(b):\n    global i\n    if i < len(by_site):\n        i +=1\n    else:\n        button_next.disabled = True\n    update_view()\n\ndef on_prev(b):\n    global i\n    if i > 0:\n        i -=1\n    else:\n        button_prev.disabled = True\n    update_view()\n    \n\nbutton_next.on_click(on_next)\nbutton_prev.on_click(on_prev)\n\n\n\n\n\n\n\n\n\n\n\nta_gaps = gap_stat.filter(\n    pl.col(\"variable\") == \"TA_F_QC\" \n).collect()\n\n\nta_gaps.to_pandas().hist(column=\"gap_len\")\nplt.yscale('log')\n\n\n\n\n\n\n\nall_vars = gap_stat.select(pl.col(\"variable\").unique().sort()).collect()[\"variable\"]\n\n\n@interact(var = all_vars)\ndef plot_var_dist(var):\n    ta_gaps = gap_stat.filter(\n        pl.col(\"variable\") == var \n    ).collect().to_pandas().hist(\"gap_len\")\n    plt.yscale('log') \n    plt.title(var)\n\n\n\n\n\nall_sites = gap_stat.select(pl.col(\"site\").unique().sort()).collect()[\"site\"]\n\n\n@interact(var = all_vars, site = all_sites)\ndef plot_var_dist(var, site):\n    ta_gaps = gap_stat.filter(\n        (pl.col(\"variable\") == var) & (pl.col(\"site\") == site)\n    ).collect().to_pandas().hist(\"gap_len\")\n    plt.yscale('log') \n    plt.title(var)\n\n\n\n\n\n@interact(var = all_vars, site = all_sites)\ndef plot_var_dist(var, site, small=False):\n    ta_gaps = gap_stat.filter(\n        (pl.col(\"variable\") == var) & (pl.col(\"site\") == site)\n    ).filter(\n        pl.col(\"gap_len\") < 200 if small else True\n    ).collect().to_pandas().hist(\"gap_len\")\n    plt.title(f\"{site}: {var} - { 'gaps < 200' if small else 'all gaps'}\")\n\n\n\n\n\n\n\n\nvar_gaps = gap_stat.filter(\n        (pl.col(\"variable\") == 'TA_F_QC')\n    ).filter(\n        pl.col(\"gap_len\") < 20000\n    ).sort(pl.col(\"gap\n        \n    ).collect().to_pandas()\n\n\nalt.data_transformers.enable('data_server')\n\nDataTransformerRegistry.enable('data_server')\n\n\n\n \nalt.Chart(var_gaps).mark_boxplot().encode(\n    y=alt.Y('site', sort=alt.Sort(alt.EncodingSortField(field=\"y\", op=\"mean\", order=\"ascending\"))),\n    x='gap_len'\n)\n\n\n\n\n\n\n\nwidgets.IntSlider?\n\n\nInit signature: widgets.IntSlider(value=None, min=None, max=None, step=None, **kwargs)\nDocstring:     \nSlider widget that represents an integer bounded from above and below.\n    \nInit docstring:\nParameters\n----------\nvalue: integer\n    The initial value.\nmin: integer\n    The lower limit for the value.\nmax: integer\n    The upper limit for the value.\nstep: integer\n    The step between allowed values.\nbehavior : str\n    slider handle and connector dragging behavior. Default is 'drag-tap'.\nFile:           ~/.local/lib/python3.10/site-packages/ipywidgets/widgets/widget_int.py\nType:           MetaHasTraits\nSubclasses:     \n\n\n\n\n\n@interact(var = all_vars)\ndef plot_var_dist(var, max_len=widgets.IntSlider(1000, 100, 20_000, 100)):\n    var_gaps = gap_stat.filter(\n        (pl.col(\"variable\") == var)\n    ).filter(\n        pl.col(\"gap_len\") < max_len\n    ).collect().to_pandas()\n    \n    display(alt.Chart(var_gaps).mark_boxplot().encode(\n        y=alt.Y('site', sort=alt.Sort(alt.EncodingSortField(field=\"y\", op=\"mean\", order=\"ascending\"))),\n        x='gap_len'\n    ))\n\n\n\n\n\ngap_stat.with_columns(\n    (pl.col(\"gap_len\") / pl.col(\"total_obs\")).alias(\"frac_gap\")\n).head().collect()\n\n\n\n\nshape: (5, 6)\n\n\n\n\ngap_len\n\n\nvariable\n\n\nsite\n\n\ntotal_obs\n\n\nend\n\n\nfrac_gap\n\n\n\n\nu32\n\n\nstr\n\n\nstr\n\n\ni32\n\n\ndatetime[μs]\n\n\nf64\n\n\n\n\n\n\n16992\n\n\n\"TA_F_MDS_QC\"\n\n\n\"AR-SLu\"\n\n\n52559\n\n\n2009-01-01 00:30:00\n\n\n0.323294\n\n\n\n\n5\n\n\n\"TA_F_MDS_QC\"\n\n\n\"AR-SLu\"\n\n\n52559\n\n\n2009-12-21 11:00:00\n\n\n0.000095\n\n\n\n\n1\n\n\n\"TA_F_MDS_QC\"\n\n\n\"AR-SLu\"\n\n\n52559\n\n\n2009-12-21 17:00:00\n\n\n0.000019\n\n\n\n\n1\n\n\n\"TA_F_MDS_QC\"\n\n\n\"AR-SLu\"\n\n\n52559\n\n\n2010-01-06 13:00:00\n\n\n0.000019\n\n\n\n\n3\n\n\n\"TA_F_MDS_QC\"\n\n\n\"AR-SLu\"\n\n\n52559\n\n\n2010-01-07 13:00:00\n\n\n0.000057\n\n\n\n\n\n\n\n\ngap_stat.with_columns(\n    (pl.col(\"gap_len\") / pl.col(\"total_obs\")).alias(\"frac_gap\")\n).groupby([\"variable\", \"site\"]).agg(pl.col(\"gap_len\").sum()).head().collect()\n\n\n\n\nshape: (5, 3)\n\n\n\n\nvariable\n\n\nsite\n\n\ngap_len\n\n\n\n\nstr\n\n\nstr\n\n\nu32\n\n\n\n\n\n\n\"TA_F_MDS_QC\"\n\n\n\"CH-Fru\"\n\n\n16804\n\n\n\n\n\"SW_IN_F_QC\"\n\n\n\"CZ-BK2\"\n\n\n50520\n\n\n\n\n\"NEE_VUT_MEAN_Q...\n\n\n\"DE-Lkb\"\n\n\n66368\n\n\n\n\n\"SW_IN_F_QC\"\n\n\n\"AU-DaP\"\n\n\n23880\n\n\n\n\n\"NEE_CUT_REF_QC...\n\n\n\"CG-Tch\"\n\n\n51474\n\n\n\n\n\n\n\n\ngap_stat.with_columns(\n    (pl.col(\"gap_len\") / pl.col(\"total_obs\")).alias(\"frac_gap\")\n).groupby([\"variable\", \"site\"]).agg(\n    pl.col(\"gap_len\").sum() / pl.col(\"total_obs\").first()\n).groupby(\"variable\").agg(pl.col(\"gap_len\").mean()).collect()\n\n\n\n\nshape: (53, 2)\n\n\n\n\nvariable\n\n\ngap_len\n\n\n\n\nstr\n\n\nf64\n\n\n\n\n\n\n\"NEE_CUT_95_QC\"\n\n\n0.831628\n\n\n\n\n\"SWC_F_MDS_6_QC...\n\n\n0.519709\n\n\n\n\n\"TS_F_MDS_4_QC\"\n\n\n0.410402\n\n\n\n\n\"TS_F_MDS_7_QC\"\n\n\n0.53222\n\n\n\n\n\"TA_F_QC\"\n\n\n0.198846\n\n\n\n\n\"NEE_CUT_REF_QC...\n\n\n0.785538\n\n\n\n\n\"CO2_F_MDS_QC\"\n\n\n0.408158\n\n\n\n\n\"VPD_F_MDS_QC\"\n\n\n0.245457\n\n\n\n\n\"NEE_CUT_MEAN_Q...\n\n\n0.954132\n\n\n\n\n\"SWC_F_MDS_1_QC...\n\n\n0.314847\n\n\n\n\n\"TS_F_MDS_6_QC\"\n\n\n0.424062\n\n\n\n\n\"TS_F_MDS_5_QC\"\n\n\n0.40489\n\n\n\n\n...\n\n\n...\n\n\n\n\n\"NEE_VUT_84_QC\"\n\n\n0.773485\n\n\n\n\n\"TS_F_MDS_2_QC\"\n\n\n0.287485\n\n\n\n\n\"SWC_F_MDS_5_QC...\n\n\n0.528756\n\n\n\n\n\"LW_IN_JSB_QC\"\n\n\n0.260428\n\n\n\n\n\"NEE_VUT_REF_QC...\n\n\n0.754275\n\n\n\n\n\"NEE_VUT_16_QC\"\n\n\n0.76001\n\n\n\n\n\"H_F_MDS_QC\"\n\n\n0.401424\n\n\n\n\n\"P_F_QC\"\n\n\n0.311598\n\n\n\n\n\"SW_IN_F_MDS_QC...\n\n\n0.16772\n\n\n\n\n\"NEE_VUT_75_QC\"\n\n\n0.763633\n\n\n\n\n\"WS_F_QC\"\n\n\n0.257303\n\n\n\n\n\"NEE_VUT_50_QC\"\n\n\n0.751421\n\n\n\n\n\n\n\n\ngap_stat.with_columns(\n    (pl.col(\"gap_len\") / pl.col(\"total_obs\")).alias(\"frac_gap\")\n).groupby([\"variable\", \"site\"]).agg(\n    pl.col(\"gap_len\").sum() / pl.col(\"total_obs\").first()\n).filter(pl.col(\"variable\") == \"TA_F_QC\").collect()\n\n\n\n\nshape: (205, 3)\n\n\n\n\nvariable\n\n\nsite\n\n\ngap_len\n\n\n\n\nstr\n\n\nstr\n\n\nf64\n\n\n\n\n\n\n\"TA_F_QC\"\n\n\n\"CH-Dav\"\n\n\n0.062063\n\n\n\n\n\"TA_F_QC\"\n\n\n\"US-Tw2\"\n\n\n0.518483\n\n\n\n\n\"TA_F_QC\"\n\n\n\"PA-SPs\"\n\n\n0.081377\n\n\n\n\n\"TA_F_QC\"\n\n\n\"US-Wi6\"\n\n\n0.240018\n\n\n\n\n\"TA_F_QC\"\n\n\n\"DK-Fou\"\n\n\n0.040242\n\n\n\n\n\"TA_F_QC\"\n\n\n\"AU-GWW\"\n\n\n0.593282\n\n\n\n\n\"TA_F_QC\"\n\n\n\"US-Ivo\"\n\n\n0.093088\n\n\n\n\n\"TA_F_QC\"\n\n\n\"RU-Che\"\n\n\n0.384089\n\n\n\n\n\"TA_F_QC\"\n\n\n\"CA-TPD\"\n\n\n0.044025\n\n\n\n\n\"TA_F_QC\"\n\n\n\"AU-Cum\"\n\n\n0.26736\n\n\n\n\n\"TA_F_QC\"\n\n\n\"DE-Geb\"\n\n\n0.004645\n\n\n\n\n\"TA_F_QC\"\n\n\n\"BR-Sa1\"\n\n\n0.168888\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"TA_F_QC\"\n\n\n\"US-Ne2\"\n\n\n0.038275\n\n\n\n\n\"TA_F_QC\"\n\n\n\"CA-Gro\"\n\n\n0.141903\n\n\n\n\n\"TA_F_QC\"\n\n\n\"CZ-wet\"\n\n\n0.042611\n\n\n\n\n\"TA_F_QC\"\n\n\n\"GL-ZaF\"\n\n\n0.490097\n\n\n\n\n\"TA_F_QC\"\n\n\n\"IT-CA1\"\n\n\n0.229968\n\n\n\n\n\"TA_F_QC\"\n\n\n\"IT-La2\"\n\n\n0.529701\n\n\n\n\n\"TA_F_QC\"\n\n\n\"US-UMB\"\n\n\n0.015757\n\n\n\n\n\"TA_F_QC\"\n\n\n\"AU-Ade\"\n\n\n0.24837\n\n\n\n\n\"TA_F_QC\"\n\n\n\"CA-NS6\"\n\n\n0.205061\n\n\n\n\n\"TA_F_QC\"\n\n\n\"AU-TTE\"\n\n\n0.182124\n\n\n\n\n\"TA_F_QC\"\n\n\n\"CH-Fru\"\n\n\n0.095861\n\n\n\n\n\"TA_F_QC\"\n\n\n\"US-MMS\"\n\n\n0.03284"
  },
  {
    "objectID": "Simple GP Hainich.html",
    "href": "Simple GP Hainich.html",
    "title": "GPFA Imputation Analysis",
    "section": "",
    "text": "imputation using simple GP\n\n%load_ext autoreload\n%autoreload 2\n\n\nfrom gpfa_imputation.imputation import *\nfrom gpfa_imputation.data_preparation import *\nfrom gpfa_imputation.simple_gp_imputation import *\n\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom pyprojroot import here\nimport matplotlib.pyplot as plt\n\nfrom gpfa_imputation.utils import *\n\n\ncache_path = here() / \".cache\"\n\n\n\ntake the first 200 rows from the Hainich dataset\n\nhai_path = Path(\"FLX_DE-Hai_FLUXNET2015_FULLSET_HH_2000-2012_1-4.csv\")\nhai_raw = pd.read_csv(here(\"data\") / hai_path, na_values=[\"-9999\", \"-9999.99\"], parse_dates=[0, 1], nrows=200)\n\n\nmeteo_vars = {\n    \"TA_F\": \"TA\",\n    \"SW_IN_F\": \"SW_IN\",\n    \"LW_IN_F\": \"LW_IN\",\n    \"VPD_F\": \"VPD\",\n    #\"PA\": \"PA\"\n}\n\nunits = {\n    'TA': '°C',\n    'SW_IN': 'W m-2',\n    'LW_IN': 'W m-2',\n    'VPD': 'hPa'\n}\n\nhai = (hai_raw\n       .rename(columns=meteo_vars)\n       .set_index(\"TIMESTAMP_END\")\n       .loc[:, meteo_vars.values()])\nhai\n\n\n\n\n\n  \n    \n      \n      TA\n      SW_IN\n      LW_IN\n      VPD\n    \n    \n      TIMESTAMP_END\n      \n      \n      \n      \n    \n  \n  \n    \n      2000-01-01 00:30:00\n      -0.60\n      0.0\n      302.475\n      0.222\n    \n    \n      2000-01-01 01:00:00\n      -0.65\n      0.0\n      302.475\n      0.122\n    \n    \n      2000-01-01 01:30:00\n      -0.58\n      0.0\n      301.677\n      0.090\n    \n    \n      2000-01-01 02:00:00\n      -0.51\n      0.0\n      301.677\n      0.110\n    \n    \n      2000-01-01 02:30:00\n      -0.49\n      0.0\n      301.677\n      0.102\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2000-01-05 02:00:00\n      4.74\n      0.0\n      330.202\n      1.191\n    \n    \n      2000-01-05 02:30:00\n      4.75\n      0.0\n      330.202\n      1.057\n    \n    \n      2000-01-05 03:00:00\n      4.76\n      0.0\n      330.202\n      0.935\n    \n    \n      2000-01-05 03:30:00\n      4.62\n      0.0\n      330.202\n      1.162\n    \n    \n      2000-01-05 04:00:00\n      4.51\n      0.0\n      330.202\n      1.636\n    \n  \n\n200 rows × 4 columns\n\n\n\n\n\n\n\nreset_seed()\ndata_r_gaps = GPFADataTest(hai[:150]).add_random_missing()\ndata_c_gaps = GPFADataTest(hai[:150]).add_gap(15, meteo_vars.values())\n\n\n\n\nres_r_gaps = SimpleGPImputationExplorer(data_r_gaps.data).fit().to_result(data_r_gaps.data_compl_tidy, units=units)\n\n\n\n\n/home/simone/anaconda3/envs/data-science/lib/python3.10/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:136: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\ntorch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\nX = torch.triangular_solve(B, A).solution\nshould be replaced with\nX = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2183.)\n  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n\n\n\n\n\n\n\n\n\n\n\n\nres_r_gaps.display_results(plot_args = {'bind_interaction': False})\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\nMetrics  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.9914\n    \n    \n      SW_IN\n      0.9628\n    \n    \n      LW_IN\n      0.9681\n    \n    \n      VPD\n      0.9736\n    \n  \n\n  RMSE \n\n  \n    \n      variable\n      rmse\n      units\n    \n  \n  \n    \n      TA\n      0.0855\n      °C\n    \n    \n      SW_IN\n      7.1671\n      W m-2\n    \n    \n      LW_IN\n      3.3635\n      W m-2\n    \n    \n      VPD\n      0.0416\n      hPa\n    \n  \n\n \n\n\n\nModel Info  lengthscale \n\n  \n    \n      variable\n      lengthscale\n    \n  \n  \n    \n      TA\n      6.6367\n    \n    \n      SW_IN\n      5.1249\n    \n    \n      LW_IN\n      7.2702\n    \n    \n      VPD\n      3.0779\n    \n  \n\n  outputscale \n\n  \n    \n      variable\n      outputscale\n    \n  \n  \n    \n      TA\n      0.8106\n    \n    \n      SW_IN\n      1.6388\n    \n    \n      LW_IN\n      0.5797\n    \n    \n      VPD\n      0.8409\n    \n  \n\n  likelihood \n\n  \n    \n      variable\n      noise\n    \n  \n  \n    \n      TA\n      0.0064\n    \n    \n      SW_IN\n      0.0237\n    \n    \n      LW_IN\n      0.0247\n    \n    \n      VPD\n      0.0098\n    \n  \n\n \n\n\n\n\n\n\nres_c_gaps = SimpleGPImputationExplorer(data_c_gaps.data).fit().to_result(data_c_gaps.data_compl_tidy, units=units)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nres_c_gaps.display_results(plot_args = {'bind_interaction': False})\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\nMetrics  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.9500\n    \n    \n      SW_IN\n      0.9746\n    \n    \n      LW_IN\n      0.9130\n    \n    \n      VPD\n      0.9401\n    \n  \n\n  RMSE \n\n  \n    \n      variable\n      rmse\n      units\n    \n  \n  \n    \n      TA\n      0.2064\n      °C\n    \n    \n      SW_IN\n      5.9171\n      W m-2\n    \n    \n      LW_IN\n      5.5561\n      W m-2\n    \n    \n      VPD\n      0.0626\n      hPa\n    \n  \n\n \n\n\n\nModel Info  lengthscale \n\n  \n    \n      variable\n      lengthscale\n    \n  \n  \n    \n      TA\n      3.0968\n    \n    \n      SW_IN\n      3.9848\n    \n    \n      LW_IN\n      2.8674\n    \n    \n      VPD\n      2.5715\n    \n  \n\n  outputscale \n\n  \n    \n      variable\n      outputscale\n    \n  \n  \n    \n      TA\n      0.6266\n    \n    \n      SW_IN\n      0.7329\n    \n    \n      LW_IN\n      0.6387\n    \n    \n      VPD\n      0.7777\n    \n  \n\n  likelihood \n\n  \n    \n      variable\n      noise\n    \n  \n  \n    \n      TA\n      0.0028\n    \n    \n      SW_IN\n      0.0239\n    \n    \n      LW_IN\n      0.0201\n    \n    \n      VPD\n      0.0064\n    \n  \n\n \n\n\n\n\n\n\ntry with a different random seed\n\nreset_seed(101)\ndata_r_gaps = GPFADataTest(hai[:150]).add_random_missing()\ndata_c_gaps = GPFADataTest(hai[:150]).add_gap(15, meteo_vars.values())\n\n\n\n\nres_r_gaps = SimpleGPImputationExplorer(data_r_gaps.data).fit().to_result(data_r_gaps.data_compl_tidy, units=units)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nres_r_gaps.display_results(plot_args = {'bind_interaction': False})\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\nMetrics  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.9908\n    \n    \n      SW_IN\n      0.9660\n    \n    \n      LW_IN\n      0.9693\n    \n    \n      VPD\n      0.9676\n    \n  \n\n  RMSE \n\n  \n    \n      variable\n      rmse\n      units\n    \n  \n  \n    \n      TA\n      0.0885\n      °C\n    \n    \n      SW_IN\n      6.8475\n      W m-2\n    \n    \n      LW_IN\n      3.3026\n      W m-2\n    \n    \n      VPD\n      0.0460\n      hPa\n    \n  \n\n \n\n\n\nModel Info  lengthscale \n\n  \n    \n      variable\n      lengthscale\n    \n  \n  \n    \n      TA\n      6.9147\n    \n    \n      SW_IN\n      4.5656\n    \n    \n      LW_IN\n      6.7753\n    \n    \n      VPD\n      5.6677\n    \n  \n\n  outputscale \n\n  \n    \n      variable\n      outputscale\n    \n  \n  \n    \n      TA\n      0.8032\n    \n    \n      SW_IN\n      1.1016\n    \n    \n      LW_IN\n      0.5749\n    \n    \n      VPD\n      1.0537\n    \n  \n\n  likelihood \n\n  \n    \n      variable\n      noise\n    \n  \n  \n    \n      TA\n      0.0065\n    \n    \n      SW_IN\n      0.0076\n    \n    \n      LW_IN\n      0.0384\n    \n    \n      VPD\n      0.0294\n    \n  \n\n \n\n\n\n\n\n\nres_c_gaps = SimpleGPImputationExplorer(data_c_gaps.data).fit().to_result(data_c_gaps.data_compl_tidy, units=units)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nres_c_gaps.display_results(plot_args = {'bind_interaction': False, 'properties': {}})\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\nMetrics  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.9849\n    \n    \n      SW_IN\n      0.9654\n    \n    \n      LW_IN\n      0.9809\n    \n    \n      VPD\n      0.9291\n    \n  \n\n  RMSE \n\n  \n    \n      variable\n      rmse\n      units\n    \n  \n  \n    \n      TA\n      0.1135\n      °C\n    \n    \n      SW_IN\n      6.9104\n      W m-2\n    \n    \n      LW_IN\n      2.6041\n      W m-2\n    \n    \n      VPD\n      0.0680\n      hPa\n    \n  \n\n \n\n\n\nModel Info  lengthscale \n\n  \n    \n      variable\n      lengthscale\n    \n  \n  \n    \n      TA\n      3.0464\n    \n    \n      SW_IN\n      3.9805\n    \n    \n      LW_IN\n      2.9175\n    \n    \n      VPD\n      2.5759\n    \n  \n\n  outputscale \n\n  \n    \n      variable\n      outputscale\n    \n  \n  \n    \n      TA\n      0.6008\n    \n    \n      SW_IN\n      0.7517\n    \n    \n      LW_IN\n      0.5940\n    \n    \n      VPD\n      0.7584\n    \n  \n\n  likelihood \n\n  \n    \n      variable\n      noise\n    \n  \n  \n    \n      TA\n      0.0025\n    \n    \n      SW_IN\n      0.0284\n    \n    \n      LW_IN\n      0.0168\n    \n    \n      VPD\n      0.0061"
  },
  {
    "objectID": "Kernel exploration.html",
    "href": "Kernel exploration.html",
    "title": "GPFA Imputation Analysis",
    "section": "",
    "text": "Kernel visualization\n\nfrom gpfa_imputation.gpfa import GPFAKernel\nimport gpytorch\nimport torch\nimport matplotlib.pyplot as plt\nimport altair as alt\nimport pandas as pd\n\n\nk = gpytorch.kernels.RBFKernel()\n\n\nk.lengthscale = 3\n\n\nk(torch.tensor([1]), torch.tensor([2, 3])).evaluate()\n\ntensor([[0.9460, 0.8007]], grad_fn=<RBFCovarianceBackward>)\n\n\n\nalt.renderers.enable('mimetype')\n\nRendererRegistry.enable('mimetype')\n\n\n\ndef plot_kernel(kernel, t_range = torch.arange(-10, 10)):\n    y = kernel(torch.tensor([0]), t_range).evaluate().detach().numpy().squeeze()\n    return alt.Chart(pd.DataFrame({'x': t_range, 'y': y})).mark_line().encode(x='x', y ='y')\n    #plt.plot(t_range, y\n    # return y\n\n\nplot_kernel(k)"
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "GPFA Imputation Analysis",
    "section": "",
    "text": "Notes\nNotes: - Kernel Lengthscale: too short to handle big gaps - how to encode time? - normalization - parameters init\nnext steps:\n\n\n\nthings to try: - more variables - more kernels - basic variable dist - log - deploy to website\nThings to consider: - different latent kernel for different latent variable?\n\nTA\nSW_IN\nLW_IN\nVPD\nWS\nWD\nP\nPA\nSWC\nPPFD\nCO2 flux\nH02 flux\nLE\n\nCode improvements: - move normalization out of the learner class - use something like fastai pipelines for data transformation …"
  },
  {
    "objectID": "GPFA Hainich - multi latent var.html",
    "href": "GPFA Hainich - multi latent var.html",
    "title": "GPFA Imputation Analysis",
    "section": "",
    "text": "Trying to use more than 1 latent variable\n\n%load_ext autoreload\n%autoreload 2\n\n%matplotlib inline\n\n\nfrom gpfa_imputation.imputation import *\nfrom gpfa_imputation.data_preparation import *\n\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom pyprojroot import here\nimport matplotlib.pyplot as plt\n\nfrom gpfa_imputation.utils import cache_disk\n\n\ndef reset_seed():\n    torch.manual_seed(27);\n    np.random.seed(27);\n\n\ntorch.manual_seed(27);\nnp.random.seed(27);\ncache_path = here() / \".cache\"\n\n\n\ntake the first 200 rows from the Hainich dataset\n\nhai_path = Path(\"FLX_DE-Hai_FLUXNET2015_FULLSET_HH_2000-2012_1-4.csv\")\nhai_raw = pd.read_csv(here(\"data\") / hai_path, na_values=[\"-9999\", \"-9999.99\"], parse_dates=[0, 1], nrows=200)\n\n\nmeteo_vars = {\n    \"TA_F\": \"TA\",\n    \"SW_IN_F\": \"SW_IN\",\n    \"LW_IN_F\": \"LW_IN\",\n    \"VPD_F\": \"VPD\",\n    #\"PA\": \"PA\"\n}\n\nunits = {\n    'TA': '°C',\n    'SW_IN': 'W m-2',\n    'LW_IN': 'W m-2',\n    'VPD': 'hPa'\n}\n\nhai = (hai_raw\n       .rename(columns=meteo_vars)\n       .set_index(\"TIMESTAMP_END\")\n       .loc[:, meteo_vars.values()])\nhai\n\n\n\n\n\n  \n    \n      \n      TA\n      SW_IN\n      LW_IN\n      VPD\n    \n    \n      TIMESTAMP_END\n      \n      \n      \n      \n    \n  \n  \n    \n      2000-01-01 00:30:00\n      -0.60\n      0.0\n      302.475\n      0.222\n    \n    \n      2000-01-01 01:00:00\n      -0.65\n      0.0\n      302.475\n      0.122\n    \n    \n      2000-01-01 01:30:00\n      -0.58\n      0.0\n      301.677\n      0.090\n    \n    \n      2000-01-01 02:00:00\n      -0.51\n      0.0\n      301.677\n      0.110\n    \n    \n      2000-01-01 02:30:00\n      -0.49\n      0.0\n      301.677\n      0.102\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2000-01-05 02:00:00\n      4.74\n      0.0\n      330.202\n      1.191\n    \n    \n      2000-01-05 02:30:00\n      4.75\n      0.0\n      330.202\n      1.057\n    \n    \n      2000-01-05 03:00:00\n      4.76\n      0.0\n      330.202\n      0.935\n    \n    \n      2000-01-05 03:30:00\n      4.62\n      0.0\n      330.202\n      1.162\n    \n    \n      2000-01-05 04:00:00\n      4.51\n      0.0\n      330.202\n      1.636\n    \n  \n\n200 rows × 4 columns\n\n\n\n\n\nmakes here all the slow computations and cache them on disk\n\nreset_seed()\ndata_r_gaps = GPFADataTest(hai[:150]).add_random_missing()\ndata_c_gaps = GPFADataTest(hai[:150]).add_gap(15, meteo_vars.values())\n\n\ncache_file_gaps = cache_path / \"hai_diff_latents.pickle\"\n# cache_file_gaps.unlink() # uncomment this line to reset the cache\n\n\n@cache_disk(cache_file_gaps)\ndef compute_multiple_latent():\n    hai_r_gaps = [GPFAImputationExplorer(\n        data_r_gaps.data, latent_dims=i)\n                  .fit()\n                  .to_result(data_r_gaps.data_compl_tidy, units=units)\n                  for i in range(1,4)]\n    hai_c_gaps = [GPFAImputationExplorer(\n        data_c_gaps.data, latent_dims=i)\n                  .fit()\n                  .to_result(data_c_gaps.data_compl_tidy, units=units)\n                  for i in range(1,4)]\n    return hai_r_gaps, hai_c_gaps\n\n\nhai_r_gaps, hai_c_gaps = compute_multiple_latent()\n\n\n\n\n\n\nhai_r_gaps\n\n[<gpfa_imputation.imputation.GPFAResult>,\n <gpfa_imputation.imputation.GPFAResult>,\n <gpfa_imputation.imputation.GPFAResult>]\n\n\n\nhai_r_gaps[0].display_results()\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\n  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.6243\n    \n    \n      SW_IN\n      0.1244\n    \n    \n      LW_IN\n      0.0072\n    \n    \n      VPD\n      0.9597\n    \n  \n\n  Λ \n\n  \n    \n      variable\n      z0\n    \n  \n  \n    \n      time\n      0.8015\n    \n    \n      variable\n      0.4251\n    \n    \n      mean\n      -0.1879\n    \n    \n      std\n      1.0596\n    \n  \n\n  Lengthscale \n\n  \n    \n      latent\n      lengthscale\n    \n  \n  \n    \n      z0\n      5.6057\n    \n  \n\n \n\n\n\nhai_r_gaps[1].display_results()\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\n  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.9913\n    \n    \n      SW_IN\n      0.1884\n    \n    \n      LW_IN\n      0.9673\n    \n    \n      VPD\n      0.5811\n    \n  \n\n  Λ \n\n  \n    \n      variable\n      z0\n      z1\n    \n  \n  \n    \n      time\n      0.8553\n      0.5997\n    \n    \n      variable\n      0.3110\n      -0.1375\n    \n    \n      mean\n      -0.3717\n      0.6710\n    \n    \n      std\n      0.7057\n      0.2981\n    \n  \n\n  Lengthscale \n\n  \n    \n      latent\n      lengthscale\n    \n  \n  \n    \n      z0\n      7.0575\n    \n    \n      z1\n      7.4311\n    \n  \n\n \n\n\n\nhai_r_gaps[2].display_results()\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\n  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.9915\n    \n    \n      SW_IN\n      0.9635\n    \n    \n      LW_IN\n      0.9679\n    \n    \n      VPD\n      0.6259\n    \n  \n\n  Λ \n\n  \n    \n      variable\n      z0\n      z1\n      z2\n    \n  \n  \n    \n      time\n      0.8547\n      0.4558\n      -0.0728\n    \n    \n      variable\n      0.4540\n      -0.3101\n      1.2743\n    \n    \n      mean\n      -0.2829\n      0.7159\n      0.0165\n    \n    \n      std\n      0.7268\n      0.1550\n      0.2461\n    \n  \n\n  Lengthscale \n\n  \n    \n      latent\n      lengthscale\n    \n  \n  \n    \n      z0\n      6.8582\n    \n    \n      z1\n      7.3777\n    \n    \n      z2\n      5.3624\n    \n  \n\n \n\n\n\n\n\n\nhai_c_gaps[0].display_results()\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\n  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.9793\n    \n    \n      SW_IN\n      0.0152\n    \n    \n      LW_IN\n      -0.0507\n    \n    \n      VPD\n      0.5711\n    \n  \n\n  Λ \n\n  \n    \n      variable\n      z0\n    \n  \n  \n    \n      time\n      0.8542\n    \n    \n      variable\n      0.1202\n    \n    \n      mean\n      0.1860\n    \n    \n      std\n      0.6229\n    \n  \n\n  Lengthscale \n\n  \n    \n      latent\n      lengthscale\n    \n  \n  \n    \n      z0\n      6.0641\n    \n  \n\n \n\n\n\nhai_c_gaps[1].display_results()\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\n  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.9789\n    \n    \n      SW_IN\n      0.1882\n    \n    \n      LW_IN\n      0.9552\n    \n    \n      VPD\n      0.6114\n    \n  \n\n  Λ \n\n  \n    \n      variable\n      z0\n      z1\n    \n  \n  \n    \n      time\n      0.5927\n      0.6728\n    \n    \n      variable\n      0.4136\n      -0.0936\n    \n    \n      mean\n      -0.5082\n      0.5232\n    \n    \n      std\n      0.5586\n      0.4200\n    \n  \n\n  Lengthscale \n\n  \n    \n      latent\n      lengthscale\n    \n  \n  \n    \n      z0\n      5.8459\n    \n    \n      z1\n      6.5770\n    \n  \n\n \n\n\n\nhai_c_gaps[2].display_results()\n\n/home/simone/.local/lib/python3.10/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for col_name, dtype in df.dtypes.iteritems():\n\n\n\n\n\n\n\n\n  r2 \n\n  \n    \n      variable\n      r2\n    \n  \n  \n    \n      TA\n      0.9785\n    \n    \n      SW_IN\n      0.9640\n    \n    \n      LW_IN\n      0.9562\n    \n    \n      VPD\n      0.6513\n    \n  \n\n  Λ \n\n  \n    \n      variable\n      z0\n      z1\n      z2\n    \n  \n  \n    \n      time\n      -0.0527\n      -0.4903\n      0.7231\n    \n    \n      variable\n      0.8765\n      0.1260\n      0.2360\n    \n    \n      mean\n      -0.0042\n      -0.6728\n      -0.3668\n    \n    \n      std\n      0.2132\n      -0.2787\n      0.5878\n    \n  \n\n  Lengthscale \n\n  \n    \n      latent\n      lengthscale\n    \n  \n  \n    \n      z0\n      4.5862\n    \n    \n      z1\n      6.9706\n    \n    \n      z2\n      5.3607"
  }
]