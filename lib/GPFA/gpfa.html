<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.97">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>meteo_imp - Gaussian Processes Factor Analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="meteo_imp - Gaussian Processes Factor Analysis">
<meta property="og:description" content="Derivation of the equations to solve the Gaussian Processes Factor Analysis as described in: Yu, B.M., Cunningham, J.P., Santhanam, G., Ryu, S., Shenoy, K.V., Sahani, M., 2008.">
<meta property="og:site-name" content="meteo_imp">
<meta name="twitter:title" content="meteo_imp - Gaussian Processes Factor Analysis">
<meta name="twitter:description" content="Derivation of the equations to solve the Gaussian Processes Factor Analysis as described in: Yu, B.M., Cunningham, J.P., Santhanam, G., Ryu, S., Shenoy, K.V., Sahani, M., 2008.">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">meteo_imp</span>
    </a>
  </div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Gaussian Processes Factor Analysis</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">GPFA Imputation</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data_preparation.html" class="sidebar-item-text sidebar-link">Data Preparation</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../results.html" class="sidebar-item-text sidebar-link">Results</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../simplegp_imputation.html" class="sidebar-item-text sidebar-link">Simple GP Imputation</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../gaussian.html" class="sidebar-item-text sidebar-link">Gaussian Distributions Utils</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../utils.html" class="sidebar-item-text sidebar-link">Utils</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Fluxnet</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Fluxnet/gap_finder.html" class="sidebar-item-text sidebar-link">Find Gaps in Fluxnet data</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Fluxnet/hainich.html" class="sidebar-item-text sidebar-link">Fluxnet Hainich</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">GPFA</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../GPFA/gpfa.html" class="sidebar-item-text sidebar-link active">Gaussian Processes Factor Analysis</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../GPFA/learner.html" class="sidebar-item-text sidebar-link">GPFA Learner</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../GPFA/imputation.html" class="sidebar-item-text sidebar-link">Imputation time series</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">kalman</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../kalman/filter.html" class="sidebar-item-text sidebar-link">Kalman Filter</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../kalman/test_filter_pykalman.html" class="sidebar-item-text sidebar-link">Compare PyKalman</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../kalman/filter_numerical_stability.html" class="sidebar-item-text sidebar-link">Numerical stability filter</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../kalman/fastai.html" class="sidebar-item-text sidebar-link">Implement Kalman model using FastAI</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../kalman/learner.html" class="sidebar-item-text sidebar-link">Kalman Filter Models</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../kalman/imputation.html" class="sidebar-item-text sidebar-link">Imputation Kalman Model</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../kalman/old statsmodels - statespace.html" class="sidebar-item-text sidebar-link">[Not Working] StatsModels Kalman filter</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../kalman/old_01_pykalman_models.html" class="sidebar-item-text sidebar-link">[OLD] PyKalman Filter Models</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../kalman/old_02_pykalman_imputation.html" class="sidebar-item-text sidebar-link">[OLD] Imputation PyKalman Model</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#notation" id="toc-notation" class="nav-link active" data-scroll-target="#notation">Notation</a></li>
  <li><a href="#gaussian-processes-factor-analysis-model" id="toc-gaussian-processes-factor-analysis-model" class="nav-link" data-scroll-target="#gaussian-processes-factor-analysis-model">Gaussian Processes Factor Analysis model</a></li>
  <li><a href="#derivation-of-px" id="toc-derivation-of-px" class="nav-link" data-scroll-target="#derivation-of-px">Derivation of <span class="math inline">\(p(X)\)</span></a>
  <ul class="collapse">
  <li><a href="#diagonal-of-the-covariance-matrix" id="toc-diagonal-of-the-covariance-matrix" class="nav-link" data-scroll-target="#diagonal-of-the-covariance-matrix">Diagonal of the covariance matrix</a></li>
  <li><a href="#off-diagonal" id="toc-off-diagonal" class="nav-link" data-scroll-target="#off-diagonal">Off-diagonal</a></li>
  <li><a href="#result" id="toc-result" class="nav-link" data-scroll-target="#result">Result</a></li>
  <li><a href="#latent-variable-with-more-than-one-dimension" id="toc-latent-variable-with-more-than-one-dimension" class="nav-link" data-scroll-target="#latent-variable-with-more-than-one-dimension">Latent variable with more than one dimension</a></li>
  </ul></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps">Next steps</a></li>
  <li><a href="#implementation" id="toc-implementation" class="nav-link" data-scroll-target="#implementation">Implementation</a>
  <ul class="collapse">
  <li><a href="#kernel" id="toc-kernel" class="nav-link" data-scroll-target="#kernel">Kernel</a>
  <ul class="collapse">
  <li><a href="#scriptfunction-object-at-0x7f2e64aac8b0" id="toc-scriptfunction-object-at-0x7f2e64aac8b0" class="nav-link" data-scroll-target="#scriptfunction-object-at-0x7f2e64aac8b0">ScriptFunction object at 0x7f2e64aac8b0&gt;</a></li>
  <li><a href="#gpfakernel" id="toc-gpfakernel" class="nav-link" data-scroll-target="#gpfakernel">GPFAKernel</a></li>
  </ul></li>
  <li><a href="#gpfa" id="toc-gpfa" class="nav-link" data-scroll-target="#gpfa">GPFA</a>
  <ul class="collapse">
  <li><a href="#gpfazeromean" id="toc-gpfazeromean" class="nav-link" data-scroll-target="#gpfazeromean">GPFAZeroMean</a></li>
  <li><a href="#gpfa-1" id="toc-gpfa-1" class="nav-link" data-scroll-target="#gpfa-1">GPFA</a></li>
  </ul></li>
  <li><a href="#multi-dimensional-latent-variable" id="toc-multi-dimensional-latent-variable" class="nav-link" data-scroll-target="#multi-dimensional-latent-variable">Multi-dimensional latent variable</a></li>
  <li><a href="#get-info" id="toc-get-info" class="nav-link" data-scroll-target="#get-info">Get info</a>
  <ul class="collapse">
  <li><a href="#gpfa.get_info" id="toc-gpfa.get_info" class="nav-link" data-scroll-target="#gpfa.get_info">GPFA.get_info</a></li>
  </ul></li>
  <li><a href="#export" id="toc-export" class="nav-link" data-scroll-target="#export">Export</a></li>
  <li><a href="#get-info-1" id="toc-get-info-1" class="nav-link" data-scroll-target="#get-info-1">Get info</a>
  <ul class="collapse">
  <li><a href="#gpfa.get_info-1" id="toc-gpfa.get_info-1" class="nav-link" data-scroll-target="#gpfa.get_info-1">GPFA.get_info</a></li>
  </ul></li>
  <li><a href="#get-info-2" id="toc-get-info-2" class="nav-link" data-scroll-target="#get-info-2">Get info</a>
  <ul class="collapse">
  <li><a href="#gpfa.get_info-2" id="toc-gpfa.get_info-2" class="nav-link" data-scroll-target="#gpfa.get_info-2">GPFA.get_info</a></li>
  </ul></li>
  <li><a href="#export-1" id="toc-export-1" class="nav-link" data-scroll-target="#export-1">Export</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/mone27/meteo_imp/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Gaussian Processes Factor Analysis</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<p>Derivation of the equations to solve the Gaussian Processes Factor Analysis as described in: Yu, B.M., Cunningham, J.P., Santhanam, G., Ryu, S., Shenoy, K.V., Sahani, M., 2008. Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity, in: Advances in Neural Information Processing Systems. Curran Associates, Inc.</p>
<section id="notation" class="level2">
<h2 class="anchored" data-anchor-id="notation">Notation</h2>
<ul>
<li><span class="math inline">\(T\)</span> Number of time steps</li>
<li><span class="math inline">\(N\)</span> Number of variables observed</li>
<li><span class="math inline">\(K\)</span> Number of dimensions of latent variable</li>
<li><span class="math inline">\(x_{:,t}\)</span> vector of all the <span class="math inline">\(N\)</span> variables at time <span class="math inline">\(t\)</span>, <span class="math inline">\(\in \mathbb{R}^N\)</span></li>
<li><span class="math inline">\(x_{n,:}\)</span> vector of the <span class="math inline">\(n\)</span>th variable at for time steps in <span class="math inline">\(T\)</span>, <span class="math inline">\(\in \mathbb{R}^T\)</span></li>
<li><span class="math inline">\(x_{n,t}\)</span> <span class="math inline">\(n\)</span>th variable at time <span class="math inline">\(t\)</span>, <span class="math inline">\(\in \mathbb{R}\)</span></li>
<li><span class="math inline">\(X_M = [x_{:,1}, ... x_{:, T}]\)</span> Matrix with all the <span class="math inline">\(N\)</span> variables at all time steps <span class="math inline">\(T\)</span>, <span class="math inline">\(\in \mathbb{R}^{N \times T}\)</span></li>
<li><span class="math inline">\(X\)</span> is a vector obtained by “flattening” <span class="math inline">\(X_M\)</span>, by putting next to each other all variable at time <span class="math inline">\(t\)</span>, <span class="math inline">\(\in \mathbb{R}^{(N \cdot T)}\)</span></li>
<li><span class="math inline">\(t\)</span> time step</li>
<li><span class="math inline">\(z_{i, t}\)</span> <span class="math inline">\(i\)</span>th latent variable at time <span class="math inline">\(t\)</span>, <span class="math inline">\(\in \mathbb{R}\)</span></li>
<li><span class="math inline">\(Z = [z_1 , ... z_t]\)</span> Vector with <span class="math inline">\(z\)</span> at all time steps in <span class="math inline">\(T\)</span>, <span class="math inline">\(\in \mathbb{R}^{K \times T}\)</span></li>
</ul>
</section>
<section id="gaussian-processes-factor-analysis-model" class="level2">
<h2 class="anchored" data-anchor-id="gaussian-processes-factor-analysis-model">Gaussian Processes Factor Analysis model</h2>
<p>We model the variables in this way <span class="math display">\[x_{:,t} = \Lambda z_{:,t} + \epsilon \]</span> where:</p>
<ul>
<li><span class="math inline">\(\Lambda\)</span> is a Factor loading matrix that transforms <span class="math inline">\(z_{:,t}\)</span> into <span class="math inline">\(x_{:,t}\)</span>, <span class="math inline">\(\in \mathbb{R}^{N \times K}\)</span></li>
<li><span class="math inline">\(\epsilon\)</span> Random noise. The random noise is independent between the different time steps, <span class="math inline">\(\in \mathbb{R}^N\)</span>:
<ul>
<li><span class="math inline">\(p(\epsilon) = \mathcal{N}(0, \psi)\)</span> distribution of noise</li>
<li><span class="math inline">\(\psi\)</span>, covariance matrix of noise, it is a diagional matrix, <span class="math inline">\(\in \mathbb{R}^{N \times N}\)</span></li>
</ul></li>
</ul>
<p>The model consider <span class="math inline">\(\langle X \rangle = 0\)</span> (if <span class="math inline">\(X\)</span> doesn’t have a 0 mean it can be easily transformed by substracting the mean)</p>
<p>The latent variable <span class="math inline">\(z\)</span> is modelled over time using a Gaussian Process, one process for each dimension <span class="math inline">\(k\)</span> for simplicity we assumed that <span class="math inline">\(z\)</span> has only one dimension (<span class="math inline">\(k = 1\)</span>)</p>
<p><span class="math display">\[p(Z) = \mathcal{GP}(0, k(t, t \prime))\]</span></p>
</section>
<section id="derivation-of-px" class="level2">
<h2 class="anchored" data-anchor-id="derivation-of-px">Derivation of <span class="math inline">\(p(X)\)</span></h2>
<p><span class="math inline">\(p(x_{:,t}|z_{:,t}) = \mathcal{N}(\Lambda z_{:,t}, \psi)\)</span> is easy to derive and then <span class="math inline">\(p(x_{:,t})\)</span> and <span class="math inline">\(p(z_{:,t}|x_{:,t})\)</span> can be obtained using the rules of Gaussian inference.</p>
<p>However, what is interesting is to have the analytical form of <span class="math inline">\(p(X)\)</span>, which models both the relations between <span class="math inline">\(z\)</span> and <span class="math inline">\(x\)</span> and the <span class="math inline">\(z\)</span> and <span class="math inline">\(t\)</span>. The likelihood of <span class="math inline">\(p(X)\)</span> can then be maximized to obtain the parameters of the latent transformation and the kernel hyperparameter.</p>
<p><span class="math inline">\(p(X)\)</span> is a Guassian distribution with <span class="math inline">\(T\cdot N\)</span> dimensions.</p>
<p><span class="math inline">\(p(X) = \mathcal{N}(\langle X \rangle, \langle X X^T \rangle)\)</span></p>
<section id="diagonal-of-the-covariance-matrix" class="level3">
<h3 class="anchored" data-anchor-id="diagonal-of-the-covariance-matrix">Diagonal of the covariance matrix</h3>
<p>Let’s start with the diagonal of the covariance matrix (<span class="math inline">\(t = t \prime\)</span>)</p>
<p><span class="math inline">\(\langle x_{:,t}x_{:,t}^T \rangle = \langle (\Lambda z_{:,t} + \epsilon_{t})(\Lambda z_{:,t} + \epsilon_{t})^T \rangle\)</span></p>
<p>by multipling the two vectors together we obtain</p>
<p><span class="math inline">\(\langle x_{:,t}x_{:,t}^T \rangle = \langle \Lambda z_{:,t} z_{:,t}^T \Lambda^T + \Lambda z_{:,t} \epsilon_{t}^T + \epsilon_t \Lambda^T z_{:,t}^T + \epsilon_t \epsilon_{t}^T \rangle\)</span></p>
<p>The using the linearity of the <a href="https://www.statlect.com/fundamentals-of-probability/expected-value-properties">expectation</a> we can:</p>
<ol type="1">
<li>transform the expecations of a sum into a sum of expecations</li>
<li>move the <span class="math inline">\(\Lambda\)</span> out of the expecation, as it doesn’t depend on <span class="math inline">\(z\)</span></li>
<li><span class="math inline">\(\langle z_{:,t} \epsilon_t \rangle = \langle z_{:,t} \rangle \langle \epsilon_t \rangle\)</span> because <span class="math inline">\(z_{:,t}\)</span> and <span class="math inline">\(\epsilon_t\)</span> are independent random variables</li>
</ol>
<p><span class="math inline">\(\langle x_{:,t}x_{:,t}^T \rangle = \Lambda \langle z_{:,t} z_{:,t}^T\rangle \Lambda^T + \Lambda \langle z_{:,t} \rangle \langle \epsilon_{t}^T \rangle + \langle \epsilon_{t} \rangle \Lambda^T \langle z_{:,t}^T \rangle + \langle \epsilon_t \epsilon_{t}^T \rangle\)</span></p>
<p>Then considering that <span class="math inline">\(\langle z_{:,t} \rangle = 0\)</span> and that <span class="math inline">\(\langle \epsilon_t \rangle = 0\)</span> the expression can be simplified as:</p>
<p><span class="math inline">\(\langle x_{:,t}x_{:,t}^T \rangle = \Lambda \langle z_{:,t} z_{:,t}^T\rangle \Lambda^T + \langle \epsilon_t \epsilon_{t}^T \rangle\)</span></p>
<p>Then substituting:</p>
<ol type="1">
<li><span class="math inline">\(\langle z_{:,t} z_{:,t}^T\rangle = k(t, t)\)</span> as that is the covariance matrix of the Gaussian process</li>
<li><span class="math inline">\(\langle \epsilon_t \epsilon_t^T \rangle= \psi\)</span></li>
</ol>
<p><span class="math inline">\(\langle x_{:,t}x_{:,t}^T \rangle = \Lambda k(t,t) \Lambda^T + \psi\)</span></p>
</section>
<section id="off-diagonal" class="level3">
<h3 class="anchored" data-anchor-id="off-diagonal">Off-diagonal</h3>
<p>similar to the steps of above</p>
<p><span class="math inline">\(\langle x_{:,t}x_{:,t \prime}^T \rangle = \langle (\Lambda z_{:,t} + \epsilon_{t})(\Lambda z_{:,t \prime} + \epsilon_{t \prime})^T \rangle\)</span></p>
<p>by multipling the two vectors together we obtain</p>
<p><span class="math inline">\(\langle x_{:,t}x_{:,t \prime}^T \rangle = \langle \Lambda z_{:,t} z_{:,t \prime}^T \Lambda^T + \Lambda z_{:,t} \epsilon_{t \prime}^T + \epsilon_t \Lambda^T z_{:,t \prime}^T + \epsilon_t \epsilon_{t \prime}^T \rangle\)</span></p>
<p>Then using the linearity of the <a href="https://www.statlect.com/fundamentals-of-probability/expected-value-properties">expectation</a> we can:</p>
<ol type="1">
<li>transform the expecations of a sum into a sum of expecations</li>
<li>move the <span class="math inline">\(\Lambda\)</span> out of the expecatios, as it doesn’t depend on t</li>
<li><span class="math inline">\(\langle z_{:,t} \epsilon_t \rangle = \langle z_{:,t} \rangle \langle \epsilon_t \rangle\)</span> because <span class="math inline">\(z_{:,t}\)</span> and <span class="math inline">\(\epsilon_t\)</span> are independent random variables</li>
</ol>
<p><span class="math inline">\(\langle x_{:,t}x_{:,t}^T \rangle = \Lambda \langle z_{:,t} z_{:,t}^T\rangle \Lambda^T + \Lambda \langle z_{:,t} \rangle \langle \epsilon_{t}^T \rangle + \langle \epsilon_{t} \rangle \Lambda^T \langle z_{:,t}^T \rangle + \langle \epsilon_t \epsilon_{t}^T \rangle\)</span></p>
<p>Then considering that <span class="math inline">\(\langle z_{:,t} \rangle = 0\)</span> and that <span class="math inline">\(\langle \epsilon_t \rangle = 0\)</span> the expression can be simplified as:</p>
<p><span class="math inline">\(\langle x_{:,t}x_{:,t \prime}^T \rangle = \Lambda \langle z_{:,t} z_{:,t \prime}^T\rangle \Lambda^T + \langle \epsilon_t \epsilon_{t \prime}^T \rangle\)</span></p>
<p>Then substituting: 1) <span class="math inline">\(\langle z_{:,t} z_{:,t \prime}^T\rangle = k(t,t \prime)\)</span> as that is the covariance matrix of the Gaussian process 2) <span class="math inline">\(\langle \epsilon_t \epsilon_{t \prime}^T \rangle= 0\)</span> as <span class="math inline">\(\epsilon_t\)</span> and <span class="math inline">\(\epsilon_{t \prime}\)</span> are independent and <span class="math inline">\(\langle \epsilon_t \rangle = 0\)</span></p>
<p><span class="math inline">\(\langle x_{:,t}x_{:,t \prime}^T \rangle = \Lambda k(t,t \prime) \Lambda^T\)</span></p>
</section>
<section id="result" class="level3">
<h3 class="anchored" data-anchor-id="result">Result</h3>
<p>The equation for the diagonal and off-diagonal element can be summarized as:</p>
<p><span class="math display">\[\langle x_{:,t}x_{:,t \prime}^T \rangle = \Lambda k(t,t \prime) \Lambda^T + \delta(t - t \prime)\psi\]</span></p>
<p>where <span class="math inline">\(\delta(x) = \begin{cases}  1 &amp; if\ x=0 \\  0 &amp; if\ x \ne 0 \\  \end{cases}\)</span></p>
<p>Therefore <span class="math inline">\(p(X)\)</span> can be modelled as:</p>
<p><span class="math display">\[p(X) = \mathcal{N}\left (0 , {\begin{array}{cccc}
    \Lambda k(t_1,t_1) \Lambda^T + \delta(1-1)\psi &amp; \Lambda k(t_{1},t_{2}) \Lambda^T + \delta(1-2)\psi&amp; \cdots &amp; \Lambda k(t_1 ,t_t) \Lambda^T + \delta(1-t)\psi\\
    \Lambda k(t_{2},t_{1}) \Lambda^T+ \delta(2-1)\psi &amp;  \Lambda k(t_{2},t_{2}) \Lambda^T + \delta(2-2)\psi &amp; \cdots &amp; \Lambda k(t_{2},t_{t}) \Lambda^T + \delta(2-t)\psi\\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
    \Lambda k(t_{t}, t_{1}) \Lambda^T+ \delta(t-1)\psi &amp; \Lambda k(t_{t},t_{2}) \Lambda^T + \delta(t-2)\psi&amp; \cdots &amp; \Lambda k(t_{t},t_{t}) \Lambda^T + \delta(t-t)\psi\\
    \end{array} } \right )\]</span></p>
<p>and this is also Gaussian Process with a “special” kernel. Multiplying kernel with a constant (<span class="math inline">\(\Lambda\)</span>) or adding a kernel (<span class="math inline">\(\delta\)</span>) yields another valid kernel</p>
<p>If we define a new kernel as <span class="math display">\[K(t,t \prime) = \Lambda k(t,t \prime) \Lambda^T + \delta(t - t \prime)\psi\]</span></p>
<p>Then</p>
<p><span class="math display">\[ p(X) = \mathcal{GP}(0, K(t, t\prime))\]</span></p>
</section>
<section id="latent-variable-with-more-than-one-dimension" class="level3">
<h3 class="anchored" data-anchor-id="latent-variable-with-more-than-one-dimension">Latent variable with more than one dimension</h3>
<p>In order to have a latent variable with more than one-dimesions, we need to make small changes to the formula</p>
<p>The starting point is the covariance matrix of the latent at time <span class="math inline">\(t\)</span>, which is:</p>
<p><span class="math display">\[\langle z_{:,t} z_{:,t}^T\rangle = \left(\begin{array}{ccc} \langle z_{1:,t} z_{1:,t}^T\rangle &amp; \cdots &amp; \langle z_{1:,t} z_{k:,t}^T\rangle\\ \vdots &amp; \ddots &amp; \vdots \\ \langle z_{k:,t} z_{1:,t}^T \rangle &amp; \cdots &amp; \langle z_{k:,t} z_{k:,t}^T\rangle\end{array}\right)\]</span></p>
<p>since each dimension in <span class="math inline">\(z\)</span> is indipendent:</p>
<p><span class="math inline">\(\langle z_{k,t} z_{k\prime,t} \rangle = 0\)</span></p>
<p>each dimension in <span class="math inline">\(z\)</span> is modelled using a different kernel (<span class="math inline">\(k_{z_k}(t,t\prime)\)</span>), hence:</p>
<p><span class="math display">\[\langle z_{:,t} z_{:,t}^T\rangle = \left(\begin{array}{ccc} k_{z_1}(t, t) &amp; \cdots &amp; 0 \\ \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; \cdots &amp; k_{z_k}(t, t)\end{array}\right)\]</span></p>
<p>so the GPFA Kernel is:<br>
<span class="math display">\[K(t,t \prime) = \Lambda \left(\begin{array}{ccc} k_{z_1}(t, t \prime) &amp; \cdots &amp; 0 \\ \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; \cdots &amp; k_{z_k}(t, t \prime)\end{array}\right) \Lambda^T + \delta(t - t \prime)\psi\]</span></p>
<p>so <code>p(X)</code> is:</p>
<p><span class="math display">\[p(X) = \mathcal{N}\left (0 , {\begin{array}{ccc}
    \Lambda \left(\begin{array}{ccc} k_{z_1}(t_1, t_1) &amp; \cdots &amp; 0 \\ \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; \cdots &amp; k_{z_k}(t_1, t_1)\end{array}\right) \Lambda^T + \delta(t_1 - t_1)\psi &amp; \cdots &amp; \Lambda \left(\begin{array}{ccc} k_{z_1}(t_1, t_t) &amp; \cdots &amp; 0 \\ \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; \cdots &amp; k_{z_k}(t_1, t_t)\end{array}\right) \Lambda^T + \delta(t_1 - t_t)\psi\\
    \vdots &amp; \ddots &amp; \vdots\\
    \Lambda \left(\begin{array}{ccc} k_{z_1}(t_t, t_1) &amp; \cdots &amp; 0 \\ \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; \cdots &amp; k_{z_k}(t_t, t_1)\end{array}\right) \Lambda^T + \delta(t_t - t_1)\psi &amp; \cdots &amp; \Lambda \left(\begin{array}{ccc} k_{z_1}(t_t, t_t) &amp; \cdots &amp; 0 \\ \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; \cdots &amp; k_{z_k}(t_t, t_t)\end{array}\right) \Lambda^T + \delta(t_t - t_t)\psi\\
    \end{array} } \right )\]</span></p>
</section>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next steps</h2>
<ul>
<li>The parameters of the final GP (<span class="math inline">\(\Lambda, \psi\)</span> and the kernel hyperparameters) can be fitted by maximizing the likelihood of <span class="math inline">\(p(X)\)</span> using gradient descent</li>
</ul>
</section>
<section id="implementation" class="level1">
<h1>Implementation</h1>
<section id="kernel" class="level2">
<h2 class="anchored" data-anchor-id="kernel">Kernel</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GPFAKernel(gpytorch.kernels.Kernel):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Kernel to implement Gaussian Processes Factor Analysis</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>                 n_features: <span class="bu">int</span>, <span class="co"># number of variables at each time step</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>                 latent_kernel: gpytorch.kernels.Kernel, <span class="co"># func that returns any valid GPyTorch Kernel used to model the relationship over time of the latent</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>                 latent_dims:<span class="bu">int</span> <span class="op">=</span> <span class="dv">1</span>,  <span class="co"># Number of latent dims</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>                 Lambda: torch.tensor <span class="op">=</span> <span class="va">None</span>, <span class="co">#(n_features * latent_dims) initial value for factor loading matrix. If None init to one</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>                 psi: torch.tensor <span class="op">=</span> <span class="va">None</span>, <span class="co">#(n_features) initial value for random noise covariance. Note this is only the diagonal matrix</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>                 <span class="op">**</span>kwargs):</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(GPFAKernel, <span class="va">self</span>).<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Number of features in the X for each time step</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_features <span class="op">=</span> n_features</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.latent_dims <span class="op">=</span> latent_dims</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># see GPyTorch Kernels</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_parameter(</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>            name <span class="op">=</span> <span class="st">"Lambda"</span>,</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>            parameter <span class="op">=</span> torch.nn.Parameter(torch.rand(<span class="va">self</span>.n_features, <span class="va">self</span>.latent_dims)))</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># each dim has it's own latent kernel</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.latent_kernels <span class="op">=</span> torch.nn.ModuleList([latent_kernel() <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.latent_dims)])</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_parameter(</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>            name <span class="op">=</span> <span class="st">"raw_psi_diag"</span>,</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>            parameter <span class="op">=</span> torch.nn.Parameter(torch.zeros(<span class="va">self</span>.n_features))) </span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_constraint(<span class="st">"raw_psi_diag"</span>, gpytorch.constraints.Positive())</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> psi <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>: <span class="va">self</span>.psi <span class="op">=</span> psi</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convenient getter and setter for psi, since there is the Positive() constraint</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> psi(<span class="va">self</span>):</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># when accessing the parameter, apply the constraint transform</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.raw_psi_diag_constraint.transform(<span class="va">self</span>.raw_psi_diag)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">@psi.setter</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> psi(<span class="va">self</span>, value):</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>._set_psi(value)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _set_psi(<span class="va">self</span>, value):</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> torch.is_tensor(value):</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>            value <span class="op">=</span> torch.as_tensor(value).to(<span class="va">self</span>.raw_psi_diag)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># when setting the paramater, transform the actual value to a raw one by applying the inverse transform</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.initialize(raw_psi_diag<span class="op">=</span><span class="va">self</span>.raw_psi_diag_constraint.inverse_transform(value))</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, t1, t2, diag <span class="op">=</span> <span class="va">False</span>, last_dim_is_batch<span class="op">=</span><span class="va">False</span>, <span class="op">**</span>params):</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># not implemented yet</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> diag <span class="kw">is</span> <span class="va">False</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> last_dim_is_batch <span class="kw">is</span> <span class="va">False</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># take the number of observations from the input</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>        n_obs <span class="op">=</span> t1.shape[<span class="dv">0</span>]</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>        <span class="co"># compute the latent kernel</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>        kT <span class="op">=</span> torch.stack([ kernel(t1, t2, diag, last_dim_is_batch, <span class="op">**</span>params).evaluate() <span class="co"># this may make the whole thing slow as it breaks lazy evaluations</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>                         <span class="cf">for</span> kernel <span class="kw">in</span> <span class="va">self</span>.latent_kernels], dim<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> compute_gpfa_covariance(<span class="va">self</span>.Lambda, kT, <span class="va">self</span>.psi, <span class="va">self</span>.n_features, n_obs)</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> num_outputs_per_input(<span class="va">self</span>, x1,x2):</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.n_features</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a><span class="co"># this is a separate function, because torch script cannot take self as a parameter</span></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a><span class="at">@torch.jit.script</span></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_gpfa_covariance(Lambda, kT, psi, n_features, n_obs):</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pre allocate covariance matrix</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>    X_cov <span class="op">=</span> torch.empty(n_features <span class="op">*</span> n_obs, n_features <span class="op">*</span> n_obs, device<span class="op">=</span>Lambda.device)</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> torch.arange(n_obs):</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> torch.arange(n_obs):</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>            <span class="co"># i:i+1 is required to keep the number of dimensions</span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>            cov <span class="op">=</span>  Lambda <span class="op">@</span> torch.diag(kT[i,j,:]) <span class="op">@</span> Lambda.T</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>            <span class="co"># only diagonals add the noise</span></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">==</span> j: cov <span class="op">+=</span> torch.diag(psi)</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>            <span class="co"># add a block of size n_features*n_features to the covariance matrix</span></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>            X_cov[i<span class="op">*</span>n_features:(i<span class="op">*</span>n_features <span class="op">+</span> n_features),j<span class="op">*</span>n_features:(j<span class="op">*</span>n_features<span class="op">+</span>n_features)] <span class="op">=</span> cov</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X_cov</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<section id="scriptfunction-object-at-0x7f2e64aac8b0" class="level3">
<h3 class="anchored" data-anchor-id="scriptfunction-object-at-0x7f2e64aac8b0">ScriptFunction object at 0x7f2e64aac8b0&gt;</h3>
<hr>
<p><a href="https://github.com/mone27/meteo_imp/blob/master/meteo_imp/gpfa/gpfa.py#L14" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="gpfakernel" class="level3">
<h3 class="anchored" data-anchor-id="gpfakernel">GPFAKernel</h3>
<blockquote class="blockquote">
<pre><code> GPFAKernel (n_features:int, latent_kernel:gpytorch.kernels.kernel.Kernel,
             latent_dims:int=1, Lambda:&lt;built-
             inmethodtensoroftypeobjectat0x7f2edb2dd460&gt;=None, psi:&lt;built-
             inmethodtensoroftypeobjectat0x7f2edb2dd460&gt;=None, **kwargs)</code></pre>
</blockquote>
<p>Kernel to implement Gaussian Processes Factor Analysis</p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 25%">
<col style="width: 34%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>n_features</td>
<td>int</td>
<td></td>
<td>number of variables at each time step</td>
</tr>
<tr class="even">
<td>latent_kernel</td>
<td>Kernel</td>
<td></td>
<td>func that returns any valid GPyTorch Kernel used to model the relationship over time of the latent</td>
</tr>
<tr class="odd">
<td>latent_dims</td>
<td>int</td>
<td>1</td>
<td>Number of latent dims</td>
</tr>
<tr class="even">
<td>Lambda</td>
<td>tensor</td>
<td>None</td>
<td>(n_features * latent_dims) initial value for factor loading matrix. If None init to one</td>
</tr>
<tr class="odd">
<td>psi</td>
<td>tensor</td>
<td>None</td>
<td>(n_features) initial value for random noise covariance. Note this is only the diagonal matrix</td>
</tr>
<tr class="even">
<td>kwargs</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>gpfa_k <span class="op">=</span> GPFAKernel(n_features<span class="op">=</span><span class="dv">2</span>, latent_kernel<span class="op">=</span>gpytorch.kernels.RBFKernel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The parameters are correctly registered</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="bu">list</span>(gpfa_k.named_parameters())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[('Lambda',
  Parameter containing:
  tensor([[0.5982],
          [0.9041]], requires_grad=True)),
 ('raw_psi_diag',
  Parameter containing:
  tensor([0., 0.], requires_grad=True)),
 ('latent_kernels.0.raw_lengthscale',
  Parameter containing:
  tensor([[0.]], requires_grad=True))]</code></pre>
</div>
</div>
<p>Check that the Kernel is running</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>gpfa_k(torch.tensor((<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>))).evaluate()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>tensor([[1.0510, 0.5409, 0.1264, 0.1910, 0.0056, 0.0084],
        [0.5409, 1.5106, 0.1910, 0.2887, 0.0084, 0.0127],
        [0.1264, 0.1910, 1.0510, 0.5409, 0.1264, 0.1910],
        [0.1910, 0.2887, 0.5409, 1.5106, 0.1910, 0.2887],
        [0.0056, 0.0084, 0.1264, 0.1910, 1.0510, 0.5409],
        [0.0084, 0.0127, 0.1910, 0.2887, 0.5409, 1.5106]],
       grad_fn=&lt;CopySlices&gt;)</code></pre>
</div>
</div>
</section>
</section>
<section id="gpfa" class="level2">
<h2 class="anchored" data-anchor-id="gpfa">GPFA</h2>
<hr>
<p><a href="https://github.com/mone27/meteo_imp/blob/master/meteo_imp/gpfa/gpfa.py#L97" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="gpfazeromean" class="level3">
<h3 class="anchored" data-anchor-id="gpfazeromean">GPFAZeroMean</h3>
<blockquote class="blockquote">
<pre><code> GPFAZeroMean (n_features, device)</code></pre>
</blockquote>
<p>Zero Mean function to be used in GPFA, as it takes into account the number of features</p>
<p>to change the latent_kernel you should subcall <a href="https://mone27.github.io/meteo_imp/lib/GPFA/gpfa.html#gpfa"><code>GPFA</code></a> in this way the <code>get_info</code> function for the kernel can be changed to include the latent kernel details</p>
<hr>
<p><a href="https://github.com/mone27/meteo_imp/blob/master/meteo_imp/gpfa/gpfa.py#L110" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="gpfa-1" class="level3">
<h3 class="anchored" data-anchor-id="gpfa-1">GPFA</h3>
<blockquote class="blockquote">
<pre><code> GPFA (train_x, train_y, likelihood, n_features, latent_dims=1)</code></pre>
</blockquote>
<p>The base class for any Gaussian process latent function to be used in conjunction with exact inference.</p>
<p>:param torch.Tensor train_inputs: (size n x d) The training features :math:<code>\mathbf X</code>. :param torch.Tensor train_targets: (size n) The training targets :math:<code>\mathbf y</code>. :param ~gpytorch.likelihoods.GaussianLikelihood likelihood: The Gaussian likelihood that defines the observational distribution. Since we’re using exact inference, the likelihood must be Gaussian.</p>
<p>The :meth:<code>forward</code> function should describe how to compute the prior latent distribution on a given input. Typically, this will involve a mean and kernel function. The result must be a :obj:<code>~gpytorch.distributions.MultivariateNormal</code>.</p>
<p>Calling this model will return the posterior of the latent Gaussian process when conditioned on the training data. The output will be a :obj:<code>~gpytorch.distributions.MultivariateNormal</code>.</p>
<p>Example: &gt;&gt;&gt; class MyGP(gpytorch.models.ExactGP): &gt;&gt;&gt; def <strong>init</strong>(self, train_x, train_y, likelihood): &gt;&gt;&gt; super().__init__(train_x, train_y, likelihood) &gt;&gt;&gt; self.mean_module = gpytorch.means.ZeroMean() &gt;&gt;&gt; self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel()) &gt;&gt;&gt; &gt;&gt;&gt; def forward(self, x): &gt;&gt;&gt; mean = self.mean_module(x) &gt;&gt;&gt; covar = self.covar_module(x) &gt;&gt;&gt; return gpytorch.distributions.MultivariateNormal(mean, covar) &gt;&gt;&gt; &gt;&gt;&gt; # train_x = …; train_y = … &gt;&gt;&gt; likelihood = gpytorch.likelihoods.GaussianLikelihood() &gt;&gt;&gt; model = MyGP(train_x, train_y, likelihood) &gt;&gt;&gt; &gt;&gt;&gt; # test_x = …; &gt;&gt;&gt; model(test_x) # Returns the GP latent function at test_x &gt;&gt;&gt; likelihood(model(test_x)) # Returns the (approximate) predictive posterior distribution at test_x</p>
<p>make some very simple test data, to check that the model is working and can learn the parameters</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> torch.arange(<span class="dv">1</span>,<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.hstack([torch.arange(<span class="dv">0</span>,<span class="dv">3</span>) <span class="op">+</span> <span class="dv">2</span><span class="op">*</span> i <span class="cf">for</span> i <span class="kw">in</span> T])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>X</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>tensor([ 2,  3,  4,  4,  5,  6,  6,  7,  8,  8,  9, 10])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>X.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>torch.Size([12])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>tensor([1, 2, 3, 4])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize likelihood and model</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>likelihood <span class="op">=</span> gpytorch.likelihoods.GaussianLikelihood()</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GPFA(T, X, likelihood, n_features <span class="op">=</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>GPFA(
  (likelihood): GaussianLikelihood(
    (noise_covar): HomoskedasticNoise(
      (raw_noise_constraint): GreaterThan(1.000E-04)
    )
  )
  (mean_module): GPFAZeroMean()
  (covar_module): GPFAKernel(
    (latent_kernels): ModuleList(
      (0): RBFKernel(
        (raw_lengthscale_constraint): Positive()
      )
    )
    (raw_psi_diag_constraint): Positive()
  )
)</code></pre>
</div>
</div>
<p>Getting the prior from the GP</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>model(T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>MultivariateNormal(loc: torch.Size([12]))</code></pre>
</div>
</div>
<p>Fitting the parameters using gradient descend</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># this is for running the notebook in our testing framework</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>training_iter <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Find optimal model hyperparameters</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>model.train()</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>likelihood.train()</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the adam optimizer</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.1</span>)  <span class="co"># Includes GaussianLikelihood parameters</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co"># "Loss" for GPs - the marginal log likelihood</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>mll <span class="op">=</span> gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> []</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(training_iter):</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Zero gradients from previous iteration</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Output from model</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> model(T)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calc loss and backprop gradients</span></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="op">-</span>mll(output, X)</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>    losses.append(loss.item())</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Iter </span><span class="sc">%d</span><span class="st">/</span><span class="sc">%d</span><span class="st"> - Loss: </span><span class="sc">%.3f</span><span class="st">   lengthscale: </span><span class="sc">%.3f</span><span class="st">, Lambda: </span><span class="sc">%.3f</span><span class="st">   noise: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span> (</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>        i <span class="op">+</span> <span class="dv">1</span>, training_iter, loss.item(),</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>        model.covar_module.latent_kernels[<span class="dv">0</span>].lengthscale.item(),</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>        model.covar_module.Lambda.mean().item(),</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>        model.likelihood.noise.item()</span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Iter 1/10 - Loss: 10.056   lengthscale: 0.693, Lambda: 0.591   noise: 0.693
Iter 2/10 - Loss: 8.484   lengthscale: 0.744, Lambda: 0.691   noise: 0.744
Iter 3/10 - Loss: 7.256   lengthscale: 0.798, Lambda: 0.789   noise: 0.797
Iter 4/10 - Loss: 6.304   lengthscale: 0.853, Lambda: 0.884   noise: 0.850
Iter 5/10 - Loss: 5.564   lengthscale: 0.910, Lambda: 0.975   noise: 0.904
Iter 6/10 - Loss: 4.984   lengthscale: 0.968, Lambda: 1.061   noise: 0.956
Iter 7/10 - Loss: 4.526   lengthscale: 1.027, Lambda: 1.141   noise: 1.008
Iter 8/10 - Loss: 4.159   lengthscale: 1.086, Lambda: 1.216   noise: 1.058
Iter 9/10 - Loss: 3.863   lengthscale: 1.145, Lambda: 1.286   noise: 1.106
Iter 10/10 - Loss: 3.622   lengthscale: 1.203, Lambda: 1.350   noise: 1.152</code></pre>
</div>
</div>
<p>The model is training!</p>
</section>
</section>
<section id="multi-dimensional-latent-variable" class="level2">
<h2 class="anchored" data-anchor-id="multi-dimensional-latent-variable">Multi-dimensional latent variable</h2>
<section id="dimensions" class="level4">
<h4 class="anchored" data-anchor-id="dimensions">2 dimensions</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize likelihood and model</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>likelihood_m <span class="op">=</span> gpytorch.likelihoods.GaussianLikelihood()</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>model_m <span class="op">=</span> GPFA(T, X, likelihood, n_features <span class="op">=</span> <span class="dv">3</span>, latent_dims<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>model_m</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>GPFA(
  (likelihood): GaussianLikelihood(
    (noise_covar): HomoskedasticNoise(
      (raw_noise_constraint): GreaterThan(1.000E-04)
    )
  )
  (mean_module): GPFAZeroMean()
  (covar_module): GPFAKernel(
    (latent_kernels): ModuleList(
      (0): RBFKernel(
        (raw_lengthscale_constraint): Positive()
      )
      (1): RBFKernel(
        (raw_lengthscale_constraint): Positive()
      )
    )
    (raw_psi_diag_constraint): Positive()
  )
)</code></pre>
</div>
</div>
<p>check GP is running</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>model_m.covar_module.latent_kernels</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>ModuleList(
  (0): RBFKernel(
    (raw_lengthscale_constraint): Positive()
  )
  (1): RBFKernel(
    (raw_lengthscale_constraint): Positive()
  )
)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>model_m.covar_module.Lambda</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Parameter containing:
tensor([[0.8592, 0.4173],
        [0.0988, 0.0617],
        [0.4201, 0.6319]], requires_grad=True)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>likelihood(model_m(T))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>MultivariateNormal(loc: torch.Size([12]))</code></pre>
</div>
</div>
</section>
<section id="dimensions-1" class="level4">
<h4 class="anchored" data-anchor-id="dimensions-1">5 dimensions</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize likelihood and model</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>likelihood_m <span class="op">=</span> gpytorch.likelihoods.GaussianLikelihood()</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>model_m <span class="op">=</span> GPFA(T, X, likelihood, n_features <span class="op">=</span> <span class="dv">3</span>, latent_dims<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>model_m</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>GPFA(
  (likelihood): GaussianLikelihood(
    (noise_covar): HomoskedasticNoise(
      (raw_noise_constraint): GreaterThan(1.000E-04)
    )
  )
  (mean_module): GPFAZeroMean()
  (covar_module): GPFAKernel(
    (latent_kernels): ModuleList(
      (0): RBFKernel(
        (raw_lengthscale_constraint): Positive()
      )
      (1): RBFKernel(
        (raw_lengthscale_constraint): Positive()
      )
      (2): RBFKernel(
        (raw_lengthscale_constraint): Positive()
      )
      (3): RBFKernel(
        (raw_lengthscale_constraint): Positive()
      )
      (4): RBFKernel(
        (raw_lengthscale_constraint): Positive()
      )
    )
    (raw_psi_diag_constraint): Positive()
  )
)</code></pre>
</div>
</div>
<p>check GP is running</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>model_m.covar_module.latent_kernels</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>ModuleList(
  (0): RBFKernel(
    (raw_lengthscale_constraint): Positive()
  )
  (1): RBFKernel(
    (raw_lengthscale_constraint): Positive()
  )
  (2): RBFKernel(
    (raw_lengthscale_constraint): Positive()
  )
  (3): RBFKernel(
    (raw_lengthscale_constraint): Positive()
  )
  (4): RBFKernel(
    (raw_lengthscale_constraint): Positive()
  )
)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>model_m.covar_module.Lambda</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Parameter containing:
tensor([[0.2383, 0.0719, 0.9205, 0.6215, 0.9508],
        [0.5192, 0.2102, 0.9280, 0.0948, 0.4027],
        [0.4778, 0.7141, 0.3596, 0.9803, 0.4140]], requires_grad=True)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>likelihood(model_m(T))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>MultivariateNormal(loc: torch.Size([12]))</code></pre>
</div>
</div>
</section>
</section>
<section id="get-info" class="level2">
<h2 class="anchored" data-anchor-id="get-info">Get info</h2>
<p>this is to return the kernel info for printing, both during training and for the final results</p>
<p>The general api is:</p>
<p><code>get_info(var_names=None) -&gt; dict[str, pd.DataFrame]</code> where the string the title of a kernel parameter</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_info(<span class="va">self</span>: GPFA,</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>             var_names <span class="op">=</span> <span class="va">None</span> <span class="co"># Optional variable names for better printing</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>            ) <span class="op">-&gt;</span> <span class="bu">dict</span>[<span class="bu">str</span>, pd.DataFrame]:</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Model info for a GPFA with a RBFKernel"</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> {}</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>    latent_names <span class="op">=</span> [<span class="ss">f"z</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.covar_module.latent_dims)]</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>    out[<span class="st">"Lambda"</span>] <span class="op">=</span> pd.concat([</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">None</span> <span class="cf">if</span> var_names <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> pd.Series(var_names, name<span class="op">=</span><span class="st">'variable'</span>),</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>        pd.DataFrame(</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.covar_module.Lambda.detach().cpu().numpy(),</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>            columns<span class="op">=</span>latent_names)],</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>        axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>    ls <span class="op">=</span> [<span class="va">self</span>.covar_module.latent_kernels[i].lengthscale.detach().item() <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.covar_module.latent_dims)]</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>    out[<span class="st">"lengthscale"</span>] <span class="op">=</span> pd.DataFrame({</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">'latent'</span>: latent_names,</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">'lengthscale'</span>: ls</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>    psi <span class="op">=</span> <span class="va">self</span>.covar_module.psi.detach().cpu().numpy()</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>    out[<span class="st">"psi"</span>] <span class="op">=</span> pd.DataFrame({</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">'variable'</span>: var_names,</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">'psi'</span>: psi </span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>    out[<span class="st">"likelihood"</span>] <span class="op">=</span> pd.DataFrame({<span class="st">'noise'</span>: [<span class="va">self</span>.likelihood.noise_covar.noise.detach().item()]})</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p><a href="https://github.com/mone27/meteo_imp/blob/master/meteo_imp/gpfa/gpfa.py#L191" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="gpfa.get_info" class="level3">
<h3 class="anchored" data-anchor-id="gpfa.get_info">GPFA.get_info</h3>
<blockquote class="blockquote">
<pre><code> GPFA.get_info (var_names=None)</code></pre>
</blockquote>
<p>Model info for a GPFA with a RBFKernel</p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 25%">
<col style="width: 34%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>var_names</td>
<td>NoneType</td>
<td>None</td>
<td>Optional variable names for better printing</td>
</tr>
<tr class="even">
<td><strong>Returns</strong></td>
<td><strong>dict</strong></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>model_m.get_info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'Lambda':          z0        z1        z2        z3        z4
 0  0.238300  0.071901  0.920541  0.621538  0.950799
 1  0.519228  0.210204  0.928017  0.094791  0.402726
 2  0.477801  0.714146  0.359620  0.980278  0.414003,
 'lengthscale':   latent  lengthscale
 0     z0     0.693147
 1     z1     0.693147
 2     z2     0.693147
 3     z3     0.693147
 4     z4     0.693147,
 'psi':   variable       psi
 0     None  0.693147
 1     None  0.693147
 2     None  0.693147,
 'likelihood':       noise
 0  1.195812}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>model_m.get_info([<span class="st">"a"</span>, <span class="st">"b"</span>, <span class="st">"c"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'Lambda':   variable        z0        z1        z2        z3        z4
 0        a  0.238300  0.071901  0.920541  0.621538  0.950799
 1        b  0.519228  0.210204  0.928017  0.094791  0.402726
 2        c  0.477801  0.714146  0.359620  0.980278  0.414003,
 'lengthscale':   latent  lengthscale
 0     z0     0.693147
 1     z1     0.693147
 2     z2     0.693147
 3     z3     0.693147
 4     z4     0.693147,
 'psi':   variable       psi
 0        a  0.693147
 1        b  0.693147
 2        c  0.693147,
 'likelihood':       noise
 0  1.195812}</code></pre>
</div>
</div>
</section>
</section>
<section id="export" class="level2">
<h2 class="anchored" data-anchor-id="export">Export</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>model_m.covar_module.latent_kernels</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>ModuleList(
  (0): RBFKernel(
    (raw_lengthscale_constraint): Positive()
  )
  (1): RBFKernel(
    (raw_lengthscale_constraint): Positive()
  )
  (2): RBFKernel(
    (raw_lengthscale_constraint): Positive()
  )
  (3): RBFKernel(
    (raw_lengthscale_constraint): Positive()
  )
  (4): RBFKernel(
    (raw_lengthscale_constraint): Positive()
  )
)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>model_m.covar_module.Lambda</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Parameter containing:
tensor([[0.2383, 0.0719, 0.9205, 0.6215, 0.9508],
        [0.5192, 0.2102, 0.9280, 0.0948, 0.4027],
        [0.4778, 0.7141, 0.3596, 0.9803, 0.4140]], requires_grad=True)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>likelihood(model_m(T))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>MultivariateNormal(loc: torch.Size([12]))</code></pre>
</div>
</div>
</section>
<section id="get-info-1" class="level2">
<h2 class="anchored" data-anchor-id="get-info-1">Get info</h2>
<p>this is to return the kernel info for printing, both during training and for the final results</p>
<p>The general api is:</p>
<p><code>get_info(var_names=None) -&gt; dict[str, pd.DataFrame]</code> where the string the title of a kernel parameter</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_info(<span class="va">self</span>: GPFA,</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>             var_names <span class="op">=</span> <span class="va">None</span> <span class="co"># Optional variable names for better printing</span></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>            ) <span class="op">-&gt;</span> <span class="bu">dict</span>[<span class="bu">str</span>, pd.DataFrame]:</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Model info for a GPFA with a RBFKernel"</span></span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> {}</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>    latent_names <span class="op">=</span> [<span class="ss">f"z</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.covar_module.latent_dims)]</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>    out[<span class="st">"Lambda"</span>] <span class="op">=</span> pd.concat([</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">None</span> <span class="cf">if</span> var_names <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> pd.Series(var_names, name<span class="op">=</span><span class="st">'variable'</span>),</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>        pd.DataFrame(</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.covar_module.Lambda.detach().cpu().numpy(),</span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a>            columns<span class="op">=</span>latent_names)],</span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a>        axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a>    ls <span class="op">=</span> [<span class="va">self</span>.covar_module.latent_kernels[i].lengthscale.detach().item() <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.covar_module.latent_dims)]</span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a>    out[<span class="st">"lengthscale"</span>] <span class="op">=</span> pd.DataFrame({</span>
<span id="cb55-19"><a href="#cb55-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">'latent'</span>: latent_names,</span>
<span id="cb55-20"><a href="#cb55-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">'lengthscale'</span>: ls</span>
<span id="cb55-21"><a href="#cb55-21" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb55-22"><a href="#cb55-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb55-23"><a href="#cb55-23" aria-hidden="true" tabindex="-1"></a>    psi <span class="op">=</span> <span class="va">self</span>.covar_module.psi.detach().cpu().numpy()</span>
<span id="cb55-24"><a href="#cb55-24" aria-hidden="true" tabindex="-1"></a>    out[<span class="st">"psi"</span>] <span class="op">=</span> pd.DataFrame({</span>
<span id="cb55-25"><a href="#cb55-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">'variable'</span>: var_names,</span>
<span id="cb55-26"><a href="#cb55-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">'psi'</span>: psi </span>
<span id="cb55-27"><a href="#cb55-27" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb55-28"><a href="#cb55-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb55-29"><a href="#cb55-29" aria-hidden="true" tabindex="-1"></a>    out[<span class="st">"likelihood"</span>] <span class="op">=</span> pd.DataFrame({<span class="st">'noise'</span>: [<span class="va">self</span>.likelihood.noise_covar.noise.detach().item()]})</span>
<span id="cb55-30"><a href="#cb55-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb55-31"><a href="#cb55-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p><a href="https://github.com/mone27/meteo_imp/blob/master/meteo_imp/gpfa/gpfa.py#L191" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="gpfa.get_info-1" class="level3">
<h3 class="anchored" data-anchor-id="gpfa.get_info-1">GPFA.get_info</h3>
<blockquote class="blockquote">
<pre><code> GPFA.get_info (var_names=None)</code></pre>
</blockquote>
<p>Model info for a GPFA with a RBFKernel</p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 25%">
<col style="width: 34%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>var_names</td>
<td>NoneType</td>
<td>None</td>
<td>Optional variable names for better printing</td>
</tr>
<tr class="even">
<td><strong>Returns</strong></td>
<td><strong>dict</strong></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>model_m.get_info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'Lambda':          z0        z1        z2        z3        z4
 0  0.238300  0.071901  0.920541  0.621538  0.950799
 1  0.519228  0.210204  0.928017  0.094791  0.402726
 2  0.477801  0.714146  0.359620  0.980278  0.414003,
 'lengthscale':   latent  lengthscale
 0     z0     0.693147
 1     z1     0.693147
 2     z2     0.693147
 3     z3     0.693147
 4     z4     0.693147,
 'psi':   variable       psi
 0     None  0.693147
 1     None  0.693147
 2     None  0.693147,
 'likelihood':       noise
 0  1.195812}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>model_m.get_info([<span class="st">"a"</span>, <span class="st">"b"</span>, <span class="st">"c"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'Lambda':   variable        z0        z1        z2        z3        z4
 0        a  0.238300  0.071901  0.920541  0.621538  0.950799
 1        b  0.519228  0.210204  0.928017  0.094791  0.402726
 2        c  0.477801  0.714146  0.359620  0.980278  0.414003,
 'lengthscale':   latent  lengthscale
 0     z0     0.693147
 1     z1     0.693147
 2     z2     0.693147
 3     z3     0.693147
 4     z4     0.693147,
 'psi':   variable       psi
 0        a  0.693147
 1        b  0.693147
 2        c  0.693147,
 'likelihood':       noise
 0  1.195812}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>model_m.covar_module.Lambda</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Parameter containing:
tensor([[0.2383, 0.0719, 0.9205, 0.6215, 0.9508],
        [0.5192, 0.2102, 0.9280, 0.0948, 0.4027],
        [0.4778, 0.7141, 0.3596, 0.9803, 0.4140]], requires_grad=True)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>likelihood(model_m(T))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>MultivariateNormal(loc: torch.Size([12]))</code></pre>
</div>
</div>
</section>
</section>
<section id="get-info-2" class="level2">
<h2 class="anchored" data-anchor-id="get-info-2">Get info</h2>
<p>this is to return the kernel info for printing, both during training and for the final results</p>
<p>The general api is:</p>
<p><code>get_info(var_names=None) -&gt; dict[str, pd.DataFrame]</code> where the string the title of a kernel parameter</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_info(<span class="va">self</span>: GPFA,</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>             var_names <span class="op">=</span> <span class="va">None</span> <span class="co"># Optional variable names for better printing</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>            ) <span class="op">-&gt;</span> <span class="bu">dict</span>[<span class="bu">str</span>, pd.DataFrame]:</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Model info for a GPFA with a RBFKernel"</span></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> {}</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>    latent_names <span class="op">=</span> [<span class="ss">f"z</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.covar_module.latent_dims)]</span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>    out[<span class="st">"Lambda"</span>] <span class="op">=</span> pd.concat([</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">None</span> <span class="cf">if</span> var_names <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> pd.Series(var_names, name<span class="op">=</span><span class="st">'variable'</span>),</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>        pd.DataFrame(</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.covar_module.Lambda.detach().cpu().numpy(),</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>            columns<span class="op">=</span>latent_names)],</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>        axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>    ls <span class="op">=</span> [<span class="va">self</span>.covar_module.latent_kernels[i].lengthscale.detach().item() <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.covar_module.latent_dims)]</span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a>    out[<span class="st">"lengthscale"</span>] <span class="op">=</span> pd.DataFrame({</span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">'latent'</span>: latent_names,</span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">'lengthscale'</span>: ls</span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb65-22"><a href="#cb65-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-23"><a href="#cb65-23" aria-hidden="true" tabindex="-1"></a>    psi <span class="op">=</span> <span class="va">self</span>.covar_module.psi.detach().cpu().numpy()</span>
<span id="cb65-24"><a href="#cb65-24" aria-hidden="true" tabindex="-1"></a>    out[<span class="st">"psi"</span>] <span class="op">=</span> pd.DataFrame({</span>
<span id="cb65-25"><a href="#cb65-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">'variable'</span>: var_names,</span>
<span id="cb65-26"><a href="#cb65-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">'psi'</span>: psi </span>
<span id="cb65-27"><a href="#cb65-27" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb65-28"><a href="#cb65-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-29"><a href="#cb65-29" aria-hidden="true" tabindex="-1"></a>    out[<span class="st">"likelihood"</span>] <span class="op">=</span> pd.DataFrame({<span class="st">'noise'</span>: [<span class="va">self</span>.likelihood.noise_covar.noise.detach().item()]})</span>
<span id="cb65-30"><a href="#cb65-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-31"><a href="#cb65-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p><a href="https://github.com/mone27/meteo_imp/blob/master/meteo_imp/gpfa/gpfa.py#L191" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="gpfa.get_info-2" class="level3">
<h3 class="anchored" data-anchor-id="gpfa.get_info-2">GPFA.get_info</h3>
<blockquote class="blockquote">
<pre><code> GPFA.get_info (var_names=None)</code></pre>
</blockquote>
<p>Model info for a GPFA with a RBFKernel</p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 25%">
<col style="width: 34%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>var_names</td>
<td>NoneType</td>
<td>None</td>
<td>Optional variable names for better printing</td>
</tr>
<tr class="even">
<td><strong>Returns</strong></td>
<td><strong>dict</strong></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>model_m.get_info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'Lambda':          z0        z1        z2        z3        z4
 0  0.238300  0.071901  0.920541  0.621538  0.950799
 1  0.519228  0.210204  0.928017  0.094791  0.402726
 2  0.477801  0.714146  0.359620  0.980278  0.414003,
 'lengthscale':   latent  lengthscale
 0     z0     0.693147
 1     z1     0.693147
 2     z2     0.693147
 3     z3     0.693147
 4     z4     0.693147,
 'psi':   variable       psi
 0     None  0.693147
 1     None  0.693147
 2     None  0.693147,
 'likelihood':       noise
 0  1.195812}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>model_m.get_info([<span class="st">"a"</span>, <span class="st">"b"</span>, <span class="st">"c"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'Lambda':   variable        z0        z1        z2        z3        z4
 0        a  0.238300  0.071901  0.920541  0.621538  0.950799
 1        b  0.519228  0.210204  0.928017  0.094791  0.402726
 2        c  0.477801  0.714146  0.359620  0.980278  0.414003,
 'lengthscale':   latent  lengthscale
 0     z0     0.693147
 1     z1     0.693147
 2     z2     0.693147
 3     z3     0.693147
 4     z4     0.693147,
 'psi':   variable       psi
 0        a  0.693147
 1        b  0.693147
 2        c  0.693147,
 'likelihood':       noise
 0  1.195812}</code></pre>
</div>
</div>
</section>
</section>
<section id="export-1" class="level2">
<h2 class="anchored" data-anchor-id="export-1">Export</h2>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>