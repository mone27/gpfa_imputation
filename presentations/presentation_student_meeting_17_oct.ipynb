{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Meterological time series imputation with Gaussian Processes Factor Analysis\n",
        "author: Simone Massaro\n",
        "Date: 17 Oct 2022\n",
        "format: revealjs\n",
        "---"
      ],
      "id": "c820e02f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "-   I am master student in \"Ecosystem Analysis and Modelling\" from the forestry department\n",
        "-   master thesis on Gap filling meterological data with Fabian Sinz as co-supervisor\n",
        "\n",
        "## Outline\n",
        "\n",
        "1.  Problem formulation\n",
        "2.  Modelling approach\n",
        "3.  Model flow\n",
        "4.  First results\n",
        "5.  Next steps\n",
        "\n",
        "## 1. Problem formulation\n",
        "\n",
        "-   to measure **greenhouse gas exchanges** \"Eddy Covariance\" state of the art technique\n",
        "-   measurement set-up includes meteorological variables (eg. air temperature, wind speed ...)\n",
        "-   technical issues (eg. broken sensor) result in **meteo time series** with **gaps**\n",
        "-   presence of gaps is a problem for many applications of the data (eg. ecosystem modelling)\n",
        "\n",
        "## How to fill gaps (or imputation approaches)\n",
        "\n",
        "-   use previous and following measurements for one variable and temporal auto-correlation (eg. diurnal cycles)\n",
        "-   correlation with other variables measures (eg. solar radiation and temperature)\n",
        "-   other measurements of meteo variables\n",
        "\n",
        "## Why this is relevant\n",
        "\n",
        "-   imputation of meteo time series is already implemented in processing pipelines\n",
        "-   main limitations\n",
        "    -   simple algorithms (mainly linear models)\n",
        "    -   no uncertainty for the predictions\n",
        "    -   don't combine the different imputation approaches\n",
        "\n",
        "## 2. Modelling approach\n",
        "\n",
        "first model: Gaussian Process Factor Analysis\n",
        "\n",
        "Model one latent variable ($z$) over time with a Gaussian Process\n",
        "\n",
        "$$x_{:,t} = \\Lambda z_{:,t} + \\epsilon $$\n",
        "\n",
        "$\\Lambda$ express relation between observed variables and latent variable at each time step\n",
        "\n",
        "## 3. Model flow {.smaller}\n",
        "\n",
        "-   dataframe with missing data\n",
        "-   row without missing data -> training data\n",
        "-   row with missing data -> prediction time\n",
        "-   normalize data\n",
        "-   fit kernel hyperparameters on training data using gradient descend\n",
        "-   predict missing data (mean + std) using Gaussian Processes\n",
        "-   compute conditional distribution for rows with at least 1 variable non-missing\n",
        "-   impute gaps in original dataframe\n",
        "\n",
        "# 4. First Results {.smaller}\n",
        "\n",
        "## Random gaps in dataset - plot\n"
      ],
      "id": "65b2991c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| include: false\n",
        "import altair as alt\n",
        "from pathlib import Path\n",
        "from pyprojroot import here\n",
        "\n",
        "plot = alt.Chart.from_json(\n",
        "    (Path(here()) / \"analysis\" / 'plots' / \"plot_hai_winter_4_var_200_obs_random_gaps_row_20_value_10.vl.json\").read_text())"
      ],
      "id": "57dd440f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results GPFA (dataset: 200 rows; prob missing row: 20%; prob missing value: 10%)\n"
      ],
      "id": "14b79c25"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-cap: caption\n",
        "plot"
      ],
      "id": "04e3fed3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    variable    rmse\n",
        "\n",
        "0 LW_IN 19.316336 1 SW_IN 41.114666 2 TA 0.096362 3 VPD 0.228843\n",
        "\n",
        "## Random gaps in dataset\n",
        "\n",
        "| Variable | RMSE  | Unit  |\n",
        "|----------|-------|-------|\n",
        "| TA       | 0.09  | Â°C    |\n",
        "| SW_IN    | 41.11 | W m-2 |\n",
        "| LW_IN    | 19.31 | W m-2 |\n",
        "| VPD      | 0.22  | hPa   |\n",
        "\n",
        ": Root Mean Square Error for each variable\n",
        "\n",
        "## Measure model performance\n",
        "\n",
        "-   RMSE\n",
        "-   Loss (log likelihood) also on prediction?\n",
        "\n",
        "## GPFA improvements\n",
        "\n",
        "-   test different kernels\n",
        "-   use more than one latent variables\n",
        "-   make it faster (GPU + Sparse Gaussian Processes)\n"
      ],
      "id": "aa34a55b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": []
      },
      "source": [
        "#| include: false\n",
        "!quarto render presentation_student_meeting_17_oct.ipynb "
      ],
      "id": "592e1492",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "data_science",
      "language": "python",
      "display_name": "data_science"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}