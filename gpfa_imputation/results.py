# AUTOGENERATED! DO NOT EDIT! File to edit: ../lib_nbs/04_Results.ipynb.

# %% auto 0
__all__ = ['GPFAResult']

# %% ../lib_nbs/04_Results.ipynb 3
from .learner import *
from .data_preparation import *
from .imputation import *
from .utils import *

import torch

import pandas as pd
import numpy as np
import sklearn
from sklearn.metrics import mean_squared_error, r2_score

from fastcore.foundation import patch, patch_to
from fastcore.meta import delegates
from fastcore.basics import store_attr, listify
from fastcore.test import test_close
from itertools import zip_longest
from fastcore.dispatch import typedispatch

import matplotlib.pyplot as plt
import altair as alt
from altair import datum

from typing import Collection


# %% ../lib_nbs/04_Results.ipynb 4
class GPFAResult:
    def __init__(self,
                 data_imputed, #imputed data in tidy format
                 data_complete, # complete data in tidy format
                 model_info, # learner for parameters display
                 units = None, # units for plots
                 metrics_all_data = True # Compute metrics only for gap or for all data?
                ):
        store_attr()

# %% ../lib_nbs/04_Results.ipynb 6
@patch
def to_result(self: GPFAImputation, data_complete, units=None):
    var_names = self.data.columns
    return GPFAResult(self.impute(add_time=True), data_complete, self.learner.model.get_info(var_names), units, metrics_all_data=False)

# %% ../lib_nbs/04_Results.ipynb 7
@patch
def to_result(self: GPFAImputationExplorer, data_complete, units=None):
    var_names = self.data.columns
    return GPFAResult(self.predict(), data_complete, self.learner.model.get_info(var_names), units)

# %% ../lib_nbs/04_Results.ipynb 12
@patch
def compute_metric(self: GPFAResult,
                   metric, # function that takes as argument true and pred and returns the metric
                   metric_name = 'metric',
                  ):
    df = pd.merge(self.data_imputed, self.data_complete, on = ['time','variable'])
    
    vars = []
    
    for var in df.variable.unique():
        mask = (df.variable == var) & (df.is_missing == True) if not self.metrics_all_data else df.variable == var
        
        df_var = df[mask]
        vars.append({'variable': var,
                      metric_name: metric(df_var['value'], df_var['mean']) if len(df_var) > 0 else None})
    
    return pd.DataFrame(vars)

# %% ../lib_nbs/04_Results.ipynb 13
@patch
def rmse(self: GPFAResult):
    rmse = self.compute_metric(lambda x, y: np.sqrt(mean_squared_error(x,y)), "rmse")
    if self.units: rmse = rmse.assign(units= self.units.values())
    return rmse

# %% ../lib_nbs/04_Results.ipynb 16
@patch
def r2(self: GPFAResult):
    return self.compute_metric(r2_score, "r2")

# %% ../lib_nbs/04_Results.ipynb 18
@patch
def print_metrics(self: GPFAResult):
    
    old = self.metrics_all_data
    
    self.metrics_all_data = True
    all_met = {
    'r2': self.r2(),
    'RMSE': self.rmse()
    }
    
    self.metrics_all_data = False
    met = {**all_met,
    'r2 - Only GAP': self.r2(),
    'RMSE - Only GAP': self.rmse()
    }
    
    self.metrics_all_data = old
    return met

# %% ../lib_nbs/04_Results.ipynb 21
def _plot_variable(imp, complete, variable, y_label="", sel=None, properties = {}):
    
    imp = imp[imp.variable == variable]
    sel = sel if sel is not None else alt.selection_interval(bind="scales")
    
    error = alt.Chart(imp).mark_errorband().encode(
        x = "time",    
        y = alt.Y("err_low:Q", title = y_label, scale=alt.Scale(zero=False)),
        y2 = "err_high:Q",
        color=alt.Color("variable",
                        legend = alt.Legend(title=["Line: pred. mean", "area: +/- 2 std", "(variable)"])
                       ),
        tooltip = alt.Tooltip(['std', 'mean'], format=".4")
    ).transform_calculate(
        err_low = "datum.mean - 2 * datum.std",
        err_high = "datum.mean + 2 * datum.std"
    ).properties( **properties)

    pred = alt.Chart(imp).mark_line().encode(
        x = "time",    
        y = alt.Y("mean:Q", title = y_label, scale=alt.Scale(zero=False)),
        color="variable",
    ).add_selection(
        sel
    ).properties(title = variable)

    base_plot = error + pred
    
    if complete is not None:

        complete = complete[complete.variable == variable]
        truth_plt = alt.Chart(complete).mark_point(
            color='black',
            strokeWidth = 1,
            fillOpacity = 1
        ).encode(
            x = alt.X("time", axis=alt.Axis(domain=False, labels = False, ticks=False, title=None)),
            y = alt.Y("value", title = y_label, scale=alt.Scale(zero=False)),
            fill= alt.Fill("is_missing", scale = alt.Scale(range=["#ffffff00", "black"]),
                           legend = alt.Legend(title =["Observed data","(is missing)"])),
            shape = "is_missing",
        )
       
        p = {'width': properties['width']} if properties else {}
        missing = alt.Chart(complete).mark_tick(
            color='black',
        ).encode(
            x = "time",
            color = alt.condition(datum.is_missing, alt.value('black'), alt.value('white'))
        ).add_selection(
            sel
        ).properties(**p)

        base_plot = alt.VConcatChart(vconcat=[(truth_plt + base_plot), missing], spacing=-10)
        
    return base_plot
    

# %% ../lib_nbs/04_Results.ipynb 23
@patch()
def plot_pred(
    self: GPFAResult,
    n_cols: int = 2,
    bind_interaction: bool =True, # Whether the sub-plots for each variable should be connected for zooming/panning
    properties:dict = {} # additional properties (eg. size) for altair plot
):
    "Plot the prediction for each variable"
   
    plot_list = [alt.hconcat() for _ in range(0, self.data_imputed.shape[0], n_cols)]
    selection_scale = alt.selection_interval(bind="scales", encodings=['x']) if bind_interaction else None
    for idx, variable in enumerate(pd.unique(self.data_imputed.variable)):
        plot_list[idx // n_cols] |= _plot_variable(self.data_imputed,
                                                   self.data_complete,
                                                   variable,
                                                   y_label = f"{variable} [{self.units[variable]}]" if self.units is not None else variable,
                                                   sel = selection_scale, properties=properties)
    
    plot = alt.vconcat(*plot_list)
    
    return plot

# %% ../lib_nbs/04_Results.ipynb 28
from IPython.display import HTML

from ipywidgets import HBox, VBox, interact, widgets
from ipywidgets.widgets import Output

# %% ../lib_nbs/04_Results.ipynb 29
def _style_df(df):
    """style dataframe for better printing """
    return df.style.hide(axis="index").format(precision = 4)

def _display_as_row(dfs: dict[str, pd.DataFrame], title="", styler=_style_df):
    """display multiple dataframes in the same row"""
    out = []
    for df_title, df in dfs.items():
        df_html = _style_df(df).to_html()
        out.append(f"<div> <p style='font-size: 1.3rem;'>{df_title}</p> {df_html} </div>")
    out = f"<div style=\"display: flex; column-gap: 20px; flex-wrap: wrap;\" class='table table-striped table-sm'> {''.join(out)}</div>"
    display(HTML(f"<p style='font-size: 1.5rem; font-decoration: bold'>{title}<p>" + "".join(out)))

# %% ../lib_nbs/04_Results.ipynb 33
@patch 
def display_results(self: GPFAResult, plot_args={}):
    
    plot_args = {'properties': {'height': 200 , 'width': 350}, **plot_args} # set default plot size
    plot = self.plot_pred(**plot_args)
    
    display(plot)    
    _display_as_row(self.print_metrics(), "Metrics")
    _display_as_row(self.model_info, "Model Info")   
