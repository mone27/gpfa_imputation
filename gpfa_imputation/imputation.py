# AUTOGENERATED! DO NOT EDIT! File to edit: ../lib_nbs/02_Imputation.ipynb.

# %% auto 0
__all__ = ['GPFADataGenerator', 'GPFADataTest', 'GPFAImputation']

# %% ../lib_nbs/02_Imputation.ipynb 4
from .learner import *

import torch

import pandas as pd
import numpy as np
from fastcore.foundation import patch

import matplotlib.pyplot as plt
import altair as alt

# %% ../lib_nbs/02_Imputation.ipynb 7
class GPFADataGenerator:
    def __init__(self,
                    n_features: int,
                    n_obs: int,
                    latent_func = lambda x: torch.sin(3*x), # Functions used to generate the true latent
                    noise_std = .2,
                    Lambda = None
                ):
        
        self.n_features, self.n_obs = n_features, n_obs
        self.time = torch.arange(0, self.n_obs, dtype=torch.float)
        
        self.latent = latent_func(self.time)
        
        self.Lambda = torch.tensor(Lambda).reshape(n_features, 1) if Lambda is not None else torch.rand(n_features, 1)
        
        self.exact_X = (self.Lambda * self.latent).T
        
        self.X =  self.exact_X + torch.normal(0., noise_std, size = (n_obs, n_features)) 
        
        self.data = pd.DataFrame(self.X.numpy(), columns = [f"x{i}" for i in range(self.n_features)]) 
        

# %% ../lib_nbs/02_Imputation.ipynb 8
class GPFADataTest:
    def __init__(self, data: pd.DataFrame):
        " Init with provided dataset"
        self.data = data
        self.n_features, self.n_obs = data.shape[1], data.shape[0]
        self.time = torch.arange(0, self.n_obs, dtype=torch.float)
    @classmethod
    def generate(cls, *args, **kwargs):
        generator = GPFADataGenerator(*args, **kwargs)
        self = GPFADataTest(generator.data)
        self.generator = generator
        return self

# %% ../lib_nbs/02_Imputation.ipynb 13
@patch()
def add_random_missing(self: GPFADataTest,
                prob_miss_row: float = .2,#  Probability an entire row is missing
                prob_miss_value: float = .1 # Probability a single observation is missing       
               ):
    """Make some row and same values randomly missing """
    # keep the original data
    self.data_complete = self.data.copy()
        
    self.is_miss_row = torch.rand(self.n_obs) <= prob_miss_row
    
    self.data[self.is_miss_row.numpy()] = np.nan
    
    self.is_miss_value = (torch.rand(self.n_obs * self.n_features) <= prob_miss_value).reshape(-1, self.n_features)
    
    self.data[self.is_miss_value.numpy()] = np.nan
    
    return self

# %% ../lib_nbs/02_Imputation.ipynb 18
@patch
def tidy_df(self: GPFADataTest,
          complete = False, # full dataset (False) or the one with missing data (True)
          is_missing = False # add flag whether value is missing
         ):
    
    df = self.data if not complete else self.data_complete # no need to copy here because next lines does a copy anyway
    df = df.assign(time = self.time.numpy())
        
    df = df.melt("time")
    
    if is_missing: df = df.assign(is_missing = self.data.melt().value.isna()) #missing data is not from complete data
        
    return df

# %% ../lib_nbs/02_Imputation.ipynb 38
class GPFAImputation:
    def __init__(
        self,
        data: pd.DataFrame , #observed data with missing data as NA
    ):
        self.data = data
        self.T = torch.arange(0, len(data), dtype=torch.float32) # time is encoded with a increase of 1
        
        # Training data
        self.train_idx = ~self.data.isna().any(axis=1)
        self.train_data = torch.tensor(self.data[self.train_idx].to_numpy().astype(np.float32))
        self.train_T = self.T[self.train_idx]
        
        self.learner = GPFALearner(X = self.train_data, T = self.train_T)

        # Prediction data
        self.pred_T = self.T[~self.train_idx]
        self.cond_idx = torch.tensor(~self.data[~self.train_idx].isna().to_numpy().flatten()) # conditional obsevations
        self.cond_obs = torch.tensor(self.data[~self.train_idx].to_numpy().astype(np.float32).flatten()[self.cond_idx])
        
        
    def impute(self,
               add_time = True, # add column with time?
               tidy = True # tidy data?
               ):
        self.learner.train()
        self.pred = self.learner.predict(self.pred_T, obs = self.cond_obs, idx = self.cond_idx)
        
        if tidy: return self._impute_tidy(add_time)
        else: return self._impute_wide(add_time)
        
        
    def _impute_wide(self, add_time):
        """ Impute in wide format"""
        
        imp_data = self.data.copy()
        for col_idx, col_name in enumerate(imp_data.columns):
            imp_data.loc[~self.train_idx, col_name] = self.pred.mean[:, col_idx].numpy()
            imp_data.loc[~self.train_idx, col_name + "_std"] = self.pred.std[:, col_idx].numpy()
        
        idx_vars = []
        if add_time:
            imp_data["time"] = self.T
            idx_vars.append("time")
        
        return imp_data 
    
    def _impute_tidy(self, add_time):
        """ transform the pred output into a tidy dataframe suitable for plotting"""
        feature_names = self.data.columns

        pred_mean = pd.DataFrame(self.pred.mean, columns = feature_names).assign(time = self.pred_T).melt("time", value_name="mean")
        pred_std = pd.DataFrame(self.pred.std, columns = feature_names).assign(time = self.pred_T).melt("time", value_name="std")
        
        pred = pd.merge(pred_mean, pred_std, on=['time', 'variable'])  
        
        train_data = self.data[self.train_idx].assign(time = self.train_T).melt("time", value_name = "mean")
               
        imp_data = pd.concat((train_data, pred))
        
        return imp_data
    

# %% ../lib_nbs/02_Imputation.ipynb 45
@patch()
def plot_pred(
    self: GPFAImputation,
    complete = None # Optional true data to be plotted agaist predictions
):
    
    imp = self._impute_tidy(add_time=True) if hasattr(self, "pred") else self.impute(tidy=True, add_time=True)
    
    error = alt.Chart(imp).mark_errorband().encode(
        x = "time",    
        y = alt.Y("err_low:Q", title=""),
        y2 = "err_high:Q",
        color="variable"
    ).transform_calculate(
        err_low = "datum.mean - 2 * datum.std",
        err_high = "datum.mean + 2 * datum.std"
    )

    pred = alt.Chart(imp).mark_line().encode(
        x = "time",    
        y = alt.Y("mean:Q", title="value variable"),
        color="variable"
    )

    plot = error + pred
    
    if complete is not None:
        
        truth_plt = alt.Chart(complete).mark_point().encode(
            x = "time",
            y = alt.Y("value", title="value variable"),
            color="variable",
            shape = "is_missing"
        )
        
        plot = plot + truth_plt
    
    
    return plot

# %% ../lib_nbs/02_Imputation.ipynb 50
@patch
def __repr__(self: GPFAImputation):
    return f"""GPFA Imputation:
    N obs: {self.data.shape[0]}
    N features {self.data.shape[1]} ({', '.join(self.data.columns)})
    N missing observations {self.cond_idx.sum()}"""

@patch
def __str__(self: GPFAImputation):
    return self.__repr__()
